{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18390,
     "status": "ok",
     "timestamp": 1716394103807,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "6Ypq5zelYtZs",
    "outputId": "ec1b1e09-aee4-453d-d537-f7a52b3d2e0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1376,
     "status": "ok",
     "timestamp": 1716394105181,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "0aI0sh5wHeUW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N1oxZYq3_s3M"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQrbZQJR--Q3"
   },
   "source": [
    "## Read sentence for each ALIGNED article csv file with train set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8490,
     "status": "ok",
     "timestamp": 1716394113669,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "HpegKYMIBj2G",
    "outputId": "9f9a2a14-cc86-4d70-a253-ed5e0e4f4975"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146660\n"
     ]
    }
   ],
   "source": [
    "df_train_transcript = pd.read_csv('./CORPUS/HANJA/HANJA_TRAIN_ALL.csv')\n",
    "df_train_transcript = df_train_transcript.to_dict(orient='dict')\n",
    "\n",
    "TRAIN_KSENT = (list(df_train_transcript['KO'].values()))\n",
    "TRAIN_KSENT.remove('\\\"')\n",
    "\n",
    "TRAIN_ZSENT = (list(df_train_transcript['ZH'].values()))\n",
    "TRAIN_ZSENT.remove('”')\n",
    "\n",
    "TRAIN_HSENT = (list(df_train_transcript['HANJA_Z'].values()))\n",
    "TRAIN_HSENT.remove('\\\"')\n",
    "\n",
    "#TRAIN_HSENT = (list(df_train_transcript['HANJA_K'].values()))\n",
    "#TRAIN_HSENT.remove('\\\"')\n",
    "\n",
    "print(len(TRAIN_KSENT))\n",
    "df_train_transcript = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1730,
     "status": "ok",
     "timestamp": 1716394115396,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "cdp5CTVABkI_",
    "outputId": "d97aabff-1cb4-4aa9-aeb3-5e0845651802"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36089\n"
     ]
    }
   ],
   "source": [
    "df_test_transcript = pd.read_csv('./CORPUS/HANJA/HANJA_TEST_ALL.csv')\n",
    "df_test_transcript = df_test_transcript.to_dict(orient='dict')\n",
    "\n",
    "TEST_KSENT = (list(df_test_transcript['KO'].values()))\n",
    "TEST_ZSENT = (list(df_test_transcript['ZH'].values()))\n",
    "TEST_HSENT = (list(df_test_transcript['HANJA_Z'].values()))\n",
    "#TEST_HSENT = (list(df_test_transcript['HANJA_K'].values()))\n",
    "\n",
    "df_test_transcript = []\n",
    "print(len(TEST_KSENT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6219,
     "status": "ok",
     "timestamp": 1716394121611,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "TKQgkPEWJE9Q",
    "outputId": "4718f93c-55eb-4fa4-8046-22ef21846f99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146660\n"
     ]
    }
   ],
   "source": [
    "df_train_zhuyin = pd.read_csv('./CORPUS/ZHUYIN/ZHUYIN_TRAIN_ALL.csv')\n",
    "df_train_zhuyin = df_train_zhuyin.to_dict(orient='dict')\n",
    "\n",
    "TRAIN_ZYSENT = (list(df_train_zhuyin['zhuyin'].values()))\n",
    "TRAIN_ZYSENT.remove(np.nan)\n",
    "TRAIN_ZYSENT = [sent.replace('\\n','') for sent in TRAIN_ZYSENT]\n",
    "\n",
    "df_train_zhuyin = []\n",
    "print(len(TRAIN_ZYSENT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 878,
     "status": "ok",
     "timestamp": 1716394122487,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "Fbno4O52JE9Q",
    "outputId": "3e0b3deb-a500-47c6-c534-3038b72d7f1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36089\n"
     ]
    }
   ],
   "source": [
    "df_test_zhuyin = pd.read_csv('./CORPUS/ZHUYIN/ZHUYIN_TEST_ALL.csv')\n",
    "df_test_zhuyin = df_test_zhuyin.to_dict(orient='dict')\n",
    "\n",
    "TEST_ZYSENT = [sent.replace('\\n','') for sent in (list(df_test_zhuyin['zhuyin'].values()))]\n",
    "\n",
    "df_test_transcript = []\n",
    "print(len(TEST_ZYSENT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_delete_indexs(src_lists,dst_lists):\n",
    "    delete_indexs = {}\n",
    "    for i in range(len(src_lists)):\n",
    "        if(len(src_lists[i]) < 3 or len(dst_lists[i]) < 3):\n",
    "            delete_indexs[i] = 1\n",
    "            print(i,src_lists[i], dst_lists[i])\n",
    "    return list(delete_indexs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_indexs_items(lists,delete_indexs):\n",
    "    delete_indexs.reverse()\n",
    "    for i in delete_indexs:\n",
    "        del lists[i]\n",
    "    return lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1685 （掌聲） 박수\n",
      "2315 不! 절대! 아닙니다!\n",
      "6228 嗨。 안녕하세요.\n",
      "6447 謝謝 감사합니다.!\n",
      "9080 好! 알겠습니다.\n",
      "10567 是的。 네.\n",
      "11806 十？ 열 개? 우리는 질문해야 합니다.\n",
      "11991 」 ”\n",
      "13214 嗨。 안녕하세요.\n",
      "14710 不。 아뇨.\n",
      "31278 好。 좋아요.\n",
      "33767 好。 좋습니다.\n",
      "34090 什麼？ 뭐라\n",
      "36726 不！ 아니죠.\n",
      "39959 嗨！ 안녕하세요.\n",
      "40878 你。 바로 여러분입니다.\n",
      "46783 謝謝 감사합니다\n",
      "51043 哇。 오우.\n",
      "64302 好。 좋아요.\n",
      "66859 」 \" 저.. 회사의 관리자가 당신에게 심장 판막을 보내지 않기로 결정했습니다.\n",
      "74805 人。 무언가는, 어 딘가는 언제나 변했을 겁니다.\n",
      "76821 嗨！ 신발끈에도 패턴이 있기 때문입니다.\n",
      "77330 在她於1917年過世時，這些夢想仍未實現。 ”\n",
      "77331 」 감사합니다.\n",
      "82234 摸。 이분은 조나 단이고 37세이며 석사 학위를 가지고 있습니다.\n",
      "88883 因為和穆斯林結盟來對抗基督教夥伴所造成的憤怒讓他也失去了所有剩下的當地支援。 \"\n",
      "88884 」 다른 방법으로는 생각지도 못할 아이디어를 얻을 수 있습니다.\n",
      "89997 好。 눈은 계속 감고 계시 고요 차이점을 들으셨나요?\n",
      "93311 嗨。 제 수염이 반쪽만 있는 걸 눈치 채셨을 겁니다.\n",
      "94843 透過讚美自由言論及讚頌平凡英雄，他的劇作讓觀眾在歡笑的同時也能有所思考。 \"\n",
      "94844 」 감사합니다.\n",
      "98549 好。 모두 앉아 주세요.\n",
      "100655 當時，我一直有修練松濤館空手道，從我有印象以來都在練，所以我已經拿了黑帶。 네.\n",
      "101007 對？ ( 웃음) 이 시계의 무게는 기계적으로 조정되어서 계속해서 천천히 작동하도록 되어 있습니다.\n",
      "105530 嗨！ ( 박수와 함성) 2020년 3월 이후로 사람들 보는 게 처음이에요.\n",
      "108350 很多那些成功的男人都不喜歡聽到我說為什麼我不需要男朋友。 네.\n",
      "110284 謝謝 그리고 우리가 다음에 가야 할 길을 방향 잡을 수 있을 것입니다.\n",
      "113692 樹。 ( 긁는 소리) 이렇게 말 야. ( 비트 박스) ( 트럼펫 소리) ( 비트 박스) ( 비트 박스) 기본으로 돌아가. ( 비트 박스) ( 비트 박스) 넌 이 소리를 알아. ( 비트 박스) 소리질러. ( 박수와 환호) ( 휘파람 소리) ( 박수와 환호) 감사합니다.\n",
      "118078 掌聲 감사합니다.\n",
      "118934 這是波普舞。 \"\n",
      "120433 不！ 안돼요!\n",
      "120470 酷！ 오 멋져요.\n",
      "122336 不！ 아니죠!\n",
      "123519 」 ”\n",
      "133673 」 \"\n",
      "136650 」 \"\n",
      "137408 「是的」什麼？ 네.\n",
      "141947 不。 아닙니다.\n",
      "146612 146612 146612 146612\n"
     ]
    }
   ],
   "source": [
    "train_del_idxs = find_delete_indexs(TRAIN_ZSENT,TRAIN_KSENT)\n",
    "TRAIN_ZSENT = delete_indexs_items(TRAIN_ZSENT,train_del_idxs)\n",
    "TRAIN_KSENT = delete_indexs_items(TRAIN_KSENT,train_del_idxs)\n",
    "TRAIN_HSENT = delete_indexs_items(TRAIN_HSENT,train_del_idxs)\n",
    "TRAIN_ZYSENT = delete_indexs_items(TRAIN_ZYSENT,train_del_idxs)\n",
    "print(len(TRAIN_ZSENT),len(TRAIN_KSENT),len(TRAIN_HSENT),len(TRAIN_ZYSENT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3566 」 \"\n",
      "5206 」 \"\n",
      "6312 不。 아닙니다.\n",
      "10187 是的。 네.\n",
      "11109 好。 좋아요.\n",
      "12403 嗨。 안녕하세요?\n",
      "12441 」 ”\n",
      "12901 不！ 아닙니다!\n",
      "15159 謝謝 감사합니다.\n",
      "17733 不。 아닙니다.\n",
      "18956 是的。 네.\n",
      "19868 」 \"\n",
      "22513 好。 좋아요.\n",
      "23679 」 \" 는 말을 요.\n",
      "25285 冰。 얼음이고요.\n",
      "29343 嗨！ 그러니까... 안녕하세요!\n",
      "34778 不。 아니죠.\n",
      "36072 36072 36072 36072\n"
     ]
    }
   ],
   "source": [
    "test_del_idxs = find_delete_indexs(TEST_ZSENT,TEST_KSENT)\n",
    "TEST_ZSENT = delete_indexs_items(TEST_ZSENT,test_del_idxs)\n",
    "TEST_KSENT = delete_indexs_items(TEST_KSENT,test_del_idxs)\n",
    "TEST_HSENT = delete_indexs_items(TEST_HSENT,test_del_idxs)\n",
    "TEST_ZYSENT = delete_indexs_items(TEST_ZYSENT,test_del_idxs)\n",
    "print(len(TEST_ZSENT),len(TEST_KSENT),len(TEST_HSENT),len(TEST_ZYSENT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1716393414638,
     "user": {
      "displayName": "Yeezi",
      "userId": "08687854767328262193"
     },
     "user_tz": -480
    },
    "id": "MDNobIQfJE9Q",
    "outputId": "088c461d-217d-4505-946d-c6269b4d8f5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ㄒㄧㄝˋㄒㄧㄝˋㄉㄚˋㄐㄧㄚ。\n",
      "ㄨㄛˇㄒㄧㄤㄒㄧㄣˋㄖㄨˊㄍㄨㄛˇㄋㄧˇㄍㄟˇㄊㄚㄇㄣ˙ㄓㄥˋㄑㄩㄝˋㄉㄜ˙ㄈㄤㄈㄚˇㄏㄜˊㄍㄨㄥㄐㄩˋ，ㄊㄚㄇㄣ˙ㄎㄜˇㄧˇㄅㄚˇㄕㄢㄉㄡㄓㄨㄢˇㄧˊㄌㄜ˙ㄒㄧㄝˋㄒㄧㄝˋ（ㄍㄨˇㄓㄤˇㄕㄥ）\n"
     ]
    }
   ],
   "source": [
    "print(TRAIN_ZYSENT[0])\n",
    "print(TEST_ZYSENT[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TED2020 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311376\n"
     ]
    }
   ],
   "source": [
    "df_train_transcript = pd.read_csv('./CORPUS/ted2020/TED2020_HANJA_TRAIN_ALL.csv')\n",
    "df_train_transcript = df_train_transcript.to_dict(orient='dict')\n",
    "\n",
    "TRAIN_KSENT = (list(df_train_transcript['KO'].values()))\n",
    "\n",
    "TRAIN_ZSENT = (list(df_train_transcript['ZH'].values()))\n",
    "\n",
    "TRAIN_HSENT = (list(df_train_transcript['HANJA_Z'].values()))\n",
    "\n",
    "print(len(TRAIN_KSENT))\n",
    "df_train_transcript = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77844\n"
     ]
    }
   ],
   "source": [
    "df_test_transcript = pd.read_csv('./CORPUS/ted2020/TED2020_HANJA_TEST_ALL.csv')\n",
    "df_test_transcript = df_test_transcript.to_dict(orient='dict')\n",
    "\n",
    "TEST_KSENT = (list(df_test_transcript['KO'].values()))\n",
    "TEST_ZSENT = (list(df_test_transcript['ZH'].values()))\n",
    "TEST_HSENT = (list(df_test_transcript['HANJA_Z'].values()))\n",
    "#TEST_HSENT = (list(df_test_transcript['HANJA_K'].values()))\n",
    "\n",
    "df_test_transcript = []\n",
    "print(len(TEST_KSENT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311376\n"
     ]
    }
   ],
   "source": [
    "df_train_zhuyin = pd.read_csv('./CORPUS/ted2020/TED2020_TRAIN_ALL_ZHUYIN.csv')\n",
    "df_train_zhuyin = df_train_zhuyin.to_dict(orient='dict')\n",
    "\n",
    "TRAIN_ZYSENT = (list(df_train_zhuyin['zhuyin'].values()))\n",
    "\n",
    "TRAIN_ZYSENT = [str(sent).replace('\\n','') for sent in TRAIN_ZYSENT]\n",
    "\n",
    "df_train_zhuyin = []\n",
    "print(len(TRAIN_ZYSENT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77844\n"
     ]
    }
   ],
   "source": [
    "df_test_zhuyin = pd.read_csv('./CORPUS/ted2020/TED2020_TEST_ALL_ZHUYIN.csv')\n",
    "df_test_zhuyin = df_test_zhuyin.to_dict(orient='dict')\n",
    "\n",
    "TEST_ZYSENT = [str(sent).replace('\\n','') for sent in (list(df_test_zhuyin['zhuyin'].values()))]\n",
    "\n",
    "df_test_transcript = []\n",
    "print(len(TEST_ZYSENT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbBZ0gHTc5S2"
   },
   "source": [
    "# Pretrain Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 7752,
     "status": "ok",
     "timestamp": 1716394130237,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "Ja9cukshN9og"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, BertConfig, BertForPreTraining, AutoModel, BertTokenizerFast\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertConfig, BertForMaskedLM\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yraQyz90_5Wp"
   },
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 251,
     "status": "ok",
     "timestamp": 1716394179356,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "5Y7gzOyzXXgK"
   },
   "outputs": [],
   "source": [
    "# 設定訓練參數\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "max_length = 32\n",
    "#batch_size = 16\n",
    "batch_size = 32\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1716393421962,
     "user": {
      "displayName": "Yeezi",
      "userId": "08687854767328262193"
     },
     "user_tz": -480
    },
    "id": "D4tdbhn-JE9R",
    "outputId": "c54f7236-fa4d-490e-c3b0-2c4922416c19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfN7Zeg0_8zF"
   },
   "source": [
    "## Load Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03Moe-doANbb"
   },
   "source": [
    "### Chinese Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3924,
     "status": "ok",
     "timestamp": 1716394134158,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "Y0b1DUX3aGpx",
    "outputId": "003f1c8d-558f-4535-fa34-507eb5f19a94"
   },
   "outputs": [],
   "source": [
    "#zh_tokenizer = BertTokenizer.from_pretrained('./MODELS/TOKENIZER/new_zh_tokenizer_add_bpmf_korean_tokens_v2') # load bert-base-chinese tokenizer with bpmf、hangul tokens(from 'kykim/bert-kor-base' and konlpy)\n",
    "zh_tokenizer = BertTokenizerFast.from_pretrained('bert-base-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2751\n",
      "zy: 41\n",
      "zy tokens: 2089\n"
     ]
    }
   ],
   "source": [
    "# zhuyin tokens\n",
    "import re\n",
    "zhuyins = ['ㄅ','ㄆ','ㄇ','ㄈ','ㄉ','ㄊ','ㄋ','ㄌ','ㄍ','ㄎ','ㄏ','ㄐ','ㄑ','ㄒ','ㄓ','ㄔ','ㄕ','ㄖ','ㄗ','ㄘ','ㄙ','ㄧ','ㄨ','ㄩ','ㄚ','ㄛ','ㄜ','ㄝ','ㄞ','ㄟ','ㄠ','ㄡ','ㄢ','ㄣ','ㄤ','ㄥ','ㄦ','ˇ','ˋ','ˊ','˙']\n",
    "\n",
    "def check_bpmf_is_not(text):\n",
    "    test_list = ['.*[ㄅㄆㄇㄈㄉㄊㄋㄌㄍㄎㄏㄐㄑㄒㄓㄔㄕㄖㄗㄘㄙㄧㄨㄩㄚㄛㄜㄝㄞㄟㄠㄡㄢㄣㄤㄥㄦˇˋˊ˙]+.*']\n",
    "    for t in test_list:\n",
    "        valid = re.compile(t)\n",
    "        try:\n",
    "            if(valid.match(text) != None):\n",
    "                return True\n",
    "        except:\n",
    "            return False\n",
    "    return False\n",
    "\n",
    "zhuyin_df = pd.read_csv('./CORPUS/TOKEN/zhuyin_tokens_count.csv')\n",
    "zhuyin_df = zhuyin_df.to_dict(orient='dict')\n",
    "zhuyin_tokens = list(zhuyin_df['zhuyin'].values())\n",
    "print(len(zhuyin_tokens))\n",
    "\n",
    "for tok in zhuyin_tokens:\n",
    "  if(check_bpmf_is_not(tok)):\n",
    "    continue\n",
    "  else:\n",
    "    zhuyin_tokens.remove(tok)\n",
    "print('zy:',len(zhuyins))\n",
    "print('zy tokens:',len(zhuyin_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000\n"
     ]
    }
   ],
   "source": [
    "# korean tokens\n",
    "ko_tokenizer = BertTokenizerFast.from_pretrained(\"kykim/bert-kor-base\")\n",
    "ko_tokenizer_tokens = list(ko_tokenizer.get_vocab().keys())\n",
    "print(len(ko_tokenizer_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Length:  21128\n",
      "Add zhuyins:  21146\n",
      "Add zhuyin tokens:  22839\n",
      "Add korean tokens from kykim/bert-kor-base tokenizer:  63662\n"
     ]
    }
   ],
   "source": [
    "# add new tokens\n",
    "zh_tokenizer = BertTokenizerFast.from_pretrained('bert-base-chinese')\n",
    "print('Original Length: ',len(zh_tokenizer))\n",
    "\n",
    "zh_tokenizer.add_tokens(zhuyins)\n",
    "print('Add zhuyins: ',len(zh_tokenizer))\n",
    "\n",
    "zh_tokenizer.add_tokens(zhuyin_tokens)\n",
    "print('Add zhuyin tokens: ',len(zh_tokenizer))\n",
    "\n",
    "zh_tokenizer.add_tokens(ko_tokenizer_tokens)\n",
    "print('Add korean tokens from kykim/bert-kor-base tokenizer: ',len(zh_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257,
     "referenced_widgets": [
      "b22c7a401a2544d5b3e003e4bfc89848",
      "dc692d3bd30846c893969865f28231d5",
      "6a137696522c4a6ca2c8ad9dc7e9acd5",
      "9e5336577baf42f99c498a274e7b4d0c",
      "7fd9db41a1ad42f3b5aff4d361943bb6",
      "30c4c0cd48464741b15fd40e0c450e77",
      "d46cd83f2d084f96ace507dc7873d143",
      "73cfb114ca204454900aa142feedaa47",
      "945d2960866041a7bc653dfe62a40211",
      "c8c65ba734d84a958b11806ef8c45e9c",
      "733616701add43a0b47e2565c67cc277",
      "0adc71bb095f43799268b2919bb13a99",
      "32df952cd1364acdbb0b19240b4adf48",
      "715c99ee56c244d6b9f79384e293333b",
      "76b82f63b5cc49ebbbd4e97ff4820a50",
      "2d912a15a80142c686e2a4d85ee083d3",
      "26327b0bfc984ae0ac60478845121aa0",
      "f9c5eddf3686461280d275049ee72790",
      "84fc974f3f8c40199788427160646b56",
      "4b9dde8db8da4462b28fd0793ceb5d5a",
      "be5bf2d5e1a7442dad9e0439d50579f5",
      "46f1132276e742fb909466adf9d26fe9"
     ]
    },
    "executionInfo": {
     "elapsed": 12778,
     "status": "ok",
     "timestamp": 1716394146930,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "R3Rh8QZkJE9S",
    "outputId": "eebfbbee-3d23-4707-df0a-aaade8a82340"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at ckiplab/bert-base-chinese and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(63662, 768)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zh_bert_model = AutoModel.from_pretrained('ckiplab/bert-base-chinese')\n",
    "zh_bert_model.resize_token_embeddings(len(zh_tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9ipZiyPwmrK"
   },
   "source": [
    "### Korean Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168,
     "referenced_widgets": [
      "720a589cb35d45f4aebf20dd2b73b07f",
      "9858cb49cdc247b1abd923428afb691e",
      "8fb4f3b706b14ed9bd565fa9ec9a6f9e",
      "238e7b4c12d644f9aa05c4f4c593d4cf",
      "d45bef2c5ce5422b8fd150dfb3378562",
      "644aa53bc9a047d1a4938cf9aa3de6e4",
      "759bab7844094ada9fe4d454058e3b3e",
      "0c734c2af04840a3af651a31e0ae33ee",
      "6fc971d8f2f24a62be8f9b3ff4301ba5",
      "da264c4adb1b4347a7a06dab0ce3dd57",
      "918e1783d17e44f79cfd44a9e9e1e009",
      "eee8199ead804a67a93cc1c6adcc7690",
      "7a6208ceae814dc69046c5a7a8f6d9b6",
      "22c2517d14394a4e8f3acd48feec8d56",
      "fc999c62f7f94238becc6229b2169da6",
      "dc0cec054f6947989c810c05bc469ada",
      "6074bfa7ab5145ad91c79fcac9875f3c",
      "6c4a5936add74d4cadffe7e6d9dfba73",
      "5a150d2dafa1478cb605c03ae1b6f11c",
      "7c3c148f9b90423385d516070de18258",
      "14c72a7544d547e19e3b04474ed198c2",
      "d910e33b773b44f1ac0b2461317e25ff",
      "23bacab63696486ca08b8a72ab7f9390",
      "ee853e912fec4f14ad6edacb24cf7f01",
      "8d5911ca7c2241d8a2bdb3a5f77a31e6",
      "ff694afd3f42475fb6829485061c9a72",
      "cfc8e231b76a49b7b7bcb877d5865a34",
      "a072699ae51044d8a72d5c82f8182411",
      "aa571eba262645259e967446753c17bf",
      "9370f273eb4647c4bdeadfe48dcee187",
      "b02773cc93624856906bd903ae3dff37",
      "422d1a5b399e4941bbec1937d5dee18a",
      "9a249264df174c9f8392583b817ff4b3"
     ]
    },
    "executionInfo": {
     "elapsed": 3720,
     "status": "ok",
     "timestamp": 1716393442928,
     "user": {
      "displayName": "Yeezi",
      "userId": "08687854767328262193"
     },
     "user_tz": -480
    },
    "id": "R7TXNOyqwqJa",
    "outputId": "0c02eaf5-e64b-4373-fbed-79bc6114ad4f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "720a589cb35d45f4aebf20dd2b73b07f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/80.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee8199ead804a67a93cc1c6adcc7690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/344k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23bacab63696486ca08b8a72ab7f9390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/725 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ko_tokenizer = BertTokenizerFast.from_pretrained(\"kykim/bert-kor-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bNSH5CeCxvSy"
   },
   "outputs": [],
   "source": [
    "ko_bert_model = BertModel.from_pretrained(\"kykim/bert-kor-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTK4AyyywrIr"
   },
   "source": [
    "### mbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "ecd1452d40544b9f8e824893d8965f80",
      "cd2b767543f1435299935d6dadee5034",
      "14c4da599454480886928b62d789a0d5",
      "b988ec82ad424ae3835dd35d16a568db",
      "0b8c98a0d9b7446396cfbebb7356f676",
      "bc8062ce07204a17ab32b380b3792c1f",
      "ed9e0e610cec4c84aeb24b399e6e55a4",
      "46738251f2a847faaa21f90ce1c8725f",
      "6531766795024285ab5dcb1828072349",
      "d17c9b9a5592452eb4f6944648a2e8ea",
      "56fdffe8b977489b9ec2e5ea8a40edf5",
      "1586223071164a14abc0a26dc6c39df0",
      "66de85187d564d16953e5d45a48466d5",
      "527e76b798d444fb9c088467f8fa9e4c",
      "b4da9eee63a84ad383f189e13a6d0fa9",
      "538dd1ab4c82412b83dee2d6f709f994",
      "134d4d993a884a6e8c4fc86dedb75b21",
      "b6af3a537d524dfd8c48b06001d860b5",
      "611e6c598aa3483bb2c0143f2cd498cd",
      "d8b4b59278814e38a249ff6e7a1b0885",
      "3348d44475c94cb1b98061bfcb53900e",
      "56fd94b10ecc43178e1865f37f5e20e4",
      "926df48f58ae43e0b55924dc10143d60",
      "e1c08ebdce2346a3a9be94d10fb29fb7",
      "34720f0f64834830b1c090e5b86ca5c6",
      "e45bbf5f1ed0479c91c2a5ffd920af56",
      "0563cfc3dc7a4334a53b03abea67bf34",
      "907bc2da70694082b8147f9502c5983f",
      "a4e03bf1e679463ba560517492456925",
      "f3a35087770b400fa5877ce0e6842536",
      "89cac8a78da644598575401b3bd024d9",
      "569fcbc6a1c44d52b64226dbe4d5451e",
      "ad0ea6494ceb48a8ac8a39bca70999d8",
      "e974ba8f861c48aeb8548cab312d758c",
      "0938947be70f49b4a2668b30e45b1aae",
      "2cd96637c2054f7e8489493d5281508c",
      "f802bbfadf5145f3b291cad7a617c4d4",
      "d795e4d7c862477485a2fb3587a801bb",
      "82a629771ba64d33bd22296eea4422c9",
      "f8101c683be54ab8896726653a59bf9f",
      "5db7d093c33b4e2a8082774769259371",
      "bb325f7be9334219a976b70c49578c28",
      "52362e3759cb4b3f808c602671700337",
      "96ea27ef4a594badb71ef41b3d53bec6"
     ]
    },
    "executionInfo": {
     "elapsed": 3065,
     "status": "ok",
     "timestamp": 1716272122631,
     "user": {
      "displayName": "Yeezi",
      "userId": "08687854767328262193"
     },
     "user_tz": -480
    },
    "id": "aacISo-6wteU",
    "outputId": "500742d7-35a6-4ff3-a1d3-e0b1f89026f0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd1452d40544b9f8e824893d8965f80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1586223071164a14abc0a26dc6c39df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926df48f58ae43e0b55924dc10143d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e974ba8f861c48aeb8548cab312d758c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mbert_tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "4696479d8ba840738d9a0bbec847c17b",
      "ed194bf6757a450f96d791fd7e0ecbd0",
      "3bb347ee412446e19040d3499a68a31c",
      "4fc089ca629e46179c17939fa94782bf",
      "1cba16906e3147ecadbc6706de0c39d6",
      "1de1d369d5294e5a85c9916b298fe2f1",
      "700c4a3194f241eaa4ae36b9fa476914",
      "3f5d8280b13f4a86a3604fd8a697a381",
      "dd0d07a703ed49a98f58ec914582192c",
      "32d07b4c240d44f5b7b9894bca42540f",
      "eea8c8d16bc04a93af2aabf6b526728b"
     ]
    },
    "executionInfo": {
     "elapsed": 7147,
     "status": "ok",
     "timestamp": 1716272129777,
     "user": {
      "displayName": "Yeezi",
      "userId": "08687854767328262193"
     },
     "user_tz": -480
    },
    "id": "2wrUUp8jxaBZ",
    "outputId": "f18b446b-170b-4bef-e66c-db9d99a2298c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4696479d8ba840738d9a0bbec847c17b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mbert_model = BertModel.from_pretrained('bert-base-multilingual-cased').to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHItFW4RwxZW"
   },
   "source": [
    "### chinese bert with phonetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kla9x-iJw2p6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1716394146930,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "SvX7R9FNJE9S"
   },
   "outputs": [],
   "source": [
    "my_tokenizer = zh_tokenizer\n",
    "tgt_tokenizer = zh_tokenizer\n",
    "#model_name = 'ZK9_zh_no_hanja_no_zh_v2' # use bert model : my_zh_model train() with dropout\n",
    "#model_name = 'ZK9_zh_no_hanja_no_zh_v3' # use bert model : my_zh_model eval() with dropout\n",
    "#model_name = 'ZK9_zh_no_hanja_no_zh_v4' # use bert model : original model eval() with dropout\n",
    "#model_name = 'TED_ZK9_zh_no_hanja_no_zh' # use bert model : original model train() with dropout\n",
    "model_name = 'ZK9_zh_no_hanja_no_zy' # use bert model : original model train() with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 15.69 GiB of which 40.62 MiB is free. Process 3592193 has 14.13 GiB memory in use. Including non-PyTorch memory, this process has 606.00 MiB memory in use. Of the allocated memory 350.76 MiB is allocated by PyTorch, and 19.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m my_model \u001b[38;5;241m=\u001b[39m zh_bert_model\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#my_model.load_state_dict(torch.load('./MODELS/BERTS/my_zh_model.pth'))\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m my_model \u001b[38;5;241m=\u001b[39m \u001b[43mmy_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#my_model.eval()\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_utils.py:2576\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   2572\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2573\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2574\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2575\u001b[0m         )\n\u001b[0;32m-> 2576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1152\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 802 (3 times)]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:825\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 825\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1150\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 15.69 GiB of which 40.62 MiB is free. Process 3592193 has 14.13 GiB memory in use. Including non-PyTorch memory, this process has 606.00 MiB memory in use. Of the allocated memory 350.76 MiB is allocated by PyTorch, and 19.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "my_model = zh_bert_model\n",
    "#my_model.load_state_dict(torch.load('./MODELS/BERTS/my_zh_model.pth'))\n",
    "my_model = my_model.to(device)\n",
    "#my_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "my_hanja_model = zh_bert_model\n",
    "my_hanja_model = my_hanja_model.to(device)\n",
    "my_hanja_model.load_state_dict(torch.load('./MODELS/BERTS/my_hanja_model.pth'))\n",
    "my_hanja_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "my_bpmf_model = zh_bert_model\n",
    "my_bpmf_model = my_bpmf_model.to(device)\n",
    "my_bpmf_model.load_state_dict(torch.load('./MODELS/BERTS/my_bpmf_model.pth'))\n",
    "my_bpmf_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjK5_xB2CB73"
   },
   "source": [
    "### Get Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2232,
     "status": "ok",
     "timestamp": 1716272302673,
     "user": {
      "displayName": "Yeezi",
      "userId": "08687854767328262193"
     },
     "user_tz": -480
    },
    "id": "o_FjuY2mCE0m",
    "outputId": "0d76ff9e-012a-4b80-b968-c11dfcd7563b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그러다 結局에는 그냥 屈伏下故 末乃 버리綿 적어도 多飮에는 아무 日 없을 거라고 生角하는 持經까지 이르렀습니다. 패배자可 된 느낌이었죠.\n",
      "tensor([[[-1.2058e-01, -1.4019e-01, -7.5852e-01,  ...,  5.7960e-01,\n",
      "           1.4735e-01,  5.7352e-02],\n",
      "         [-6.1292e-01, -7.4539e-01, -8.3502e-02,  ...,  9.6286e-01,\n",
      "           3.0688e-01,  2.5471e-02],\n",
      "         [-4.5489e-01, -6.0978e-01, -3.0158e-01,  ...,  1.0734e+00,\n",
      "           2.0139e-01,  4.8326e-02],\n",
      "         ...,\n",
      "         [ 2.7903e-03, -8.0216e-02, -1.0318e+00,  ...,  5.6032e-01,\n",
      "          -8.0176e-04,  3.7377e-01],\n",
      "         [-1.9213e-01, -3.8575e-01, -6.5699e-01,  ...,  7.4177e-01,\n",
      "          -1.2330e-01,  3.6022e-01],\n",
      "         [-3.7075e-01, -2.1907e-01, -5.3335e-01,  ...,  7.2308e-01,\n",
      "           2.5642e-01,  7.5225e-02]]])\n"
     ]
    }
   ],
   "source": [
    "# 输入文本\n",
    "text = TEST_HSENT[923]\n",
    "print(text)\n",
    "# 使用 mBERT 分词器对文本进行编码\n",
    "inputs = mbert_tokenizer(text, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "\n",
    "# 将输入传递给 mBERT 模型以获取输出\n",
    "with torch.no_grad():\n",
    "    outputs = mbert_model(**inputs)\n",
    "\n",
    "# 提取嵌入\n",
    "embeddings = outputs.last_hidden_state\n",
    "\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 489,
     "status": "ok",
     "timestamp": 1716272552247,
     "user": {
      "displayName": "Yeezi",
      "userId": "08687854767328262193"
     },
     "user_tz": -480
    },
    "id": "oSfAm4BHzDEw",
    "outputId": "8a264096-db37-4a94-cab9-5f4f3b345aa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1994년도義 南 아프리카 共和國義 民主酒蟻路疑 變幻殷 牛李에게 말그대로, 꿈의 實現 이었습니다. \n",
      "tensor([[[ 0.4539, -0.0473, -0.1252,  ..., -0.0150,  0.2754,  0.2246],\n",
      "         [ 0.2028, -0.1798,  0.0435,  ...,  0.7129,  1.1715, -0.2255],\n",
      "         [ 0.2783, -0.8658, -0.4960,  ...,  1.1696,  0.8914,  0.1094],\n",
      "         ...,\n",
      "         [ 0.9248, -0.6796, -0.2644,  ...,  0.6522,  0.7148, -0.1465],\n",
      "         [ 0.5105, -0.3579, -0.0180,  ...,  0.3177,  0.4877,  0.0644],\n",
      "         [ 0.4539, -0.0473, -0.1252,  ..., -0.0150,  0.2754,  0.2246]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# my_zh_model\n",
    "text = TEST_HSENT[923]\n",
    "print(text)\n",
    "# 使用 mBERT 分词器对文本进行编码\n",
    "inputs = zh_tokenizer(text, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "\n",
    "# 将输入传递给 mBERT 模型以获取输出\n",
    "with torch.no_grad():\n",
    "    outputs = my_model(**inputs)\n",
    "\n",
    "# 提取嵌入\n",
    "embeddings = outputs.last_hidden_state\n",
    "\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그러다 結局에는 그냥 屈伏下故 末乃 버리綿 적어도 多飮에는 아무 日 없을 거라고 生角하는 持經까지 이르렀습니다. 패배자可 된 느낌이었죠.\n",
      "tensor([[[ 1.3054e+00, -4.4438e+00, -2.7001e+00,  ..., -1.7835e+00,\n",
      "           5.2322e+00, -3.3590e-03],\n",
      "         [-3.1215e+00, -1.4925e+00, -6.2478e-01,  ...,  2.7746e+00,\n",
      "           3.1170e+00, -3.9944e-02],\n",
      "         [-8.0472e+00,  2.1473e+00, -6.6213e+00,  ...,  1.5663e+00,\n",
      "           3.7195e+00, -5.0157e-02],\n",
      "         ...,\n",
      "         [-5.2369e+00, -4.1304e+00,  8.6563e-01,  ..., -2.1396e+00,\n",
      "           2.4739e+00, -4.3135e-02],\n",
      "         [ 3.7941e-01, -2.1414e+00,  3.5418e+00,  ..., -3.2351e+00,\n",
      "          -1.3752e+00, -4.2022e-02],\n",
      "         [-1.5264e-02, -2.2320e+00,  2.6621e+00,  ...,  3.1985e+00,\n",
      "          -4.9516e+00, -5.2329e-02]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# my_hanja_model\n",
    "text = TEST_HSENT[923]\n",
    "print(text)\n",
    "# 使用 mBERT 分词器对文本进行编码\n",
    "inputs = zh_tokenizer(text, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "\n",
    "# 将输入传递给 mBERT 模型以获取输出\n",
    "with torch.no_grad():\n",
    "    outputs = my_hanja_model(**inputs)\n",
    "\n",
    "# 提取嵌入\n",
    "embeddings = outputs.last_hidden_state\n",
    "\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그러다 結局에는 그냥 屈伏下故 末乃 버리綿 적어도 多飮에는 아무 日 없을 거라고 生角하는 持經까지 이르렀습니다. 패배자可 된 느낌이었죠.\n",
      "tensor([[[ 1.3054e+00, -4.4438e+00, -2.7001e+00,  ..., -1.7835e+00,\n",
      "           5.2322e+00, -3.3590e-03],\n",
      "         [-3.1215e+00, -1.4925e+00, -6.2478e-01,  ...,  2.7746e+00,\n",
      "           3.1170e+00, -3.9944e-02],\n",
      "         [-8.0472e+00,  2.1473e+00, -6.6213e+00,  ...,  1.5663e+00,\n",
      "           3.7195e+00, -5.0157e-02],\n",
      "         ...,\n",
      "         [-5.2369e+00, -4.1304e+00,  8.6563e-01,  ..., -2.1396e+00,\n",
      "           2.4739e+00, -4.3135e-02],\n",
      "         [ 3.7941e-01, -2.1414e+00,  3.5418e+00,  ..., -3.2351e+00,\n",
      "          -1.3752e+00, -4.2022e-02],\n",
      "         [-1.5264e-02, -2.2320e+00,  2.6621e+00,  ...,  3.1985e+00,\n",
      "          -4.9516e+00, -5.2329e-02]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# my_bpmf_model\n",
    "text = TEST_HSENT[923]\n",
    "print(text)\n",
    "# 使用 mBERT 分词器对文本进行编码\n",
    "inputs = zh_tokenizer(text, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "\n",
    "# 将输入传递给 mBERT 模型以获取输出\n",
    "with torch.no_grad():\n",
    "    outputs = my_bpmf_model(**inputs)\n",
    "\n",
    "# 提取嵌入\n",
    "embeddings = outputs.last_hidden_state\n",
    "\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 301,
     "status": "ok",
     "timestamp": 1716272850935,
     "user": {
      "displayName": "Yeezi",
      "userId": "08687854767328262193"
     },
     "user_tz": -480
    },
    "id": "fJvv-q7J0aDG",
    "outputId": "99ed66c9-f5ab-4e73-e15f-f85c3791b3e8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mbert_model\n",
    "print(TEST_ZSENT[923])\n",
    "text = TEST_ZYSENT[923]\n",
    "print(text)\n",
    "# 使用 mBERT 分词器对文本进行编码\n",
    "inputs = mbert_tokenizer(text, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "print(inputs['input_ids'])\n",
    "print(mbert_tokenizer.decode(inputs['input_ids'][0], skip_special_tokens=True))\n",
    "# 将输入传递给 mBERT 模型以获取输出\n",
    "with torch.no_grad():\n",
    "    outputs = mbert_model(**inputs)\n",
    "\n",
    "# 提取嵌入\n",
    "embeddings = outputs.last_hidden_state\n",
    "\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 869,
     "status": "ok",
     "timestamp": 1716272859636,
     "user": {
      "displayName": "Yeezi",
      "userId": "08687854767328262193"
     },
     "user_tz": -480
    },
    "id": "eaAMxEeQ0cxY",
    "outputId": "3dd73a76-2319-41b4-bb12-f80f0e983eac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "到最後我覺得，乾脆屈服熬過去，至少到下次再發生前我能得到點平靜。\n",
      "ㄉㄠˋㄗㄨㄟˋㄏㄡˋㄨㄛˇㄐㄩㄝˊㄉㄜ˙，ㄍㄢㄘㄨㄟˋㄑㄩㄈㄨˊㄠˊㄍㄨㄛˋㄑㄩˋ，ㄓˋㄕㄠˇㄉㄠˋㄒㄧㄚˋㄘˋㄗㄞˋㄈㄚㄕㄥㄑㄧㄢˊㄨㄛˇㄋㄥˊㄉㄜ˙ㄉㄠˋㄉㄧㄢˇㄆㄧㄥˊㄐㄧㄥˋ。\n",
      "tensor([[  101, 21212, 21314, 21222, 21160, 21298, 21178,  8024, 21847, 21669,\n",
      "         21683, 21566, 22097, 21245, 21282,  8024, 21248, 21326, 21212, 21250,\n",
      "         21176, 21159, 21463, 21158, 21164, 21160, 21293, 21178, 21212, 21330,\n",
      "         21347, 21360,   511,   102]], device='cuda:0')\n",
      "ㄉㄠˋ ㄗㄨㄟˋ ㄏㄡˋ ㄨㄛˇ ㄐㄩㄝˊ ㄉㄜ˙ ， ㄍㄢ ㄘㄨㄟˋ ㄑㄩ ㄈㄨˊ ㄠˊ ㄍㄨㄛˋ ㄑㄩˋ ， ㄓˋ ㄕㄠˇ ㄉㄠˋ ㄒㄧㄚˋ ㄘˋ ㄗㄞˋ ㄈㄚ ㄕㄥ ㄑㄧㄢˊ ㄨㄛˇ ㄋㄥˊ ㄉㄜ˙ ㄉㄠˋ ㄉㄧㄢˇ ㄆㄧㄥˊ ㄐㄧㄥˋ 。\n",
      "tensor([[[ 1.0444,  0.4776, -0.3137,  ...,  0.0884,  0.1758,  0.2491],\n",
      "         [ 0.0394,  0.7345, -0.6138,  ...,  0.5273,  0.5974, -0.1578],\n",
      "         [ 0.6699,  0.8073, -0.6991,  ...,  1.1291,  0.5514, -0.5418],\n",
      "         ...,\n",
      "         [ 0.0758,  0.1053, -0.7919,  ...,  1.0411,  0.2645, -0.2673],\n",
      "         [ 0.3935,  0.5438,  0.7982,  ...,  0.5464, -0.4632,  0.2710],\n",
      "         [ 1.0444,  0.4776, -0.3137,  ...,  0.0884,  0.1758,  0.2491]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# 输入文本\n",
    "print(TEST_ZSENT[923])\n",
    "text = TEST_ZYSENT[923]\n",
    "print(text)\n",
    "# 使用 mBERT 分词器对文本进行编码\n",
    "inputs = zh_tokenizer(text, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "print(inputs['input_ids'])\n",
    "print(zh_tokenizer.decode(inputs['input_ids'][0], skip_special_tokens=True))\n",
    "\n",
    "# 将输入传递给 mBERT 模型以获取输出\n",
    "with torch.no_grad():\n",
    "    outputs = my_model(**inputs)\n",
    "\n",
    "# 提取嵌入\n",
    "embeddings = outputs.last_hidden_state\n",
    "\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zb2zO0JdJE9T"
   },
   "source": [
    "### Build Dataset Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1716394146930,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "MbMhr_ytXkPR"
   },
   "outputs": [],
   "source": [
    "# 假設您有一個平行語料庫，這是您的資料集\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, source_sentences, target_sentences):\n",
    "        self.source_sentences = source_sentences\n",
    "        self.target_sentences = target_sentences\n",
    "        self.length = len(source_sentences)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        source = self.source_sentences[index]\n",
    "        target = self.target_sentences[index]\n",
    "        \n",
    "        source_token = my_tokenizer(source, padding='max_length', truncation=True, return_tensors='pt', max_length=max_length)\n",
    "        target_token = tgt_tokenizer(target, padding='max_length', truncation=True, return_tensors='pt', max_length=max_length)\n",
    "\n",
    "        \n",
    "        \n",
    "        #print(index)\n",
    "        return source, target, source_token, target_token\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sm6_jekZJE9T"
   },
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1716394146930,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "Gl5SJr3J3F4W"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 247,
     "status": "ok",
     "timestamp": 1716394156152,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "zMHdA6GxJE9T"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "class TranslationModel(nn.Module):\n",
    "    def __init__(self, bert_model, dropout_prob=0.1):\n",
    "        super(TranslationModel, self).__init__()\n",
    "        self.bert1 = bert_model\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)\n",
    "        self.linear = nn.Linear(self.bert1.config.hidden_size, len(tgt_tokenizer))\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        zh_outputs = self.bert1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Apply dropout\n",
    "        zh_outputs = self.dropout1(zh_outputs.last_hidden_state)\n",
    "        prediction_scores = self.linear(zh_outputs)\n",
    "        return prediction_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationModel(nn.Module):\n",
    "    def __init__(self, bert_model, dropout_prob=0.1):\n",
    "        super(TranslationModel, self).__init__()\n",
    "        self.bert1 = bert_model\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)\n",
    "        #self.linear = nn.Linear(self.bert1.config.hidden_size, len(tgt_tokenizer))\n",
    "        self.linear = nn.Linear(my_model.config.hidden_size, len(tgt_tokenizer))\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        zh_outputs = self.bert1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        #zh_outputs = my_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Apply dropout\n",
    "        zh_outputs = self.dropout1(zh_outputs.last_hidden_state)\n",
    "        prediction_scores = self.linear(zh_outputs)\n",
    "        return prediction_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GGVsQ3zAJE9U"
   },
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 268,
     "status": "ok",
     "timestamp": 1716394188834,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "3H9KG4_lXpgg"
   },
   "outputs": [],
   "source": [
    "# 載入資料集\n",
    "train_source_sentences = TRAIN_ZSENT  # 中文句子\n",
    "train_target_sentences = TRAIN_KSENT  # 韓文句子\n",
    "dataset = TranslationDataset(train_source_sentences, train_target_sentences)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 248,
     "status": "ok",
     "timestamp": 1716394192120,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "3YKuaojTXr37"
   },
   "outputs": [],
   "source": [
    "test_source_sentences = TEST_ZSENT  # 中文句子\n",
    "test_target_sentences = TEST_KSENT  # 韓文句子\n",
    "test_dataset = TranslationDataset(test_source_sentences, test_target_sentences)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 256,
     "status": "ok",
     "timestamp": 1716394193455,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "jtGKPrM2N_u-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 m 25.568806648254395 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for batch in dataloader:\n",
    "        source, target, source_tokens, target_tokens  = batch\n",
    "end = time.time()\n",
    "print(int((end-start)/60),'m',(end-start)%60,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 245,
     "status": "ok",
     "timestamp": 1716394193698,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "uzfwsZmhR18j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 m 6.2127768993377686 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for batch in test_dataloader:\n",
    "        source, target, source_tokens, target_tokens  = batch\n",
    "end = time.time()\n",
    "print(int((end-start)/60),'m',(end-start)%60,'s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELC5MJCTJE9U"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 2358,
     "status": "ok",
     "timestamp": 1716402639332,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "m1SBesmJXuch"
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 15.69 GiB of which 40.62 MiB is free. Process 3592193 has 14.13 GiB memory in use. Including non-PyTorch memory, this process has 606.00 MiB memory in use. Of the allocated memory 350.76 MiB is allocated by PyTorch, and 19.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 初始化模型、損失函數和優化器\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mTranslationModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_model\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m      4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1152\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 802 (4 times)]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:825\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 825\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1150\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 15.69 GiB of which 40.62 MiB is free. Process 3592193 has 14.13 GiB memory in use. Including non-PyTorch memory, this process has 606.00 MiB memory in use. Of the allocated memory 350.76 MiB is allocated by PyTorch, and 19.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# 初始化模型、損失函數和優化器\n",
    "model = TranslationModel(my_model).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "executionInfo": {
     "elapsed": 515,
     "status": "error",
     "timestamp": 1716389322122,
     "user": {
      "displayName": "Yeezi",
      "userId": "08687854767328262193"
     },
     "user_tz": -480
    },
    "id": "elaXMMHpVltP",
    "outputId": "86357027-cf15-4636-853a-88aaebd7dbbf"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/ZH-KO-TRANSLATOR/MODELS/best_translation_model(ZK9_only_zh_add_hanja&zy_token).pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-1bc34faea862>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 加載訓練好的模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#model = TranslationModel(model_mbert).to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/ZH-KO-TRANSLATOR/MODELS/best_translation_model({}).pth'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    998\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/ZH-KO-TRANSLATOR/MODELS/best_translation_model(ZK9_only_zh_add_hanja&zy_token).pth'"
     ]
    }
   ],
   "source": [
    "# 加載訓練好的模型\n",
    "#model = TranslationModel(model_mbert).to(device)\n",
    "model.load_state_dict(torch.load('./MODELS/best_translation_model({}).pth'.format(model_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOyyXyBJJE9U"
   },
   "source": [
    "### Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 391,
     "status": "ok",
     "timestamp": 1716394204800,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "ocuLcuL6Wz1f"
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "  elapsed_time = end_time - start_time\n",
    "  elapsed_mins = int(elapsed_time/60)\n",
    "  elapsed_secs = int(elapsed_time%60)\n",
    "  return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6366,
     "status": "ok",
     "timestamp": 1716394211618,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "1ol6KlEOdYkY",
    "outputId": "00958826-12c2-47b2-d197-014237482bfc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in /home/jiazhen/.local/lib/python3.8/site-packages (4.66.2)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: python-debian 0.1.43ubuntu1 has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of python-debian or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1716394211618,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "rYYDgn6coBWc"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 352,
     "status": "ok",
     "timestamp": 1716402643886,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "Qe1AC6QZXGku"
   },
   "outputs": [],
   "source": [
    "def train(path):\n",
    "    global model, dataloader, optimizer, criterion, my_tokenizer, tgt_tokenizer\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    with tqdm(total = len(dataloader)) as pbar:\n",
    "      for batch in dataloader:\n",
    "        source_batch, target_batch, source_tokens, target_tokens  = batch\n",
    "        #print('source_tokens',source_tokens.input_ids.permute(1,0,2)[0].size())\n",
    "          \n",
    "        source_tokens_ids = source_tokens.input_ids.permute(1,0,2)[0].to(device)\n",
    "        source_tokens_attns = source_tokens.attention_mask.permute(1,0,2)[0].to(device)\n",
    "        target_tokens_ids = target_tokens.input_ids.permute(1,0,2)[0].to(device)\n",
    "          \n",
    "        #target_tokens_attns = target_tokens.to(device)\n",
    "        #source_tokens = my_tokenizer(source_batch, padding='max_length', truncation=True, return_tensors='pt', max_length=max_length).to(device)\n",
    "        #target_tokens = tgt_tokenizer(target_batch, padding='max_length', truncation=True, return_tensors='pt', max_length=max_length).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input_ids=source_tokens_ids,\n",
    "                       attention_mask=source_tokens_attns)\n",
    "\n",
    "\n",
    "        loss = criterion(output.transpose(1, 2), target_tokens_ids)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        pbar.update(1)\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "    return total_loss/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1716402644591,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "-YtHhdmNXJFo"
   },
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "  global model, test_dataloader, criterion, my_tokenizer, tgt_tokenizer\n",
    "  model.eval()\n",
    "  total_loss = 0\n",
    "  with torch.no_grad():\n",
    "    with tqdm(total = len(test_dataloader)) as pbar:\n",
    "      for batch in test_dataloader:\n",
    "        source_batch, target_batch, source_tokens, target_tokens  = batch\n",
    "        source_tokens_ids = source_tokens.input_ids.permute(1,0,2)[0].to(device)\n",
    "        source_tokens_attns = source_tokens.attention_mask.permute(1,0,2)[0].to(device)\n",
    "        target_tokens_ids = target_tokens.input_ids.permute(1,0,2)[0].to(device)\n",
    "        #source_tokens = my_tokenizer(source_batch, padding='max_length', truncation=True, return_tensors='pt', max_length=max_length).to(device)\n",
    "        #target_tokens = tgt_tokenizer(target_batch, padding='max_length', truncation=True, return_tensors='pt', max_length=max_length).to(device)\n",
    "\n",
    "        output = model(input_ids=source_tokens_ids, attention_mask=source_tokens_attns)\n",
    "        loss = criterion(output.transpose(1, 2), target_tokens_ids)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        pbar.update(1)\n",
    "\n",
    "  return total_loss/len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1716394212039,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "sq9krtvnXM8c"
   },
   "outputs": [],
   "source": [
    "def loss_history(train_loss_values, test_loss_values, path='', to_show=False):\n",
    "  before_train_loss = []\n",
    "  before_test_loss = []\n",
    "  try:\n",
    "    df_loss = pd.read_csv('./MODELS/LOSS_HISTORY/loss_plot_{}.csv'.format(path))\n",
    "    df_loss.to_dict(orient='dict')\n",
    "\n",
    "    try:\n",
    "      before_train_loss = list(df_loss['TRAIN_LOSS'].values())\n",
    "      before_test_loss = list(df_loss['TEST_LOSS'].values())\n",
    "    except:\n",
    "      before_train_loss = list(df_loss['TRAIN_LOSS'])\n",
    "      before_test_loss = list(df_loss['TEST_LOSS'])\n",
    "\n",
    "\n",
    "  except:\n",
    "    before_train_loss = []\n",
    "    before_test_loss = []\n",
    "\n",
    "  if(len(before_train_loss)>0):\n",
    "    train_loss_values = before_train_loss + train_loss_values\n",
    "    test_loss_values = before_test_loss + test_loss_values\n",
    "\n",
    "  # 假設您有每個 epoch 的索引\n",
    "  epochs = range(1, len(train_loss_values) + 1)\n",
    "  plt.clf()\n",
    "\n",
    "  # 繪製訓練損失和測試損失的折線圖\n",
    "  plt.plot(epochs, train_loss_values, 'b', label='Training loss')\n",
    "  plt.plot(epochs, test_loss_values, 'r', label='Test loss')\n",
    "  plt.title('Training and Test Loss')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.legend()\n",
    "\n",
    "  # 儲存折線圖\n",
    "  plt.savefig('./MODELS/LOSS_HISTORY/loss_plot_{}.png'.format(path))\n",
    "  if to_show:\n",
    "    plt.show()\n",
    "\n",
    "  df_loss = pd.DataFrame({'TRAIN_LOSS':train_loss_values,'TEST_LOSS':test_loss_values})\n",
    "  df_loss.to_csv('./MODELS/LOSS_HISTORY/loss_plot_{}.csv'.format(path),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1716394212039,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "bB31rAi_z0AT"
   },
   "outputs": [],
   "source": [
    "def bleu_history(bleu_score_values, path='', to_show=False):\n",
    "  before_bleu_score = []\n",
    "  try:\n",
    "    df_loss = pd.read_csv('./MODELS/LOSS_HISTORY/blue_plot_{}.csv'.format(path))\n",
    "    df_loss.to_dict(orient='dict')\n",
    "\n",
    "    try:\n",
    "      before_bleu_score = list(df_loss['BLEU_SCORE'].values())\n",
    "    except:\n",
    "      before_bleu_score = list(df_loss['BLEU_SCORE'])\n",
    "\n",
    "\n",
    "  except:\n",
    "    before_bleu_score = []\n",
    "\n",
    "  if(len(before_bleu_score)>0):\n",
    "    bleu_score_values = before_bleu_score + bleu_score_values\n",
    "\n",
    "  # 假設您有每個 epoch 的索引\n",
    "  epochs = range(1, len(bleu_score_values) + 1)\n",
    "  plt.clf()\n",
    "\n",
    "  # 繪製訓練損失和測試損失的折線圖\n",
    "  plt.plot(epochs, bleu_score_values, 'b', label='BLEU score')\n",
    "  plt.title('BLEU SCORE')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel('Score')\n",
    "  plt.legend()\n",
    "\n",
    "  # 儲存折線圖\n",
    "  plt.savefig('./MODELS/LOSS_HISTORY/blue_plot_{}.png'.format(path))\n",
    "  if to_show:\n",
    "    plt.show()\n",
    "\n",
    "  df_loss = pd.DataFrame({'BLEU_SCORE':bleu_score_values})\n",
    "  df_loss.to_csv('./MODELS/LOSS_HISTORY/blue_plot_{}.csv'.format(path),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 1452,
     "status": "ok",
     "timestamp": 1716394213489,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "GBwPiLJg75AY"
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "def bleu_score():\n",
    "  global my_tokenizer, test_target_sentences, model, max_length, device\n",
    "  model.eval()\n",
    "  # 生成目標語句\n",
    "  generated_sentences = []\n",
    "  with tqdm(total = len(test_source_sentences)) as pbar:\n",
    "    for source_sentence in test_source_sentences:\n",
    "      source_tokens = my_tokenizer(source_sentence, padding=True, truncation=True, return_tensors='pt', max_length=max_length).to(device)\n",
    "      with torch.no_grad():\n",
    "        output = model(input_ids=source_tokens.input_ids, attention_mask=source_tokens.attention_mask)\n",
    "      generated_sentence = my_tokenizer.decode(output[0].argmax(dim=-1), skip_special_tokens=True)\n",
    "      generated_sentences.append(generated_sentence)\n",
    "      pbar.update(1)\n",
    "\n",
    "\n",
    "  # 計算 BLEU 分數\n",
    "  smoothie = SmoothingFunction().method4\n",
    "  bleu_score = corpus_bleu([[ref] for ref in test_target_sentences], generated_sentences, smoothing_function=smoothie)\n",
    "\n",
    "  #print(\"BLEU 分數:\", bleu_score)\n",
    "  return bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7136,
     "status": "ok",
     "timestamp": 1716394220622,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "fcwPgTFdKB-e",
    "outputId": "97acc58c-7d6e-4bef-aedf-c2c556cb0769"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sacrebleu in /home/jiazhen/.local/lib/python3.8/site-packages (2.4.2)\n",
      "Requirement already satisfied: portalocker in /home/jiazhen/.local/lib/python3.8/site-packages (from sacrebleu) (2.8.2)\n",
      "Requirement already satisfied: regex in /home/jiazhen/.local/lib/python3.8/site-packages (from sacrebleu) (2023.12.25)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /home/jiazhen/.local/lib/python3.8/site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/jiazhen/.local/lib/python3.8/site-packages (from sacrebleu) (1.24.4)\n",
      "Requirement already satisfied: colorama in /usr/lib/python3/dist-packages (from sacrebleu) (0.4.4)\n",
      "Requirement already satisfied: lxml in /home/jiazhen/.local/lib/python3.8/site-packages (from sacrebleu) (5.2.1)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: python-debian 0.1.43ubuntu1 has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of python-debian or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 262,
     "status": "ok",
     "timestamp": 1716395870576,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "d6UfjjgfJE9a"
   },
   "outputs": [],
   "source": [
    "from sacrebleu.metrics import BLEU\n",
    "\n",
    "def sacrebleu_score(model, source_sentences,target_sentences,lang='ko'):\n",
    "  global my_tokenizer, tgt_tokenizer, max_length, device\n",
    "  model.eval()\n",
    "  bleu = BLEU()\n",
    "  bleu.trg_lang = lang\n",
    "  avg_score = {'avg':0,'1-gram':0,'2-gram':0,'3-gram':0,'4-gram':0}\n",
    "\n",
    "  # 生成目標語句\n",
    "  generated_sentences = []\n",
    "  with tqdm(total = len(source_sentences)) as pbar:\n",
    "    for i in range(len(source_sentences)):\n",
    "        source_sentence = source_sentences[i]\n",
    "        target_sentence = target_sentences[i]\n",
    "\n",
    "        source_tokens = my_tokenizer(source_sentence, padding='max_length', truncation=True, return_tensors='pt', max_length=max_length).to(device)\n",
    "        #print('source_tokens',source_tokens.input_ids)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(input_ids=source_tokens.input_ids,\n",
    "                           attention_mask=source_tokens.attention_mask)\n",
    "        generated_sentence = tgt_tokenizer.decode(output[0].argmax(dim=-1), skip_special_tokens=True)\n",
    "        gen_sent = ''\n",
    "        for sent in generated_sentence:\n",
    "            gen_sent += sent\n",
    "        generated_sentences.append(gen_sent)\n",
    "        if(i > len(source_sentences)-5):\n",
    "        #if(1):\n",
    "            print('i=',i,'='*20)\n",
    "            print('target_sentence',target_sentence)\n",
    "            print('generate:',generated_sentence)\n",
    "            print('output',output)\n",
    "            print('='*20)\n",
    "            \n",
    "        pbar.update(1)\n",
    "        '''\n",
    "        bleu_score = bleu.corpus_score([gen_sent],[[target_sentence]])\n",
    "        #print([gen_sent],[[target_sentence]])\n",
    "        #print(bleu_score)\n",
    "        avg_score['avg'] += bleu_score.score\n",
    "        avg_score['1-gram'] += bleu_score.precisions[0]\n",
    "        avg_score['2-gram'] += bleu_score.precisions[1]\n",
    "        avg_score['3-gram'] += bleu_score.precisions[2]\n",
    "        avg_score['4-gram'] += bleu_score.precisions[3]\n",
    "  avg_score['avg'] /= len(source_sentences)\n",
    "  avg_score['1-gram'] /= len(source_sentences)\n",
    "  avg_score['2-gram'] /= len(source_sentences)\n",
    "  avg_score['3-gram'] /= len(source_sentences)\n",
    "  avg_score['4-gram'] /= len(source_sentences)\n",
    "  '''\n",
    "    target_sentences = [[ref] for ref in target_sentences]\n",
    "    bleu_score = bleu.corpus_score(generated_sentences, target_sentences)\n",
    "    avg_score['avg'] = bleu_score.score\n",
    "    avg_score['1-gram'] = bleu_score.precisions[0]\n",
    "    avg_score['2-gram'] = bleu_score.precisions[1]\n",
    "    avg_score['3-gram'] = bleu_score.precisions[2]\n",
    "    avg_score['4-gram'] = bleu_score.precisions[3]\n",
    "\n",
    "  #print('gen:',generated_sentences,'tar:',[[sent] for sent in target_sentences],'sor',source_sentences)\n",
    "  #print('BLEU Score:',bleu.score)\n",
    "\n",
    "  return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1716394221065,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "gEPWbiT4v9ru"
   },
   "outputs": [],
   "source": [
    "def sacrebleu_history(bleu_score_values, path=model_name, to_show=False):\n",
    "  before_avg_score = {}\n",
    "  bleu_score_values = bleu_score_values[0]\n",
    "  tag = ['avg','1-gram','2-gram','3-gram','4-gram']\n",
    "  for key in tag:\n",
    "    bleu_score_values[key] = [bleu_score_values[key]]\n",
    "\n",
    "  try:\n",
    "    df_loss = pd.read_csv('./MODELS/LOSS_HISTORY/sacreblue_plot_{}.csv'.format(path))\n",
    "    df_loss.to_dict(orient='dict')\n",
    "    try:\n",
    "        for key in tag:\n",
    "            before_avg_score[key] = list(df_loss[key].values())\n",
    "    except:\n",
    "        for key in tag:\n",
    "            before_avg_score[key] = list(df_loss[key])\n",
    "\n",
    "\n",
    "  except:\n",
    "        for key in tag:\n",
    "            before_avg_score[key] = []\n",
    "\n",
    "  if(len(before_avg_score[tag[0]])>0):\n",
    "        for key in tag:\n",
    "            bleu_score_values[key] = before_avg_score[key] + bleu_score_values[key]\n",
    "  print(bleu_score_values)\n",
    "  # 假設您有每個 epoch 的索引\n",
    "  try:\n",
    "      epochs = range(1, len(bleu_score_values[tag[0]]) + 1)\n",
    "  except:\n",
    "      epochs = range(1,2)\n",
    "  plt.clf()\n",
    "\n",
    "  # 繪製訓練損失和測試損失的折線圖\n",
    "  for key in tag:\n",
    "        try:\n",
    "            plt.plot(epochs, bleu_score_values[key], label=key)\n",
    "        except:\n",
    "            plt.plot(epochs, list(bleu_score_values[key]), label=key)\n",
    "  plt.title('BLEU SCORE')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel('Score')\n",
    "  plt.legend()\n",
    "\n",
    "  # 儲存折線圖\n",
    "  plt.savefig('./MODELS/LOSS_HISTORY/sacreblue_plot_{}.png'.format(path))\n",
    "  if to_show:\n",
    "    plt.show()\n",
    "\n",
    "  df_loss = pd.DataFrame(bleu_score_values)\n",
    "  df_loss.to_csv('./MODELS/LOSS_HISTORY/sacreblue_plot_{}.csv'.format(path),index=False)\n",
    "  df_loss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def get_samples(src_list,tgt_list,keys=['zh','ko'],num=2000):\n",
    "    samples = {}\n",
    "    for k in keys:\n",
    "        samples[k] = []\n",
    "    randomlist = random.sample(range(0, len(src_list)), num)\n",
    "    #print(randomlist[50:55])\n",
    "    for i in randomlist:\n",
    "        samples['zh'].append(src_list[i])\n",
    "        samples['ko'].append(tgt_list[i])\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉| 77835/77844 [06:37<00:00, 193.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 77840 ====================\n",
      "target_sentence 팀 멤버와 코칭 스태프, 서포트 스태프 스포츠 심리학자들도 있었는데, 케이틀린이 아주 분명하게, 미안한 기색도 없이 말했어요. \"저는 더 이상 잘하고 싶지 않아요\" \n",
      "generate: 팀 팀의 팀의 코치 팀 팀 팀 팀 단체 팀을 그리고 쳤 스카 다 가 너 에, 과 스트 카 였 니.,...\n",
      "output tensor([[[ -4.3113, -27.4764, -28.2549,  ..., -20.2170, -27.8947, -27.9214],\n",
      "         [ -1.0162, -18.7226, -17.4484,  ..., -13.8740, -19.0492, -18.9432],\n",
      "         [ -0.2534, -10.7807, -10.8776,  ...,  -9.9903, -10.5387, -10.9237],\n",
      "         ...,\n",
      "         [  4.5918, -15.0454, -14.8095,  ...,  -5.3504, -14.8372, -14.1309],\n",
      "         [  5.1148, -15.2266, -14.9700,  ...,  -7.7341, -14.7210, -14.0702],\n",
      "         [ 16.8036, -18.5880, -18.6337,  ...,  -9.1841, -18.5809, -18.8052]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 77841 ====================\n",
      "target_sentence 국가 차원에서 이것을 계산하는 것은 한 측면이고 이미 시작되었어요. \n",
      "generate: 각각의 수치를 모든 이 계산 계산 시작합니다 시작합니다 시작합니다\n",
      "output tensor([[[ -0.8942, -30.1720, -31.0259,  ..., -24.2228, -30.3872, -30.0668],\n",
      "         [ -2.8886, -18.2915, -18.2290,  ..., -10.4238, -18.4989, -18.1885],\n",
      "         [ -3.5970, -20.2341, -20.4066,  ..., -14.3079, -20.7411, -19.8936],\n",
      "         ...,\n",
      "         [ 18.5506, -26.4081, -26.2114,  ..., -17.4376, -26.5223, -26.6453],\n",
      "         [ 18.2846, -27.0911, -26.7351,  ..., -17.5225, -27.1571, -27.2635],\n",
      "         [ 18.5743, -28.7425, -28.1185,  ..., -17.5224, -28.6585, -28.7623]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 77842 ====================\n",
      "target_sentence 어미 오리는 행복하게 새끼들이 나오는 걸 지켜봤어요. \n",
      "generate: 기쁨 기쁨 토 을 한 한 갑자기 번 번 번 보았습니다 보았습니다\n",
      "output tensor([[[ -1.9194, -28.9979, -30.1719,  ..., -22.5329, -29.2286, -29.5227],\n",
      "         [ -2.2589, -19.5110, -19.0512,  ...,  -9.8815, -19.3660, -19.1417],\n",
      "         [  0.4050, -13.5262, -13.5648,  ..., -12.5298, -13.1870, -13.0728],\n",
      "         ...,\n",
      "         [ 19.3306, -27.3590, -27.3022,  ..., -18.7852, -26.9932, -27.4586],\n",
      "         [ 18.4632, -28.6575, -28.4971,  ..., -18.4337, -28.3820, -28.5905],\n",
      "         [ 20.1905, -30.0996, -29.8460,  ..., -17.9805, -29.8460, -30.0767]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 77843 ====================\n",
      "target_sentence 이렇게 모든 것이 훌륭한데, 별안간 자동차가 덜그럭거리더니 고속도로 한복판에서 멈춰버리고 맙니다. \n",
      "generate: 모든게 잘 잘 잘... 갑자기 도로 도로 운전 도로 차에 차 차 차 도로 가. 가. 자동차 교통 교통. 교통 영향을..\n",
      "output tensor([[[ -1.5502, -27.9301, -29.1371,  ..., -22.7013, -28.3035, -28.4880],\n",
      "         [ -0.4371, -17.6838, -17.2695,  ..., -14.6378, -17.3010, -17.3656],\n",
      "         [ -1.1439, -19.5241, -19.5015,  ..., -16.9530, -19.4502, -18.6114],\n",
      "         ...,\n",
      "         [  2.1838, -19.5808, -20.5907,  ..., -14.5461, -19.8172, -19.4845],\n",
      "         [  4.0834, -20.5647, -20.6913,  ..., -14.0158, -20.7907, -19.7024],\n",
      "         [ 15.6977, -22.5977, -23.1249,  ..., -13.8401, -22.5581, -22.6244]]],\n",
      "       device='cuda:0')\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 77844/77844 [06:45<00:00, 192.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Time: 6m 45s\n",
      "\tBLEU Score:\n",
      "\t\tavg: 1.004\n",
      "\t\t1-gram: 14.182\n",
      "\t\t2-gram: 1.458\n",
      "\t\t3-gram: 0.436\n",
      "\t\t4-gram: 0.113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "samples = get_samples(TEST_ZSENT,TEST_KSENT,num=10)\n",
    "#test_score = sacrebleu_score(model, source_sentences=samples['zh'],target_sentences=samples['ko'])\n",
    "test_score = sacrebleu_score(model, source_sentences=TEST_ZSENT,target_sentences=TEST_KSENT)\n",
    "end_time = time.time()\n",
    "epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "print(f'Eval Time: {epoch_mins}m {epoch_secs}s')\n",
    "    \n",
    "print('\\tBLEU Score:')\n",
    "for k in test_score.keys():\n",
    "    print('\\t\\t{}: {:.3f}'.format(k,test_score[k]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6156,
     "status": "ok",
     "timestamp": 1716280529343,
     "user": {
      "displayName": "Yeezi",
      "userId": "08687854767328262193"
     },
     "user_tz": -480
    },
    "id": "YlalwXt-JE9a",
    "outputId": "b678a64e-9818-4627-ab27-5bda2b4b387e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TNhmOInxzxmc"
   },
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "def rouge_score():\n",
    "  global my_tokenizer, test_target_sentences, model, max_length, device\n",
    "  total_score = 0\n",
    "  model.eval()\n",
    "  # 生成目標語句\n",
    "  generated_sentences = []\n",
    "  rouge = Rouge()\n",
    "  with tqdm(total = len(test_source_sentences)) as pbar:\n",
    "    for i in range(len(test_source_sentences)):\n",
    "      source_tokens = my_tokenizer(test_source_sentences[i], padding=True, truncation=True, return_tensors='pt', max_length=max_length).to(device)\n",
    "      with torch.no_grad():\n",
    "        output = model(input_ids=source_tokens.input_ids, attention_mask=source_tokens.attention_mask)\n",
    "      generated_sentence = my_tokenizer.decode(output[0].argmax(dim=-1), skip_special_tokens=True)\n",
    "      try:\n",
    "        scores = rouge.get_scores(generated_sentences, test_target_sentences[i])\n",
    "      except:\n",
    "        scores = 0\n",
    "      print(generated_sentences)\n",
    "      print(test_target_sentences[i])\n",
    "      #print(generated_sentence)\n",
    "      #for metric, score in scores.items():\n",
    "      #  print(f\"{metric}: {score}\")\n",
    "      total_score += scores\n",
    "      pbar.update(1)\n",
    "\n",
    "  avg_score = float(total_score)/len(test_source_sentences)\n",
    "  print('Rouge Score:',avg_score)\n",
    "  return avg_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aIja_lfmJE9a"
   },
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35040,
     "status": "ok",
     "timestamp": 1716394256103,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "p5zyKLudJE9b",
    "outputId": "6371a60d-6483-4159-9f79-da89bff69fcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Downloading wandb-0.17.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-2.2.1-py2.py3-none-any.whl (281 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.6/281.6 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\n",
      "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.2.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.17.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade protobuf\n",
    "!pip install wandb\n",
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "executionInfo": {
     "elapsed": 8448,
     "status": "ok",
     "timestamp": 1716394270865,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "DEvaaVA55kgT",
    "outputId": "1324f615-89f9-4d2b-a45f-d73c3df70587"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjiazhen_li\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jiazhen/my-study/wandb/run-20240529_234619-my_TED_ZK9_zh_no_hanja_no_zh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/jiazhen_li/Chinese-Korean-Translation/runs/my_TED_ZK9_zh_no_hanja_no_zh' target=\"_blank\">TED_ZK9_zh_no_hanja_no_zh</a></strong> to <a href='https://wandb.ai/jiazhen_li/Chinese-Korean-Translation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jiazhen_li/Chinese-Korean-Translation' target=\"_blank\">https://wandb.ai/jiazhen_li/Chinese-Korean-Translation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jiazhen_li/Chinese-Korean-Translation/runs/my_TED_ZK9_zh_no_hanja_no_zh' target=\"_blank\">https://wandb.ai/jiazhen_li/Chinese-Korean-Translation/runs/my_TED_ZK9_zh_no_hanja_no_zh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/jiazhen_li/Chinese-Korean-Translation/runs/my_TED_ZK9_zh_no_hanja_no_zh?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fe754335ee0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"Chinese-Korean-Translation\",\n",
    "    name=model_name,\n",
    "    id='my_{}'.format(model_name),\n",
    "    resume='allow',\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"architecture\": \"BERT\",\n",
    "    \"dataset\": \"TEDTalks\",\n",
    "    \"epochs\": 100,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 242,
     "status": "ok",
     "timestamp": 1716402679913,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "7WyAXDtaXSmx"
   },
   "outputs": [],
   "source": [
    "best_loss = float('inf')\n",
    "#best_loss = 4.291\n",
    "#best_score = 1.132\n",
    "best_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 271,
     "status": "ok",
     "timestamp": 1716402681527,
     "user": {
      "displayName": "夏梨",
      "userId": "03563146555660366686"
     },
     "user_tz": -480
    },
    "id": "YD4OaqdCXPa9"
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UcHtMBVDXQVX",
    "outputId": "10817315-b947-46fd-e2c0-daa6fc0cb65b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:31<00:00, 14.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Time: 11m 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 192.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 인도네시아에서는 많은 열대 우림이 제거되었는데요. 그 총 크기는 아일랜드의 크기와 비슷합니다. 겨우 12년 만에 그렇게 된 것이죠. \n",
      "generate: 인도 에서는,, 열대 의 의 의 열대 림 림 대 0 0 0 0 0 0 0 년 년 년 년 년 0\n",
      "output tensor([[[  6.1256, -11.3720, -11.3421,  ...,  -4.4107, -11.6402, -11.4584],\n",
      "         [  3.3296, -10.6348,  -9.5718,  ...,  -4.8820, -10.5821, -10.4644],\n",
      "         [  2.5843, -12.9375, -12.6565,  ...,  -6.5062, -13.1869, -13.0111],\n",
      "         ...,\n",
      "         [  7.3191, -12.0663, -12.0745,  ...,  -4.8192, -11.9353, -12.3356],\n",
      "         [  7.3690, -11.7745, -11.8645,  ...,  -4.6863, -11.7671, -12.0094],\n",
      "         [ 12.9249, -13.1849, -13.5081,  ...,  -6.1767, -13.3737, -13.3585]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 이러한 대처법은 끊임없이 새롭게 유지되어야 합니다 \n",
      "generate: 이러한 방식은 계속 계속 합니다 합니다.\n",
      "output tensor([[[  5.7258, -11.4307, -11.4482,  ...,  -4.6033, -11.6203, -11.4990],\n",
      "         [  0.9375, -11.2725, -10.7093,  ...,  -5.9209, -10.8282, -11.0620],\n",
      "         [  0.0886, -11.8426, -11.5081,  ...,  -5.7534, -11.6239, -11.7798],\n",
      "         ...,\n",
      "         [ 16.2605, -13.0814, -12.4676,  ...,  -5.4800, -12.8002, -12.2817],\n",
      "         [ 16.4910, -13.3018, -12.6248,  ...,  -5.5606, -12.9066, -12.4701],\n",
      "         [ 16.7019, -13.3000, -12.5354,  ...,  -5.4642, -12.7900, -12.4544]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 전 이 과정을 통해 지속가능성을 향한 모든 생각이 동기부여되기 시작할 거라 생각합니다. 매우 긍정적인 방식으로요. 또한 아이들을 가르칠 수도 있겠죠. 아이들은 비로소 재활용에 대해 알게 되겠지만, 아직은 지속가능성이 뭔지, 에너지(탄소)발자국이 뭐고 그게 어떻게 문제가 되는지 사실 잘 알지 못합니다. \n",
      "generate: 그리고 모든 모든, 적,,,,,,,,,,.......\n",
      "output tensor([[[  6.0152, -12.1973, -12.3863,  ...,  -4.9475, -12.3415, -12.1068],\n",
      "         [  1.3582, -11.9655, -11.1171,  ...,  -6.3778, -11.6745, -12.3589],\n",
      "         [  1.8947, -13.5406, -12.6272,  ...,  -6.7106, -14.0405, -13.8287],\n",
      "         ...,\n",
      "         [  8.1359, -13.2619, -13.1711,  ...,  -6.2712, -12.9519, -13.3429],\n",
      "         [  8.1854, -13.2443, -13.1894,  ...,  -6.2889, -12.9546, -13.3753],\n",
      "         [ 14.9515, -14.3298, -14.4318,  ...,  -6.7150, -14.3802, -14.3212]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 그 농담은 코미디언으로서 제가 좋아하는 속임수를 사용해요. 세 개의 규칙인데요. 그것을 통해 의견을 제시하고 목록을 통해서 그 의견을 뒷받침합니다. \n",
      "generate: 그 농담 제가 제가 코미디 가장 가장 가장 가장 가장 가장 가장 가장 가장......\n",
      "output tensor([[[  5.5623, -11.6692, -11.8420,  ...,  -4.7827, -12.1058, -11.9639],\n",
      "         [  1.0268, -12.2460, -11.6560,  ...,  -5.6630, -12.3245, -12.6956],\n",
      "         [  2.3111, -13.1003, -12.8366,  ...,  -6.6582, -13.6127, -13.7552],\n",
      "         ...,\n",
      "         [  7.1552, -12.5743, -12.4186,  ...,  -5.4986, -12.6420, -12.7289],\n",
      "         [  7.7164, -12.4562, -12.2394,  ...,  -5.3900, -12.5917, -12.5845],\n",
      "         [ 14.2995, -13.6952, -13.6025,  ...,  -6.3573, -13.7569, -13.7001]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 01 | Eval Time: 0m 10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== save model ==\n",
      "\tTrain Loss: 3.727 | Test Loss: 3.740\n",
      "\tBLEU Score:\n",
      "\t\tavg: 1.245\n",
      "\t\t1-gram: 16.847\n",
      "\t\t2-gram: 1.773\n",
      "\t\t3-gram: 0.653\n",
      "\t\t4-gram: 0.158\n",
      "{'avg': [0.1049915270848691, 1.2451767395632234], '1-gram': [0.2652519893899204, 16.846767726908244], '2-gram': [0.1424501424501424, 1.7732401934443847], '3-gram': [0.0769230769230769, 0.6531825757917024], '4-gram': [0.0418060200668896, 0.1582669766061625]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:31<00:00, 14.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | Train Time: 11m 36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 191.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 우리는 사람들에게 이건 덫이 아니라 말합니다. 아무도 당신이 바보라고 하지 않으며, 아무도 당신 경험이 상관없다 하지 않습니다. \n",
      "generate: 우리는 이 이 이........ 바보 바보 바보 바보 바보 바보 바보 바보...\n",
      "output tensor([[[  5.2756, -12.2766, -12.5336,  ...,  -5.2108, -12.2047, -12.3395],\n",
      "         [  0.2938, -12.7598, -13.0546,  ...,  -7.6506, -12.7688, -13.5743],\n",
      "         [  1.4433, -13.4176, -14.5725,  ...,  -8.4435, -13.8448, -14.6765],\n",
      "         ...,\n",
      "         [  7.8512, -14.1683, -13.9866,  ...,  -7.7457, -14.0390, -14.2209],\n",
      "         [  7.6234, -13.8032, -13.7416,  ...,  -7.7851, -13.7307, -13.9006],\n",
      "         [ 14.3662, -14.3023, -14.0664,  ...,  -6.9103, -14.4035, -14.4862]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 그러나 같은 선택이라도 프로그래머가 미리 설정해 놓은 것이라면요? 미래의 이러한 상황에 대비해서요. 그건 좀 더 계획된 살인처럼 보이네요. \n",
      "generate: 하지만 프로그래 프로그래 가 가 이 이 지시 같은 행동을 행동을 행동을 행동을..,...\n",
      "output tensor([[[  5.1153, -11.5951, -11.9175,  ...,  -4.1671, -11.6868, -11.9653],\n",
      "         [  1.1621, -11.6609, -11.9243,  ...,  -5.6244, -12.3019, -12.3308],\n",
      "         [  1.3601, -12.6033, -13.1270,  ...,  -6.8855, -13.9475, -13.1698],\n",
      "         ...,\n",
      "         [  8.1718, -13.2606, -13.4937,  ...,  -6.3859, -13.3075, -13.2328],\n",
      "         [  8.4075, -13.2136, -13.6366,  ...,  -6.4409, -13.3881, -13.1717],\n",
      "         [ 15.1982, -14.1195, -14.0198,  ...,  -6.4945, -14.0861, -14.3779]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 이는 골프 경기에서도 플룻의 경우처럼 충분한 고민 없이는 정의가 무엇을 요구하는지 결정하기가 어려움을 보여줍니다. \"어떤 행위의 본질이란 것은 과연 무엇일까요? 또 그 행위에 관하여 어떤 자질과 장점들이 명예롭고 인정을 받을 만한 가치가 있을까요?\" \n",
      "generate: 이 골프 골프 골프 골프 는 는 는 는 는...........\n",
      "output tensor([[[  5.2561, -11.1384, -11.7262,  ...,  -4.5654, -11.4403, -11.5402],\n",
      "         [  0.8608, -12.2356, -12.6010,  ...,  -4.2859, -12.2146, -12.3256],\n",
      "         [  0.8748, -12.4757, -13.0169,  ...,  -4.2019, -12.9556, -12.5086],\n",
      "         ...,\n",
      "         [  7.3011, -12.7870, -13.6014,  ...,  -6.3772, -13.1053, -12.7340],\n",
      "         [  7.2481, -12.2591, -13.2409,  ...,  -6.4246, -12.8129, -12.3906],\n",
      "         [ 14.6963, -13.3768, -13.5505,  ...,  -6.5357, -13.5654, -13.7478]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 이들 군인은 훈련을 받지 않은 일들을 하고 있기 때문에 많은 문제들이 생기고 있습니다. \n",
      "generate: 그래서 군인 군인 이 일을 일을 일을 때 많은 많은.........\n",
      "output tensor([[[  5.2024, -11.6479, -12.1452,  ...,  -4.4055, -11.6412, -12.0630],\n",
      "         [  0.3918, -12.7051, -12.0805,  ...,  -4.2052, -11.8167, -12.5126],\n",
      "         [  1.1654, -14.1654, -14.1316,  ...,  -3.9227, -13.8643, -14.3988],\n",
      "         ...,\n",
      "         [  8.0673, -13.3011, -13.4762,  ...,  -6.1983, -13.0216, -13.4657],\n",
      "         [  8.2427, -13.2806, -13.4022,  ...,  -5.9695, -13.0135, -13.2852],\n",
      "         [ 14.9474, -14.1632, -14.4672,  ...,  -6.5272, -14.1587, -14.3961]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 02 | Eval Time: 0m 10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== save model ==\n",
      "\tTrain Loss: 3.612 | Test Loss: 3.705\n",
      "\tBLEU Score:\n",
      "\t\tavg: 1.367\n",
      "\t\t1-gram: 16.482\n",
      "\t\t2-gram: 1.729\n",
      "\t\t3-gram: 0.619\n",
      "\t\t4-gram: 0.198\n",
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.19775570272259013]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:32<00:00, 14.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | Train Time: 11m 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 188.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 그러나 그러한 부의 파장에서는 사람들을 엄청나게 나은 영양상태를 갖게 해주었어요. \n",
      "generate: 하지만 이 은 은 은 더 더 더 영양 영양\n",
      "output tensor([[[  5.2656, -13.4159, -13.5371,  ...,  -6.6516, -13.6628, -14.0693],\n",
      "         [  1.0856, -13.3257, -12.8639,  ...,  -7.1387, -12.9176, -14.4379],\n",
      "         [  0.8768, -13.6246, -13.3595,  ...,  -8.5098, -13.5110, -14.5158],\n",
      "         ...,\n",
      "         [ 17.7371, -19.0401, -18.6790,  ...,  -8.0212, -18.4273, -18.4337],\n",
      "         [ 17.7565, -19.1691, -18.8342,  ...,  -8.0817, -18.5524, -18.5735],\n",
      "         [ 17.9012, -19.3087, -18.9313,  ...,  -8.1796, -18.6455, -18.7343]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence '스턱스넷(Stuxnet)' 컴퓨터 웜의 개념은 사실 아주 단순합니다. \n",
      "generate: 컴퓨터 뱀 는 는 는 는 는 개념 매우 매우..\n",
      "output tensor([[[ 4.6588e+00, -1.2049e+01, -1.1899e+01,  ..., -5.6174e+00,\n",
      "          -1.2081e+01, -1.2289e+01],\n",
      "         [ 1.6358e-02, -1.1876e+01, -1.2292e+01,  ..., -6.7752e+00,\n",
      "          -1.2694e+01, -1.2585e+01],\n",
      "         [ 1.7013e+00, -1.2589e+01, -1.3914e+01,  ..., -6.1544e+00,\n",
      "          -1.3395e+01, -1.3086e+01],\n",
      "         ...,\n",
      "         [ 1.4850e+01, -1.5733e+01, -1.5520e+01,  ..., -6.2644e+00,\n",
      "          -1.5855e+01, -1.6108e+01],\n",
      "         [ 1.4814e+01, -1.5744e+01, -1.5494e+01,  ..., -6.2445e+00,\n",
      "          -1.5824e+01, -1.6059e+01],\n",
      "         [ 1.7565e+01, -1.6524e+01, -1.6245e+01,  ..., -6.9247e+00,\n",
      "          -1.6173e+01, -1.6452e+01]]], device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 그리고 이 방법은 일상적인 활동에 걸리는 시간을 조금씩 깎아내어 모두 더하는 것입니다. 그러면 좋은 일에 쓸 수 있는 시간을 갖게 되는 것입니다. \n",
      "generate: 이 아이디어 우리가 매일 매일 시간을 시간을 시간을 시간을 시간을 수 수 수. 수.....\n",
      "output tensor([[[  5.0629, -12.9926, -13.1454,  ...,  -5.9844, -13.1419, -13.5215],\n",
      "         [  2.3433, -14.4142, -14.3637,  ...,  -6.3886, -14.3892, -15.0642],\n",
      "         [  1.1170, -12.4680, -12.8959,  ...,  -5.4829, -12.8024, -13.1504],\n",
      "         ...,\n",
      "         [  7.7983, -13.9908, -13.9001,  ...,  -6.6237, -13.6291, -13.9041],\n",
      "         [  8.1885, -13.9674, -14.1756,  ...,  -6.5091, -13.8076, -13.8878],\n",
      "         [ 15.6321, -14.4262, -14.1983,  ...,  -6.7096, -14.2877, -14.4533]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 그래서 우리는 돌고래들이 자기들의 제일 좋아하는 장난감을 실시간으로 요구할 수 있는 그런 기술을 개발하면 좋지 않을까? 하는 생각을 하게 됬습니다. \n",
      "generate: 우리는 우리가 돌고 들이 들이 을 할 할 수 수 수 수 수 수 수 있을까\n",
      "output tensor([[[  5.4071, -13.5507, -13.9884,  ...,  -6.0016, -13.5766, -14.1327],\n",
      "         [  0.5675, -13.1119, -13.5167,  ...,  -5.7955, -12.2188, -13.5996],\n",
      "         [  1.0902, -13.8968, -14.8937,  ...,  -6.5288, -14.1053, -14.7460],\n",
      "         ...,\n",
      "         [  9.9246, -13.6337, -14.5756,  ...,  -5.6926, -13.8340, -14.2447],\n",
      "         [ 10.2540, -14.1174, -14.8395,  ...,  -5.7266, -14.3717, -14.5937],\n",
      "         [ 16.5607, -14.8699, -14.6906,  ...,  -6.0217, -14.5992, -14.9232]]],\n",
      "       device='cuda:0')\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 186.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 3.514 | Test Loss: 3.707\n",
      "\tBLEU Score:\n",
      "\t\tavg: 0.885\n",
      "\t\t1-gram: 15.983\n",
      "\t\t2-gram: 1.394\n",
      "\t\t3-gram: 0.381\n",
      "\t\t4-gram: 0.072\n",
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496363], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.38144201666735766], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.07227065359772347]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:31<00:00, 14.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | Train Time: 11m 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 193.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 저는 호모 에렉투스 두개골과 큰 관련이 있는데 왜냐하면 이 호모 에렉투스가 숨을 거둘 당시 나이와 제 나이가 같았기 때문입니다. \n",
      "generate: 저는 골 골 골 기억 기억 기억 기억... 왜냐하면 왜냐하면 왜냐하면 그. 기 기 기\n",
      "output tensor([[[  4.4921, -12.5098, -13.4927,  ...,  -5.8626, -13.2221, -12.7852],\n",
      "         [  0.2422, -12.8570, -13.7711,  ...,  -5.9015, -13.2882, -13.5821],\n",
      "         [  0.3405, -14.2161, -15.8810,  ...,  -7.0100, -15.0740, -15.5887],\n",
      "         ...,\n",
      "         [ 11.6873, -14.4157, -15.2214,  ...,  -4.9862, -14.7897, -15.1619],\n",
      "         [ 12.0556, -14.3005, -14.9535,  ...,  -4.9091, -14.6315, -14.9042],\n",
      "         [ 17.5239, -15.0812, -15.3396,  ...,  -6.4490, -15.0290, -15.6069]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence (웃음) 그렇지 않다면, 제가 질문을 했는데, 여러분의 답이 '네'라면, 여러분은 손뼉을 쳐주시면 좋겠습니다. \n",
      "generate: ( 웃음 ) 그래서 제가 질문을 질문을 질문을 질문을,,,,... 면 면. 주세요 주세요 주세요 주세요 주세요\n",
      "output tensor([[[  4.6367, -13.5423, -14.2976,  ...,  -7.4665, -13.8591, -13.3980],\n",
      "         [  3.2967, -13.6206, -14.4310,  ...,  -8.8170, -14.7809, -14.7180],\n",
      "         [  3.0444, -12.6016, -13.2912,  ...,  -7.7643, -12.7201, -12.9680],\n",
      "         ...,\n",
      "         [  8.1948, -13.5953, -13.5386,  ...,  -8.0412, -13.5219, -13.9224],\n",
      "         [  8.9904, -13.9225, -13.7084,  ...,  -7.6171, -13.6799, -13.9240],\n",
      "         [ 14.9390, -14.5274, -14.2454,  ...,  -8.0621, -14.3596, -14.4508]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 쉽고 눈에 띠는 관심의 대상이며 그럴만하지만, 사실 건물이 자동차나 트럭보다 더 큰 지구 온난화 오염원입니다. \n",
      "generate: 이 쉽게 쉽게 쉽게 수,...... 건물 건물 건물 건물 건물\n",
      "output tensor([[[  4.2432, -12.5638, -13.2793,  ...,  -6.3570, -13.0051, -12.9295],\n",
      "         [ -0.5510, -12.3917, -12.3874,  ...,  -4.0540, -12.6039, -12.2951],\n",
      "         [ -0.1882, -12.3434, -12.8526,  ...,  -4.1976, -12.3419, -12.4153],\n",
      "         ...,\n",
      "         [  7.8509, -12.9831, -12.6966,  ...,  -5.5532, -12.7764, -12.9410],\n",
      "         [  7.8400, -12.9423, -12.6762,  ...,  -5.5844, -12.9181, -13.0093],\n",
      "         [ 15.6713, -13.3950, -13.3547,  ...,  -6.3851, -13.3773, -13.7142]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 두 양성자는 뛰어넘어갈 수 있습니다. \n",
      "generate: 이 두 두 두 두 양성 자가 자가 두 다른...\n",
      "output tensor([[[  4.8890, -14.0878, -14.2177,  ...,  -8.4494, -14.0886, -13.4184],\n",
      "         [  0.0283, -14.4947, -14.0459,  ...,  -9.5776, -14.3923, -13.8813],\n",
      "         [  0.6082, -14.4030, -14.8190,  ...,  -9.2470, -15.0361, -14.5902],\n",
      "         ...,\n",
      "         [ 17.6112, -17.9195, -17.4721,  ...,  -8.2539, -17.4265, -17.4671],\n",
      "         [ 17.6596, -17.9869, -17.5506,  ...,  -8.2426, -17.5041, -17.5283],\n",
      "         [ 18.0507, -18.2944, -17.8581,  ...,  -8.5462, -17.8322, -17.8355]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 04 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 3.429 | Test Loss: 3.710\n",
      "\tBLEU Score:\n",
      "\t\tavg: 1.325\n",
      "\t\t1-gram: 16.706\n",
      "\t\t2-gram: 1.754\n",
      "\t\t3-gram: 0.591\n",
      "\t\t4-gram: 0.178\n",
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.17797456266006859]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:31<00:00, 14.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | Train Time: 11m 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 189.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 부서들간의 업무 이양은 필요치 않았습니다. \n",
      "generate: 그들은 기관 계약 계약 계약 계약...\n",
      "output tensor([[[  2.9901, -12.6608, -12.7965,  ...,  -6.4832, -12.6222, -12.5399],\n",
      "         [ -0.0502, -12.0532, -12.3791,  ...,  -5.9506, -11.5019, -11.3627],\n",
      "         [ -0.5458, -12.7838, -13.9366,  ...,  -5.2972, -12.1360, -12.2716],\n",
      "         ...,\n",
      "         [ 17.7560, -19.4588, -19.4757,  ...,  -8.3618, -19.1048, -19.3461],\n",
      "         [ 17.7879, -19.4497, -19.4575,  ...,  -8.3507, -19.0906, -19.3248],\n",
      "         [ 17.9847, -19.4761, -19.4500,  ...,  -8.4494, -19.1064, -19.3380]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 이 밥 한 공기? \n",
      "generate: 이 레스토랑?\n",
      "output tensor([[[  3.2114, -14.1573, -14.3278,  ...,  -6.6321, -14.0693, -14.0783],\n",
      "         [  1.4548, -11.6364, -11.1099,  ...,  -4.7682, -11.6010, -11.9528],\n",
      "         [  2.2286, -12.3987, -12.6159,  ...,  -6.0088, -12.0159, -13.0112],\n",
      "         ...,\n",
      "         [ 18.2747, -20.8604, -20.8836,  ...,  -8.9444, -20.4365, -20.6220],\n",
      "         [ 18.2740, -20.8498, -20.8710,  ...,  -8.9397, -20.4278, -20.6115],\n",
      "         [ 18.3730, -20.8046, -20.8156,  ...,  -8.9501, -20.3886, -20.5863]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 정말 힘들었어요. \n",
      "generate: 정말 어려운..\n",
      "output tensor([[[  3.1645, -13.4662, -13.9691,  ...,  -6.7568, -13.5777, -13.3687],\n",
      "         [  2.2004, -13.6956, -13.8828,  ...,  -5.4504, -14.0570, -14.2627],\n",
      "         [  3.3095, -13.7054, -14.0283,  ...,  -6.2111, -14.1691, -14.1636],\n",
      "         ...,\n",
      "         [ 17.7982, -19.6989, -19.6753,  ...,  -8.7273, -19.3352, -19.5031],\n",
      "         [ 17.8156, -19.6826, -19.6596,  ...,  -8.7167, -19.3270, -19.4951],\n",
      "         [ 17.9807, -19.4900, -19.4498,  ...,  -8.5996, -19.1779, -19.3335]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 이 기계를 켜자마자 연기가 사라지는 걸 볼 수 있습니다. \n",
      "generate: 이 기계가 기계가 기계 이 이 이 모든 이. 사라 사라.\n",
      "output tensor([[[  3.6368, -14.0097, -13.9204,  ...,  -7.6985, -13.5013, -13.3216],\n",
      "         [  0.8100, -12.2465, -12.0338,  ...,  -7.4866, -12.6170, -11.7960],\n",
      "         [  1.5797, -12.1253, -12.8043,  ...,  -7.6235, -12.9683, -12.6030],\n",
      "         ...,\n",
      "         [ 17.8120, -18.9900, -19.0670,  ...,  -8.5905, -19.1928, -19.1235],\n",
      "         [ 18.0912, -19.6889, -19.7686,  ...,  -8.9121, -19.8067, -19.7467],\n",
      "         [ 18.5324, -19.9638, -20.0440,  ...,  -9.0762, -20.0416, -20.0245]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 05 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 3.351 | Test Loss: 3.737\n",
      "\tBLEU Score:\n",
      "\t\tavg: 1.172\n",
      "\t\t1-gram: 15.950\n",
      "\t\t2-gram: 1.665\n",
      "\t\t3-gram: 0.538\n",
      "\t\t4-gram: 0.132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.6649206824304101], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.13190291945128385]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:32<00:00, 14.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | Train Time: 11m 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 191.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 그리고 말콤 글래드웰의 \"아웃라이어\"를 읽으신 분이 있을텐데요. 그의 성공 이론도 들어봤을 겁니다. 만 시간의 성공 법칙 말이죠. \n",
      "generate: 여러분들 중 몇 분들이 셨 셨 셨 셨 셨 셨 셨 셨 셨 들어보 들어보 들어보 들어보 들어보 들어보 셨 셨 들어보 들어보\n",
      "output tensor([[[  2.9771, -14.0596, -13.2989,  ...,  -6.3778, -13.1152, -13.3092],\n",
      "         [  1.5002, -12.5330, -12.3477,  ...,  -5.7571, -13.2104, -13.0226],\n",
      "         [  1.1823, -11.3089, -12.0774,  ...,  -5.3726, -12.4684, -12.1656],\n",
      "         ...,\n",
      "         [  4.3969, -11.8497, -11.0162,  ...,  -4.9480, -11.4939, -11.8167],\n",
      "         [  4.7605, -12.3833, -11.5494,  ...,  -4.9666, -12.1163, -12.2560],\n",
      "         [ 11.5235, -15.1580, -15.4003,  ...,  -7.0290, -14.8621, -15.2906]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 인간의 인슐린과 다르게, 이 단백질은 화학적으로 구별할 수 없는 여러분의 췌장에서 나오는것과 같은 단백질입니다. \n",
      "generate: 이것은 슐 슐 슐 슐 과.. 슐 슐 슐 슐 슐 슐 슐 슐.\n",
      "output tensor([[[  4.7026, -16.2237, -15.8255,  ...,  -9.7384, -15.5021, -15.9823],\n",
      "         [  0.8018, -14.2660, -14.3058,  ...,  -8.8278, -14.3081, -15.4813],\n",
      "         [  0.1925, -15.0579, -14.9657,  ...,  -8.8462, -14.7837, -16.0891],\n",
      "         ...,\n",
      "         [ 11.5187, -15.7764, -15.6116,  ...,  -8.9190, -15.7559, -16.3904],\n",
      "         [ 12.0563, -16.4684, -16.1378,  ...,  -9.1494, -16.4734, -16.7634],\n",
      "         [ 18.0459, -19.9610, -19.2019,  ...,  -9.4001, -19.6927, -20.3492]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 현재 경쟁적으로 조수와 파력을 활용한 전기로 만들어서 땅 속 석탄을 쓰지 않게 할 겁니다. \n",
      "generate: 그리고 발전 발전 발전 발전 발전 발전 를... 를 를 를 를....\n",
      "output tensor([[[  4.2698, -14.7444, -14.4863,  ...,  -6.9546, -14.3943, -14.1385],\n",
      "         [  0.7985, -17.0101, -16.6126,  ...,  -5.7881, -16.5476, -14.7812],\n",
      "         [  1.3529, -14.8057, -14.1624,  ...,  -4.5772, -13.7192, -12.8866],\n",
      "         ...,\n",
      "         [ 12.9796, -16.1657, -16.2706,  ...,  -6.1757, -16.5937, -15.7622],\n",
      "         [ 12.5954, -16.3508, -16.3768,  ...,  -5.2133, -16.8340, -16.0781],\n",
      "         [ 18.6778, -20.3003, -19.7047,  ...,  -8.1422, -19.7224, -19.8607]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 그리고 현대 외교에서는 이런 접근을 강화할 필요가 있다고 믿습니다. 국가들 사이에서 뿐만이 아니라, 국가내에서까지 말입니다. \n",
      "generate: 그리고 저는 우리가 우리가 국경 외교 외교 외교 외교 외교 외교 외교 외교 외교. 아니라 아니라........\n",
      "output tensor([[[  3.8920, -15.0676, -15.3384,  ...,  -8.7495, -14.6232, -14.9194],\n",
      "         [ -0.5414, -14.0780, -14.5522,  ...,  -7.6111, -13.3781, -14.3030],\n",
      "         [  2.2999, -13.2522, -13.8411,  ...,  -8.6201, -13.2719, -14.5944],\n",
      "         ...,\n",
      "         [  6.0825, -13.7877, -13.8932,  ...,  -7.9683, -13.4918, -14.4918],\n",
      "         [  6.5755, -13.8060, -14.0804,  ...,  -7.4607, -13.6046, -14.6631],\n",
      "         [ 14.9118, -15.8823, -15.8125,  ...,  -8.4547, -15.8814, -16.1627]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 06 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 3.277 | Test Loss: 3.741\n",
      "\tBLEU Score:\n",
      "\t\tavg: 1.101\n",
      "\t\t1-gram: 14.786\n",
      "\t\t2-gram: 1.621\n",
      "\t\t3-gram: 0.485\n",
      "\t\t4-gram: 0.127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038413], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107623], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:32<00:00, 14.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | Train Time: 11m 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 189.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 부레옥잠 줄기를 엮어서 긴 밧줄로 만드는 방법을 배우는 제 여정은 그렇게 시작되었습니다. \n",
      "generate: 그래서 제가 제가 을 배 을 을 배 배 배... 배,,,,, 로 배 배 배 배 배 배\n",
      "output tensor([[[  3.2221, -15.0013, -14.6287,  ...,  -8.0223, -14.4424, -14.6522],\n",
      "         [  0.0293, -12.7557, -12.9421,  ...,  -7.4211, -12.7848, -13.1220],\n",
      "         [  0.9697, -12.6954, -13.5833,  ...,  -6.7297, -13.1331, -13.7307],\n",
      "         ...,\n",
      "         [  6.1864, -13.0898, -12.7694,  ...,  -6.0595, -13.0855, -13.1307],\n",
      "         [  7.0305, -13.5169, -13.4636,  ...,  -6.7649, -13.8567, -13.7923],\n",
      "         [ 13.8180, -14.2907, -14.5397,  ...,  -7.3367, -14.3129, -14.4607]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 베이비그램이라고 불리는 건데요. 아이의 몸 전체를 엑스레이 촬영 한 것입니다. \n",
      "generate: 우리는 아기 아기 아기 아기 부 아기 아기 아기 아기...\n",
      "output tensor([[[  6.9886, -14.6430, -14.1604,  ...,  -8.8315, -14.2174, -14.5826],\n",
      "         [ -0.2588, -12.7804, -12.0082,  ...,  -5.6534, -12.8989, -12.8837],\n",
      "         [ -0.8260, -13.9889, -13.1840,  ...,  -5.0875, -13.6836, -13.5547],\n",
      "         ...,\n",
      "         [ 17.5699, -18.5610, -17.6840,  ...,  -8.8453, -18.1320, -18.2502],\n",
      "         [ 17.5108, -19.4672, -18.5849,  ...,  -9.0731, -18.9719, -19.0983],\n",
      "         [ 18.0693, -20.8984, -19.9374,  ...,  -9.7435, -20.3735, -20.5034]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 처음에는 여기서처럼 아마 10번째에 그런 패턴이 나오겠죠. \n",
      "generate: 첫 째 10 제가 10 10 11 10 10.....\n",
      "output tensor([[[  5.2643, -14.9092, -15.0162,  ...,  -8.2603, -14.7102, -14.9433],\n",
      "         [  0.0243, -11.8174, -12.8352,  ...,  -5.0817, -12.9390, -12.9747],\n",
      "         [  0.8995, -11.9596, -12.3976,  ...,  -4.8628, -12.2447, -12.8416],\n",
      "         ...,\n",
      "         [ 17.6286, -21.3699, -20.9609,  ...,  -9.2635, -20.9381, -20.6923],\n",
      "         [ 17.6317, -21.3195, -20.9137,  ...,  -9.2464, -20.8783, -20.6372],\n",
      "         [ 17.8298, -21.4263, -20.9336,  ...,  -9.3764, -20.9663, -20.6951]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 그리고 우리가 MR을 통해 영향을 주는 특별한 능력들 중 하나는 온도를 비침습적으로 측정할 수 있는 능력입니다 \n",
      "generate: 를 의 중 하나는 하나는 하나는 하나는 중 하나는 하나는 하나는 하나는 것입니다 것입니다 것입니다 것입니다 것입니다\n",
      "output tensor([[[  4.9504, -15.9272, -15.7374,  ...,  -8.2144, -15.3076, -15.0664],\n",
      "         [ -0.2866, -13.4358, -13.6907,  ...,  -8.5776, -12.9451, -13.9574],\n",
      "         [ -0.1525, -13.4407, -14.2002,  ...,  -9.0959, -13.4142, -13.4561],\n",
      "         ...,\n",
      "         [ 11.0676, -15.5678, -15.7599,  ...,  -7.2576, -15.7241, -15.1242],\n",
      "         [ 11.2316, -15.2662, -15.3522,  ...,  -7.0663, -15.5448, -15.1353],\n",
      "         [ 16.0548, -15.3041, -15.5064,  ...,  -6.2424, -15.2930, -15.1455]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 07 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 3.209 | Test Loss: 3.770\n",
      "\tBLEU Score:\n",
      "\t\tavg: 1.117\n",
      "\t\t1-gram: 15.061\n",
      "\t\t2-gram: 1.556\n",
      "\t\t3-gram: 0.464\n",
      "\t\t4-gram: 0.143\n",
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.14314453729495513]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:32<00:00, 14.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | Train Time: 11m 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 189.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 수수께끼의 나즈카 라인과 놀라운 직물의 발상지입니다. \n",
      "generate: 그것은 나 와 와 아름다운 아름다운 아름다운 아름다운 아름다운..\n",
      "output tensor([[[  2.5821, -13.0766, -12.8803,  ...,  -8.6029, -12.8935, -13.5331],\n",
      "         [ -0.2063, -11.6484, -11.7335,  ...,  -2.8954, -12.3224, -12.4733],\n",
      "         [ -0.2294, -11.3169, -10.6227,  ...,  -3.5945, -11.0572, -10.9566],\n",
      "         ...,\n",
      "         [ 18.4427, -23.9600, -23.9386,  ..., -11.0660, -23.7610, -23.4446],\n",
      "         [ 18.4165, -23.9713, -23.9385,  ..., -11.0655, -23.7647, -23.4329],\n",
      "         [ 18.4850, -24.0474, -23.9397,  ..., -11.0955, -23.8327, -23.5053]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 이런 시스템은 어떤 점이 다른 걸까요? \n",
      "generate: 왜 다른 다른 다르 까??\n",
      "output tensor([[[  1.9308, -15.7103, -15.7741,  ...,  -9.2350, -15.6159, -16.0714],\n",
      "         [  2.3831, -16.0615, -15.3640,  ...,  -8.8735, -14.9656, -15.0367],\n",
      "         [  1.6103, -15.1261, -14.5582,  ...,  -9.2150, -14.8253, -14.9827],\n",
      "         ...,\n",
      "         [ 18.0413, -25.1175, -24.7824,  ..., -11.5820, -24.6896, -24.5085],\n",
      "         [ 18.0347, -25.1303, -24.8071,  ..., -11.5962, -24.7129, -24.5127],\n",
      "         [ 18.1023, -25.1894, -24.8078,  ..., -11.6102, -24.7855, -24.5227]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 벽을 따라 내려오는 전선을 보고 싶은 사람은 없을 것입니다. \n",
      "generate: 상상,. 없는 없는 싶지 근처에 고..\n",
      "output tensor([[[  4.0081, -16.2925, -16.3415,  ..., -10.0213, -15.6391, -16.3235],\n",
      "         [  0.4052, -14.5678, -14.3682,  ...,  -7.1699, -14.0818, -13.5516],\n",
      "         [  1.2508, -14.3422, -14.3295,  ...,  -7.6795, -14.3660, -13.4127],\n",
      "         ...,\n",
      "         [ 18.2798, -24.0933, -24.1430,  ..., -11.2945, -23.8139, -23.5791],\n",
      "         [ 18.2914, -24.1002, -24.1514,  ..., -11.3161, -23.8202, -23.5787],\n",
      "         [ 18.4215, -24.2412, -24.2074,  ..., -11.3746, -23.9810, -23.7058]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 대안들이 많다 보면 선택하지 않은 대안들에 대한 매력적인 점들을 상상하게 됩니다. 결국 당신이 선택한 것에 대한 만족도를 떨어 뜨리죠. \n",
      "generate: 다른 다른 많은 있을 때 때 때 선택 선택 선택 선택 선택 선택 선택 선택 선택 선택.....\n",
      "output tensor([[[  2.5561, -15.1533, -15.6785,  ...,  -9.7216, -15.2787, -15.4999],\n",
      "         [  1.5092, -15.2695, -15.7985,  ...,  -8.8058, -15.3290, -15.5412],\n",
      "         [  0.9114, -14.3706, -14.6261,  ...,  -8.8136, -14.7044, -14.1219],\n",
      "         ...,\n",
      "         [  7.2709, -15.1755, -14.9146,  ...,  -8.5263, -15.0671, -15.2198],\n",
      "         [  6.9801, -15.0676, -14.4880,  ...,  -8.5312, -14.6246, -14.8883],\n",
      "         [ 15.2234, -17.4868, -17.4755,  ...,  -9.0769, -17.4369, -17.2675]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 08 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 3.142 | Test Loss: 3.830\n",
      "\tBLEU Score:\n",
      "\t\tavg: 1.099\n",
      "\t\t1-gram: 15.172\n",
      "\t\t2-gram: 1.525\n",
      "\t\t3-gram: 0.475\n",
      "\t\t4-gram: 0.133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456045], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167305], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.5251428764668087], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.47511968663861887], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.13289555972482803]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:32<00:00, 14.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | Train Time: 11m 36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 188.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 의사들은 '의견충돌' 또는 '지시불응' 이라는 용어를 사용합니다. 이것 모두 태도의 문제죠. \n",
      "generate: 사람들이 사람들이 하지 않으면 않는다면,,, 않는.......\n",
      "output tensor([[[  3.2282, -15.9368, -16.6588,  ..., -10.6113, -16.2311, -16.2199],\n",
      "         [  1.9351, -14.9261, -15.4107,  ...,  -9.4614, -15.7195, -15.8844],\n",
      "         [  2.3188, -15.1987, -15.4207,  ...,  -9.4210, -15.2719, -15.7384],\n",
      "         ...,\n",
      "         [ 16.7161, -22.3992, -22.1681,  ..., -11.5529, -22.5120, -22.2059],\n",
      "         [ 17.2693, -23.7242, -23.6748,  ..., -11.8953, -23.7293, -23.5607],\n",
      "         [ 18.0959, -24.7184, -24.5585,  ..., -11.8530, -24.5928, -24.4939]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 다른 흥미로운 임무 개요 아이디어는 사람이 직접 도착하기 전에 인간형 로봇을 먼저 화성에 두어 시설들을 먼저 짓게 한 후 과학팀의 협력 멤버로 두는 것입니다. \n",
      "generate: 미션 임무 에서 또 또 또 다른 하나는 하나는 하나는 하나는 전에 전에 전에 전에 전에 전에 전에 전에 것입니다.....\n",
      "output tensor([[[  3.1002, -18.0525, -18.5734,  ..., -10.3003, -18.1027, -18.0777],\n",
      "         [ -0.1226, -15.5135, -15.3299,  ...,  -5.7804, -14.7099, -15.8370],\n",
      "         [ -1.2720, -14.6289, -15.2808,  ...,  -7.6838, -13.7439, -15.0488],\n",
      "         ...,\n",
      "         [  6.9250, -15.1232, -15.1731,  ...,  -6.2264, -15.6567, -14.3488],\n",
      "         [  6.8018, -14.8967, -15.2279,  ...,  -6.4066, -15.3798, -14.3849],\n",
      "         [ 16.3992, -17.0244, -17.1140,  ...,  -9.5110, -17.0756, -16.8640]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 지금 이 시점에서 우리를 완전히 흥분시키고 도전적이게 하는 것 중의 하나는 권력무지에 대한 결과가 너무나 만연해 있다는 것입니다. 지식의 집중, 이해도의 집중, 그리고 영향력의 집중 \n",
      "generate: 또 흥미로운 흥미로운 흥미로운 흥미로운 흥미로운 흥미로운 흥미로운 하나는 하나는 하나는 권력을 권력을 이 권력 에. 에...\n",
      "output tensor([[[  3.7198, -16.8109, -17.4022,  ...,  -9.1415, -17.0713, -16.7387],\n",
      "         [  0.5585, -14.4585, -15.6324,  ...,  -6.1770, -15.1809, -15.2625],\n",
      "         [ -0.8521, -14.9204, -14.6877,  ...,  -7.0338, -14.7545, -14.5357],\n",
      "         ...,\n",
      "         [  7.4049, -14.7575, -14.9979,  ...,  -8.0804, -14.6249, -14.6901],\n",
      "         [  7.1193, -14.9632, -14.9071,  ...,  -8.1626, -14.6880, -14.4626],\n",
      "         [ 16.7390, -18.6276, -18.3386,  ...,  -9.9999, -18.4616, -18.1742]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 또 그냥 잊어버리라고도 합니다. \n",
      "generate: 우리는 사람들이 멈춰 습..\n",
      "output tensor([[[  3.8851, -15.3546, -15.5795,  ...,  -8.6220, -15.2920, -15.6015],\n",
      "         [  0.8180, -12.6929, -12.8219,  ...,  -6.6008, -11.9923, -13.7625],\n",
      "         [  1.6723, -13.8336, -14.8076,  ...,  -7.7696, -13.9625, -14.4756],\n",
      "         ...,\n",
      "         [ 18.3930, -25.6198, -25.4738,  ..., -11.8981, -25.4135, -25.3607],\n",
      "         [ 18.3695, -25.6104, -25.4620,  ..., -11.8878, -25.4103, -25.3442],\n",
      "         [ 18.5264, -25.4218, -25.2358,  ..., -11.7730, -25.2822, -25.1619]]],\n",
      "       device='cuda:0')\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 186.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 3.081 | Test Loss: 3.866\n",
      "\tBLEU Score:\n",
      "\t\tavg: 1.066\n",
      "\t\t1-gram: 15.541\n",
      "\t\t2-gram: 1.551\n",
      "\t\t3-gram: 0.423\n",
      "\t\t4-gram: 0.126\n",
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456043, 1.065565142789168], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167303, 15.54081410196518], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.525142876466809, 1.551031253113687], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.4751196866386188, 0.4233519513323135], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.132895559724828, 0.12633513265188928]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:32<00:00, 14.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Time: 11m 36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 192.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence \"라고 말했습니다. (웃음) 저는 기회 비용이 무엇인지 배웠습니다. \n",
      "generate: ( 웃음 ) 하지만 저는 기회를 기회를 에 에 배 배우 웠 웠..\n",
      "output tensor([[[ 3.3430e+00, -1.7555e+01, -1.8280e+01,  ..., -8.7466e+00,\n",
      "          -1.7386e+01, -1.7750e+01],\n",
      "         [ 1.6588e-02, -1.4122e+01, -1.5087e+01,  ..., -8.2264e+00,\n",
      "          -1.5224e+01, -1.5495e+01],\n",
      "         [ 1.2827e+00, -1.3845e+01, -1.4344e+01,  ..., -7.8052e+00,\n",
      "          -1.3819e+01, -1.3986e+01],\n",
      "         ...,\n",
      "         [ 1.8389e+01, -2.5192e+01, -2.4782e+01,  ..., -1.2235e+01,\n",
      "          -2.4923e+01, -2.4721e+01],\n",
      "         [ 1.8311e+01, -2.5365e+01, -2.4934e+01,  ..., -1.2284e+01,\n",
      "          -2.5088e+01, -2.4877e+01],\n",
      "         [ 1.8627e+01, -2.4997e+01, -2.4590e+01,  ..., -1.2140e+01,\n",
      "          -2.4779e+01, -2.4696e+01]]], device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 물에서 분리된 수소가 빠르게 우주로 탈출하고 지구에는 붉고 메마른 표면을 남기겠죠. \n",
      "generate: 물이 분해 부터 탄소 탄소 탄소 탄소 빨리 탈출 탈출 탈출 탈출 지구 탈출. 우리의...\n",
      "output tensor([[[  3.8406, -17.3115, -17.8676,  ...,  -9.8716, -17.0217, -17.2579],\n",
      "         [  1.4150, -16.3429, -16.7638,  ...,  -9.9980, -16.2528, -17.0689],\n",
      "         [ -0.0297, -15.9956, -17.2393,  ..., -12.2253, -16.1533, -16.6554],\n",
      "         ...,\n",
      "         [ 12.1035, -16.7378, -16.9988,  ...,  -8.6252, -16.8764, -16.8366],\n",
      "         [ 11.1381, -17.0107, -17.3791,  ...,  -8.1461, -16.9694, -17.0350],\n",
      "         [ 18.4440, -21.0423, -20.8814,  ..., -11.0560, -20.6534, -21.3331]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 우리가 입은 모든 것들에 우리의 이야기가 있습니다. 우리가 어디에 있었고 무엇을 하고 있었으며 어떤 사람이 되고 싶은지에 대한 이야기 말이죠. \n",
      "generate: 우리가 우리가 모든 모든 모든 모든 모든 우리가 에 에 에 에 에 에. 에 에.......\n",
      "output tensor([[[  3.7797, -15.6240, -16.3664,  ...,  -7.6962, -15.9042, -15.5498],\n",
      "         [  0.5525, -13.7501, -12.5098,  ...,  -6.8425, -12.1479, -12.6799],\n",
      "         [  0.5173, -10.6998, -10.5613,  ...,  -5.5151,  -9.7573,  -9.4183],\n",
      "         ...,\n",
      "         [  9.5327, -16.2532, -16.3188,  ...,  -8.7162, -16.8406, -16.6068],\n",
      "         [  8.7775, -15.8615, -15.7919,  ...,  -8.7979, -15.9700, -15.8249],\n",
      "         [ 15.9822, -15.6129, -15.5997,  ...,  -6.8679, -15.8575, -15.7152]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 하지만 트루도의 천재성은 캐나다의 위기가 보통은 개혁을 막는 장애물들을 없앴다는 걸 깨달은 거죠. \n",
      "generate: 하지만 테 트 의 의 놀라운 점은 점은 점은 점은 의 의 가 가 이 가,,,,,, 막는 것을 것을 것을 있다는 있다는 있다는.\n",
      "output tensor([[[  1.8528, -16.1903, -17.0877,  ...,  -8.5017, -16.1260, -16.4574],\n",
      "         [ -0.9138, -16.3592, -17.6365,  ...,  -7.3566, -16.8532, -17.4247],\n",
      "         [ -1.1584, -14.8790, -16.1947,  ...,  -8.0551, -15.4057, -15.5592],\n",
      "         ...,\n",
      "         [  2.7243, -13.3662, -13.4028,  ...,  -5.1294, -13.4659, -12.6095],\n",
      "         [  3.5400, -13.8299, -14.0690,  ...,  -5.3642, -14.1627, -13.0861],\n",
      "         [ 12.0931, -15.8535, -16.2231,  ...,  -8.3505, -15.6166, -15.7789]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 10 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 3.020 | Test Loss: 3.887\n",
      "\tBLEU Score:\n",
      "\t\tavg: 1.122\n",
      "\t\t1-gram: 15.068\n",
      "\t\t2-gram: 1.626\n",
      "\t\t3-gram: 0.463\n",
      "\t\t4-gram: 0.140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456043, 1.065565142789168, 1.1217228300472808], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167303, 15.54081410196518, 15.068451007537302], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.525142876466809, 1.551031253113687, 1.6259629568923126], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.4751196866386188, 0.4233519513323135, 0.46307665321873354], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.132895559724828, 0.1263351326518892, 0.13954365453516876]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:32<00:00, 14.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Time: 11m 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 188.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 아시다시피 1900년에 사람들이 몰던 자동차는 현재 더 나아진 도로와 기술력 덕분에 변화했습니다. \n",
      "generate: 아시 아시 다시 주행 는 가 가 가 가 변 차를 변...............\n",
      "output tensor([[[  1.6499, -18.2164, -18.8199,  ...,  -8.4166, -18.1141, -18.8821],\n",
      "         [ -1.0240, -16.8944, -16.7866,  ...,  -7.5637, -17.1010, -16.9660],\n",
      "         [  0.9222, -16.8727, -17.6284,  ...,  -7.8712, -17.1682, -17.4866],\n",
      "         ...,\n",
      "         [  5.2877, -14.9818, -16.1845,  ...,  -6.5572, -15.8027, -15.8906],\n",
      "         [  5.4631, -15.1115, -16.4150,  ...,  -5.7876, -15.4269, -15.7174],\n",
      "         [ 14.8548, -17.8029, -18.6015,  ...,  -9.2025, -18.2188, -18.4369]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 탐사 결과는 지구에서 본 것과 매우 비슷한 모습을 나타내고 있습니다. \n",
      "generate: 화성 의 대기 대기 지구 지구 지구 지구 지구 비슷한 지구 지구 것을...\n",
      "output tensor([[[  4.2981, -19.9859, -21.1033,  ..., -10.9410, -19.6948, -20.4199],\n",
      "         [ -1.0314, -14.6294, -13.8477,  ...,  -4.1000, -14.4845, -15.5781],\n",
      "         [ -1.7113, -16.0191, -16.5840,  ...,  -5.5387, -16.9607, -17.3473],\n",
      "         ...,\n",
      "         [ 18.2666, -25.3826, -25.3713,  ..., -12.9445, -25.0989, -25.3749],\n",
      "         [ 18.4436, -26.1971, -26.2187,  ..., -13.1164, -25.8577, -26.1606],\n",
      "         [ 18.6160, -26.4171, -26.4010,  ..., -13.1225, -26.1289, -26.3794]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 감사합니다. \n",
      "generate: 감사합니다.\n",
      "output tensor([[[  3.7943, -19.1375, -19.5775,  ..., -10.0528, -18.7611, -19.0693],\n",
      "         [  5.2837, -17.9882, -18.0395,  ..., -10.2388, -17.8661, -17.1403],\n",
      "         [  5.4437, -14.9144, -14.9133,  ..., -10.2478, -14.8705, -14.6036],\n",
      "         ...,\n",
      "         [ 17.6151, -24.4184, -24.1038,  ..., -12.2693, -24.2490, -24.1022],\n",
      "         [ 17.5928, -24.4401, -24.1214,  ..., -12.2837, -24.2795, -24.1158],\n",
      "         [ 17.6429, -24.5583, -24.1749,  ..., -12.3242, -24.4137, -24.2263]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 트로이는 자메이카에서 온 이민자인 어머니께서 얼마나 열심히 일하시지만 얼마나 적게 버는지를 보았고 그는 맹세했죠. 트로이는 다른 길을 가야겠다고 맹세를 했습니다. \n",
      "generate: 테 그 드는 그의 이민 이민 이민 이민 이민 이민 얼마나 얼마나 한 한 돈을 는 는 급 돈을 돈을 을 습..\n",
      "output tensor([[[  3.4240, -17.9148, -18.4256,  ...,  -8.4013, -17.5704, -18.1506],\n",
      "         [ -0.9190, -13.7553, -13.3091,  ...,  -4.1514, -14.2533, -13.0481],\n",
      "         [ -1.1047, -13.7394, -13.9482,  ...,  -7.1578, -13.9518, -13.6715],\n",
      "         ...,\n",
      "         [ 10.7658, -16.5906, -17.1431,  ...,  -6.1514, -16.7170, -16.3774],\n",
      "         [ 11.1790, -16.6946, -17.3040,  ...,  -6.6612, -17.3390, -16.5368],\n",
      "         [ 16.2119, -20.9685, -21.7381,  ...,  -9.3420, -21.3991, -21.5521]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 11 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 2.961 | Test Loss: 3.932\n",
      "\tBLEU Score:\n",
      "\t\tavg: 1.125\n",
      "\t\t1-gram: 15.400\n",
      "\t\t2-gram: 1.605\n",
      "\t\t3-gram: 0.464\n",
      "\t\t4-gram: 0.140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456043, 1.065565142789168, 1.1217228300472808, 1.1251005772205362], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167303, 15.54081410196518, 15.068451007537302, 15.399544082311627], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.525142876466809, 1.551031253113687, 1.6259629568923126, 1.6052787078983652], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.4751196866386188, 0.4233519513323135, 0.4630766532187335, 0.4637762630876256], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.132895559724828, 0.1263351326518892, 0.1395436545351687, 0.1397650436293582]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:31<00:00, 14.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Time: 11m 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 193.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 1577년 태어난 로버트 버턴은 슬픔의 경험과 원인을 연구하는데 평생을 쏟았다. \n",
      "generate: 로버트 로버트 트 은 은 은 에 년 년 년. 슬픔 슬픔 연구 연구 연구 연구 연구..\n",
      "output tensor([[[  2.6660, -19.2519, -19.8543,  ...,  -9.2281, -19.2528, -19.3042],\n",
      "         [ -1.8098,  -9.1470,  -9.6125,  ...,  -1.7073,  -9.6977, -10.2951],\n",
      "         [ -0.2655,  -9.2208,  -9.7423,  ...,  -2.5190,  -9.5474,  -9.5109],\n",
      "         ...,\n",
      "         [ 17.7400, -20.9984, -21.0203,  ...,  -9.9404, -21.9235, -21.0449],\n",
      "         [ 17.6433, -22.4781, -22.1185,  ..., -11.1795, -22.8256, -22.3267],\n",
      "         [ 19.5467, -26.1505, -25.9037,  ..., -12.6208, -26.0273, -25.9278]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 그리고 우리가 원했던 원자는 바로 '철'이었죠 \n",
      "generate: 우리는 철 철 철 원 원...\n",
      "output tensor([[[ 2.9264e+00, -1.9156e+01, -2.0073e+01,  ..., -1.1302e+01,\n",
      "          -1.8652e+01, -1.9516e+01],\n",
      "         [ 5.1605e-03, -1.2515e+01, -1.3369e+01,  ..., -9.2049e+00,\n",
      "          -1.2546e+01, -1.3316e+01],\n",
      "         [-8.3145e-01, -1.7627e+01, -1.8906e+01,  ..., -1.0782e+01,\n",
      "          -1.6956e+01, -1.7226e+01],\n",
      "         ...,\n",
      "         [ 1.8382e+01, -2.7569e+01, -2.7188e+01,  ..., -1.3327e+01,\n",
      "          -2.7074e+01, -2.7538e+01],\n",
      "         [ 1.8373e+01, -2.7558e+01, -2.7182e+01,  ..., -1.3335e+01,\n",
      "          -2.7082e+01, -2.7545e+01],\n",
      "         [ 1.8443e+01, -2.7923e+01, -2.7489e+01,  ..., -1.3517e+01,\n",
      "          -2.7485e+01, -2.7907e+01]]], device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 파일럿 셔츠 뒤에 적혀있는 글씨도 보실 수 있습니다. \"착륙이전 질문 금지\" 러시아어와 영어로 적혀 있어요. 사람들은 궁금해서 말을 걸 수도 있으니까요. 그러면 집중력을 잃게 되고 문제가 발생합니다. \n",
      "generate: 사실 로봇 \" \" \" 이렇게...... \"....\n",
      "output tensor([[[  4.9130, -17.4371, -18.0541,  ...,  -8.2681, -17.9014, -17.5951],\n",
      "         [ -1.4736, -14.6047, -14.2663,  ...,  -3.2573, -15.1560, -14.8021],\n",
      "         [ -1.1182, -14.3791, -14.3073,  ...,  -3.0667, -15.0162, -14.2196],\n",
      "         ...,\n",
      "         [ 14.9136, -19.9683, -19.9973,  ...,  -9.9589, -20.5350, -19.3666],\n",
      "         [ 15.6391, -20.3693, -20.5298,  ...,  -9.8962, -21.1866, -20.0350],\n",
      "         [ 16.2464, -23.2206, -23.1702,  ..., -10.1406, -23.0464, -23.0223]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 두 명 이상의 자녀를 가지신 분은요? \n",
      "generate: 두 두 명이 명이 명이??\n",
      "output tensor([[[  3.5877, -21.1261, -21.4560,  ..., -11.1986, -21.3565, -21.4556],\n",
      "         [  2.9651, -13.8000, -12.7638,  ...,  -6.3893, -13.2300, -13.4215],\n",
      "         [  3.4165, -15.4530, -14.8477,  ...,  -8.0937, -15.3575, -14.7296],\n",
      "         ...,\n",
      "         [ 18.5248, -28.1931, -27.7742,  ..., -13.1991, -28.0045, -28.2412],\n",
      "         [ 18.5286, -28.2614, -27.8263,  ..., -13.2208, -28.0689, -28.2852],\n",
      "         [ 18.6416, -28.4348, -27.9339,  ..., -13.2601, -28.2572, -28.4338]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 12 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 2.904 | Test Loss: 3.968\n",
      "\tBLEU Score:\n",
      "\t\tavg: 0.938\n",
      "\t\t1-gram: 15.257\n",
      "\t\t2-gram: 1.502\n",
      "\t\t3-gram: 0.409\n",
      "\t\t4-gram: 0.083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456043, 1.065565142789168, 1.1217228300472808, 1.1251005772205362, 0.9376270106656373], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167303, 15.54081410196518, 15.068451007537302, 15.399544082311628, 15.2570938285224], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.525142876466809, 1.551031253113687, 1.6259629568923126, 1.6052787078983652, 1.50159952993406], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.4751196866386188, 0.4233519513323135, 0.4630766532187335, 0.4637762630876256, 0.4086051547111825], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.132895559724828, 0.1263351326518892, 0.1395436545351687, 0.1397650436293582, 0.08256398708999474]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:32<00:00, 14.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Time: 11m 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 192.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 그래서 한번, 어떤 사람을 위해 위조서류를 만들기로 동의 했어요 아마 여러분도 아실 거에요 \n",
      "generate: 언젠가, 한 에게 에게 복사 복사 한다고 한다고 한다고 한다고, 한다고......\n",
      "output tensor([[[  1.9594, -18.3362, -19.1408,  ..., -11.3554, -18.9980, -18.8659],\n",
      "         [ -2.7773, -16.6572, -17.0914,  ...,  -7.0697, -16.4760, -17.4046],\n",
      "         [ -1.4035, -14.6578, -15.2376,  ...,  -8.3128, -14.5120, -15.4012],\n",
      "         ...,\n",
      "         [ 17.5436, -23.4252, -23.1022,  ..., -12.8280, -23.6248, -23.6225],\n",
      "         [ 17.2662, -23.7157, -23.2254,  ..., -12.8757, -23.7611, -23.7966],\n",
      "         [ 18.4347, -28.8974, -28.5014,  ..., -14.8151, -28.7820, -28.9055]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 우리는 이것을 키 교환이라고 부릅니다. \n",
      "generate: 저희는 이것을'통신 ( ( ( 이라고 릅 릅 니 니 니\n",
      "output tensor([[[  1.2807, -16.5369, -17.1113,  ...,  -9.5817, -16.7854, -17.3852],\n",
      "         [  0.2254, -17.7882, -17.3628,  ..., -10.7804, -18.0081, -17.9397],\n",
      "         [ -0.3788, -18.0585, -17.8824,  ..., -10.6722, -18.2299, -18.9793],\n",
      "         ...,\n",
      "         [ 17.5957, -26.8344, -26.7919,  ..., -13.8834, -26.9197, -27.2620],\n",
      "         [ 17.5982, -26.9179, -26.8207,  ..., -13.8688, -26.9743, -27.2902],\n",
      "         [ 17.8315, -26.8036, -26.4602,  ..., -13.7176, -26.8257, -27.0801]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 아주 혼란스런 시대에 모든 부모가 동의할 수 있는 목표가 하나 있습니다. 그것은 호랑이 엄마든, 히피 엄마든, 헬리곱터나 비행기 엄마든, 아이들의 행복이 가장 중요하다는 것이죠. \n",
      "generate: 이렇게 부모 도로 의 기 시대에 세대 모든 모든 부모 부모 부모 부모 부모 동의....... 의 의......\n",
      "output tensor([[[  0.6547, -19.1726, -19.9272,  ..., -10.5509, -19.0503, -19.6535],\n",
      "         [ -0.5449, -17.3912, -17.0239,  ...,  -9.1154, -16.7695, -17.1668],\n",
      "         [ -1.5518, -14.5604, -14.7950,  ...,  -7.6628, -13.9946, -15.2340],\n",
      "         ...,\n",
      "         [  3.3816, -14.3350, -13.8310,  ...,  -7.8684, -13.4295, -14.3052],\n",
      "         [  4.6963, -14.4892, -13.9665,  ...,  -7.7357, -13.4065, -14.1057],\n",
      "         [ 14.9230, -18.4928, -18.4349,  ..., -10.4341, -18.2914, -18.5620]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 그리고 다른 중요한 사실은, 어찌 됐건 우리한테는 전기 생산을 위한 지속 가능한 방법이 있어야 한다는 겁니다. \n",
      "generate: 또 다른, 우리가 우리가 재생 재생 재생 에너지 재생 재생 에너지 에너지 에너지 에너지 에너지 에너지 에너지 에너지 에너지 에너지....\n",
      "output tensor([[[  2.2804, -18.4925, -19.2413,  ..., -10.6403, -19.2111, -19.1236],\n",
      "         [ -0.9352, -17.3212, -17.3721,  ...,  -9.7027, -18.1601, -19.0423],\n",
      "         [ -0.1238, -18.4171, -18.5345,  ..., -10.7074, -19.2571, -19.9026],\n",
      "         ...,\n",
      "         [  6.5915, -15.6360, -16.6892,  ...,  -9.1011, -16.0194, -16.3408],\n",
      "         [  6.8313, -16.2661, -17.0899,  ...,  -8.9517, -16.6917, -16.9218],\n",
      "         [ 16.9689, -21.2770, -21.3299,  ..., -11.1241, -21.2628, -21.2819]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 13 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 2.848 | Test Loss: 3.990\n",
      "\tBLEU Score:\n",
      "\t\tavg: 0.946\n",
      "\t\t1-gram: 14.558\n",
      "\t\t2-gram: 1.339\n",
      "\t\t3-gram: 0.382\n",
      "\t\t4-gram: 0.108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456043, 1.065565142789168, 1.1217228300472808, 1.1251005772205362, 0.9376270106656373, 0.9458417505553759], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167303, 15.54081410196518, 15.068451007537302, 15.399544082311628, 15.2570938285224, 14.557690604799433], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.525142876466809, 1.551031253113687, 1.6259629568923126, 1.6052787078983652, 1.50159952993406, 1.3394397565795664], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.4751196866386188, 0.4233519513323135, 0.4630766532187335, 0.4637762630876256, 0.4086051547111825, 0.38153887345627363], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.132895559724828, 0.1263351326518892, 0.1395436545351687, 0.1397650436293582, 0.0825639870899947, 0.10757700720765949]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:31<00:00, 14.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Time: 11m 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 194.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 그리고 건물 내에서의 에너지 필요량의 감소도 무려 15퍼센트나 되는데, 이는 신선한 공기가 덜 필요하기 때문이지요. \n",
      "generate: 실내 실내 실내 공기가 공기가 더 에너지를 추가적인 공기가 필요가 하지 실내 는 % 도 % 도 15 15 15 15......\n",
      "output tensor([[[  2.7975, -21.0045, -21.4304,  ..., -11.9491, -20.9866, -21.4536],\n",
      "         [ -1.2022, -15.7558, -15.2418,  ...,  -6.1906, -17.2601, -14.4893],\n",
      "         [ -1.7269, -12.7860, -12.0204,  ...,  -5.2142, -13.4828, -11.8569],\n",
      "         ...,\n",
      "         [  8.4239, -15.9466, -16.9486,  ...,  -8.2383, -16.3714, -16.9373],\n",
      "         [  8.9072, -16.2029, -17.0918,  ...,  -8.3102, -16.6588, -16.6435],\n",
      "         [ 16.4762, -22.0269, -22.0210,  ..., -11.6057, -21.7724, -22.3954]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 사우디 종교 기관의 수장인 그랜드 머프티는 여성이 운전하는 것을 권장하지 않는다고 했습니다. \n",
      "generate: 무 슬림 자유 와 이슬람 이슬람 은, 은 디 디 디 디 디 디 가장 가장 가장 가장 가장 가장 가장 교도 교도 교도..\n",
      "output tensor([[[  2.0949, -18.2580, -18.5722,  ..., -11.5162, -18.1533, -18.6626],\n",
      "         [ -1.1258, -15.7611, -16.1289,  ..., -12.0811, -16.5380, -16.0576],\n",
      "         [ -1.2018, -16.0510, -16.9060,  ..., -12.2964, -16.4237, -16.6670],\n",
      "         ...,\n",
      "         [  5.2888, -15.8938, -15.3223,  ...,  -9.7036, -15.5041, -15.8398],\n",
      "         [  5.8695, -16.8393, -16.0914,  ...,  -9.5749, -16.4653, -16.3944],\n",
      "         [ 15.4199, -19.8290, -20.1316,  ..., -12.2887, -19.7784, -20.1091]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 기적의 치료제 같은 것은 없지만. 현대 의학은 매년 수백만명의 생명을 살립니다. 우리도 이와 같은 일을 할 수 있습니다. \n",
      "generate: 마법 치료 통치 이. 의학 의학 오늘날 의학 수백 수백 수백 명의 수백 수백 수 수백 수백 수 수.... 수 수 생명을...\n",
      "output tensor([[[  0.1526, -22.0796, -22.8937,  ..., -13.9477, -22.5187, -22.3655],\n",
      "         [ -1.1362, -18.8462, -18.5883,  ...,  -8.9253, -19.8624, -17.9013],\n",
      "         [ -2.1693, -21.0908, -20.8957,  ..., -10.4514, -21.4681, -20.4095],\n",
      "         ...,\n",
      "         [  4.8357, -14.8960, -15.2346,  ..., -10.9263, -15.4162, -15.7767],\n",
      "         [  5.6671, -15.5278, -15.9127,  ..., -11.4072, -16.1048, -16.4558],\n",
      "         [ 15.1521, -21.6087, -21.4359,  ..., -13.0267, -21.2215, -21.5192]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 오렌지색 풍선이 없어서 그랬을까요? \n",
      "generate: 그게 풍선 를 를 를 를 였 요 요\n",
      "output tensor([[[  0.7529, -18.4438, -18.7496,  ..., -11.5379, -18.3710, -19.0653],\n",
      "         [ -0.6302, -16.3163, -15.6480,  ...,  -7.3025, -16.0536, -15.6582],\n",
      "         [ -1.3064, -14.7559, -15.3223,  ...,  -7.7694, -14.6823, -14.5596],\n",
      "         ...,\n",
      "         [ 18.1758, -29.0878, -28.5760,  ..., -14.1917, -28.6312, -29.2689],\n",
      "         [ 18.1214, -28.9853, -28.4726,  ..., -14.1530, -28.5330, -29.1668],\n",
      "         [ 18.1841, -29.5815, -28.9883,  ..., -14.5091, -29.1060, -29.6566]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 14 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 2.793 | Test Loss: 4.051\n",
      "\tBLEU Score:\n",
      "\t\tavg: 1.033\n",
      "\t\t1-gram: 15.290\n",
      "\t\t2-gram: 1.562\n",
      "\t\t3-gram: 0.459\n",
      "\t\t4-gram: 0.104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456043, 1.065565142789168, 1.1217228300472808, 1.1251005772205362, 0.9376270106656373, 0.945841750555376, 1.032552971972674], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167303, 15.54081410196518, 15.068451007537302, 15.399544082311628, 15.2570938285224, 14.557690604799433, 15.290158268146262], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.525142876466809, 1.551031253113687, 1.6259629568923126, 1.6052787078983652, 1.50159952993406, 1.3394397565795664, 1.5621974049448066], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.4751196866386188, 0.4233519513323135, 0.4630766532187335, 0.4637762630876256, 0.4086051547111825, 0.3815388734562736, 0.45890552756883585], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.132895559724828, 0.1263351326518892, 0.1395436545351687, 0.1397650436293582, 0.0825639870899947, 0.1075770072076594, 0.10369986296803822]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:31<00:00, 14.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Time: 11m 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 189.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 자신들의 모든 아이디어를 걸어 놓을 수 있는 아주, 아주 견고한 격자를 가지고 있었습니다. \n",
      "generate: 그것은 정말 강력한 강력한 이론 이론 이론 이론 이론 이론 어떤 어떤 이론 이론 어떤 어떤 어떤 어떤 어떤 어떤 어떤 어떤 어떤 어떤......\n",
      "output tensor([[[  1.5898, -20.9201, -21.4972,  ..., -15.5934, -20.9190, -20.9564],\n",
      "         [ -1.1599, -24.3608, -23.5156,  ..., -17.1739, -24.0714, -23.4338],\n",
      "         [ -2.2487, -20.4192, -19.8592,  ..., -14.1820, -19.6368, -19.2511],\n",
      "         ...,\n",
      "         [  3.9929, -16.3087, -16.0541,  ..., -10.9284, -16.2867, -16.1023],\n",
      "         [  4.3034, -17.0188, -16.6147,  ..., -10.7171, -16.5802, -16.5936],\n",
      "         [ 13.5131, -21.9437, -21.9281,  ..., -13.7049, -21.2499, -21.8103]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 예외적 요소들이나 불규칙한 부분들, 혹은 말의 뉘앙스와 같이 인간에게 자연스러운 요소들이 컴퓨터에게는 어려운 점일 수 있으며 때문에 어떤 연구자들은 언어의 이해가 생물학적 뇌 구조의 독특한 산물이라고 봅니다. \n",
      "generate: 컴퓨터 의 겪는 은 은 특이 적이 적이 적이 적이 적이 적 적이 적 적 없는 수...\n",
      "output tensor([[[  3.6901, -20.1375, -20.6784,  ..., -13.3284, -20.2607, -20.2894],\n",
      "         [  0.3763, -15.1854, -16.0926,  ...,  -4.0234, -14.0482, -16.2107],\n",
      "         [ -0.2326, -15.3746, -15.3126,  ...,  -8.1743, -14.1317, -14.7576],\n",
      "         ...,\n",
      "         [ 14.4358, -21.1472, -21.1980,  ..., -11.5520, -21.0309, -20.8043],\n",
      "         [ 14.9924, -20.3095, -20.2286,  ..., -10.8731, -20.3593, -19.9348],\n",
      "         [ 18.9474, -27.6163, -27.3314,  ..., -15.0259, -26.9450, -27.9551]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 저는 또한 예상합니다. 여기로 유입되는 투자는 미국의 납세자가 나사의 유인 우주선 작업을 위해 사용하는 돈의 약 절반 정도 될 것입니다. \n",
      "generate: 미국 미국 납 납 보다 보다 보다 보다 보다 보다 보다 보다 보다 보다 보다 보다 것보다 것보다 것보다 더 것보다....\n",
      "output tensor([[[  1.3143, -19.8590, -20.7551,  ...,  -9.6275, -20.0183, -20.0320],\n",
      "         [ -2.0442, -19.1595, -20.0718,  ...,  -9.5531, -20.2413, -20.2190],\n",
      "         [ -0.4983, -18.8318, -18.9756,  ...,  -8.4213, -18.8680, -19.1158],\n",
      "         ...,\n",
      "         [  9.7975, -17.6361, -17.5155,  ...,  -8.0729, -17.6522, -17.7206],\n",
      "         [  9.8141, -17.5986, -17.8276,  ...,  -7.2917, -17.6001, -17.8968],\n",
      "         [ 17.1008, -23.7056, -23.5762,  ..., -11.7270, -23.6587, -23.7783]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 점차적으로 크고 밀도 높은 가스의 공이 형성되고 그 스스로의 중력에 의해 압축됩니다. 그리고 결과적으로 안쪽에서 열이 발생합니다. \n",
      "generate: 그러면, 가스 이 중 력 력 력 력 력 력 력 결국 열 열 열 열 열 열.\n",
      "output tensor([[[ 2.1838e+00, -2.0488e+01, -2.0699e+01,  ..., -1.3619e+01,\n",
      "          -2.0000e+01, -2.0378e+01],\n",
      "         [-9.2962e-04, -2.0302e+01, -1.8957e+01,  ..., -9.6944e+00,\n",
      "          -2.0279e+01, -1.9380e+01],\n",
      "         [-2.1548e+00, -1.6649e+01, -1.6148e+01,  ..., -1.0519e+01,\n",
      "          -1.7723e+01, -1.6209e+01],\n",
      "         ...,\n",
      "         [ 1.8242e+01, -2.2994e+01, -2.2892e+01,  ..., -1.2525e+01,\n",
      "          -2.2755e+01, -2.3638e+01],\n",
      "         [ 1.8340e+01, -2.4521e+01, -2.4142e+01,  ..., -1.3807e+01,\n",
      "          -2.4128e+01, -2.4901e+01],\n",
      "         [ 2.0653e+01, -2.9970e+01, -2.9821e+01,  ..., -1.5568e+01,\n",
      "          -2.9955e+01, -3.0650e+01]]], device='cuda:0')\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 187.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 2.741 | Test Loss: 4.101\n",
      "\tBLEU Score:\n",
      "\t\tavg: 1.109\n",
      "\t\t1-gram: 14.485\n",
      "\t\t2-gram: 1.628\n",
      "\t\t3-gram: 0.470\n",
      "\t\t4-gram: 0.136\n",
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456043, 1.065565142789168, 1.1217228300472808, 1.1251005772205362, 0.9376270106656373, 0.945841750555376, 1.032552971972674, 1.108516565724771], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167303, 15.54081410196518, 15.068451007537302, 15.399544082311628, 15.2570938285224, 14.557690604799433, 15.290158268146262, 14.485009531511755], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.525142876466809, 1.551031253113687, 1.6259629568923126, 1.6052787078983652, 1.50159952993406, 1.3394397565795664, 1.5621974049448066, 1.6277358837594262], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.4751196866386188, 0.4233519513323135, 0.4630766532187335, 0.4637762630876256, 0.4086051547111825, 0.3815388734562736, 0.4589055275688358, 0.4702501469531709], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.132895559724828, 0.1263351326518892, 0.1395436545351687, 0.1397650436293582, 0.0825639870899947, 0.1075770072076594, 0.1036998629680382, 0.1361874498027028]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:32<00:00, 14.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Time: 11m 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 191.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 라고 말할지도 모릅니다. 혹은 \"봐! 저기 바나나 나무가 있어! 가서 가져오자! \n",
      "generate: \", 야 바나나 봐 야 야....\n",
      "output tensor([[[  2.7611, -15.3002, -16.0343,  ...,  -9.8288, -15.5874, -15.6481],\n",
      "         [  2.0187, -14.4980, -14.2662,  ...,  -7.3496, -14.7164, -13.8001],\n",
      "         [  2.9901, -13.4441, -14.1065,  ...,  -6.7452, -14.0850, -14.0327],\n",
      "         ...,\n",
      "         [ 15.4243, -21.7951, -20.8246,  ..., -13.6921, -21.2604, -21.8245],\n",
      "         [ 15.3252, -21.6302, -20.6107,  ..., -13.7572, -21.0080, -21.6494],\n",
      "         [ 18.3285, -29.4306, -28.5077,  ..., -16.5231, -28.6125, -29.1775]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 동시에 캐나다는 작년에 미국보다 10배가 넘는 시리아 난민을 받아들였습니다. \n",
      "generate: 한편 캐나다, 지난 시리아 민 민 민 보다 보다 보다 보다 보다 배 배 배...\n",
      "output tensor([[[  4.0850, -18.9957, -20.7919,  ..., -11.9688, -19.4281, -19.7546],\n",
      "         [ -2.0402, -16.8245, -18.5173,  ..., -10.7085, -17.9499, -18.2941],\n",
      "         [  1.3832, -11.3318, -12.1011,  ...,  -8.0721, -13.0218, -12.4321],\n",
      "         ...,\n",
      "         [ 17.0393, -17.2473, -17.8577,  ...,  -8.3814, -17.4021, -17.7462],\n",
      "         [ 16.2479, -19.6317, -19.5101,  ...,  -9.4527, -19.3408, -19.8971],\n",
      "         [ 19.9097, -28.4761, -28.2440,  ..., -15.0789, -28.1068, -28.8073]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 만약 그들의 전문지식이나 영향력 유대감, 기술들을 끌어모을 수 있다면 과연 어떻게 될까요? 최전방의 지역 사회가 우리의 동참을 원할 때 말이죠. \n",
      "generate: 만약 전문 재능을 재능 재능 재능, 력 력 력 력,,, 재능 재능 재능 과 능력을 수 수 능력을 능력을 수,, 과 수 수 수\n",
      "output tensor([[[  1.2713, -21.0706, -22.5000,  ..., -13.7887, -21.6585, -21.3474],\n",
      "         [ -4.3760, -23.0848, -23.0902,  ..., -11.3095, -22.6146, -23.7359],\n",
      "         [ -2.4794, -18.3907, -18.2984,  ..., -10.7145, -18.5123, -18.9286],\n",
      "         ...,\n",
      "         [ -0.0918, -15.6822, -14.9757,  ...,  -7.0707, -14.9661, -15.2897],\n",
      "         [  2.2087, -16.4131, -16.6060,  ...,  -7.5557, -16.1883, -16.6448],\n",
      "         [ 10.6058, -19.8962, -20.3174,  ..., -12.4389, -19.4292, -19.7424]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence (박수) 바로 이것이 교육이 사람을 바꾼다는 겁니다. \n",
      "generate: ( 박수 ) 이것이 교육 교육에 교육에 변화를 변화를 수 수 수..\n",
      "output tensor([[[  0.6114, -20.7699, -22.2925,  ..., -12.4388, -21.8014, -21.0029],\n",
      "         [  1.2664, -21.3013, -21.7581,  ..., -15.9550, -22.3170, -22.4213],\n",
      "         [  3.6591, -17.0065, -17.2190,  ..., -10.1347, -18.1741, -17.5264],\n",
      "         ...,\n",
      "         [ 17.0391, -26.1910, -25.5920,  ..., -15.7089, -26.0721, -26.3227],\n",
      "         [ 17.3019, -26.9643, -26.3066,  ..., -15.9404, -26.8136, -27.0191],\n",
      "         [ 20.5812, -28.6954, -28.1115,  ..., -15.4862, -28.4114, -28.5245]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 16 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 2.690 | Test Loss: 4.130\n",
      "\tBLEU Score:\n",
      "\t\tavg: 1.025\n",
      "\t\t1-gram: 14.728\n",
      "\t\t2-gram: 1.536\n",
      "\t\t3-gram: 0.451\n",
      "\t\t4-gram: 0.108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456043, 1.065565142789168, 1.1217228300472808, 1.1251005772205362, 0.9376270106656373, 0.945841750555376, 1.032552971972674, 1.108516565724771, 1.025004961153448], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167303, 15.54081410196518, 15.068451007537302, 15.399544082311628, 15.2570938285224, 14.557690604799433, 15.290158268146262, 14.485009531511755, 14.7281302838836], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.525142876466809, 1.551031253113687, 1.6259629568923126, 1.6052787078983652, 1.50159952993406, 1.3394397565795664, 1.5621974049448066, 1.6277358837594262, 1.5357446942701272], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.4751196866386188, 0.4233519513323135, 0.4630766532187335, 0.4637762630876256, 0.4086051547111825, 0.3815388734562736, 0.4589055275688358, 0.4702501469531709, 0.4510114099155195], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.132895559724828, 0.1263351326518892, 0.1395436545351687, 0.1397650436293582, 0.0825639870899947, 0.1075770072076594, 0.1036998629680382, 0.1361874498027028, 0.10820559062218214]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:32<00:00, 14.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Time: 11m 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 194.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 아니면 이런 말을 하죠. \"어떻게 여자가 아빠가 될 수 있지? \n",
      "generate: 혹은 \" \" 엄마가 엄마가 \" \" \"??\n",
      "output tensor([[[  3.1327, -20.4504, -21.1156,  ..., -11.5737, -20.9680, -20.8539],\n",
      "         [ -0.2729, -21.7276, -21.4280,  ..., -12.6037, -22.0222, -21.1972],\n",
      "         [ -0.7083, -22.0825, -21.4605,  ..., -12.3432, -21.8915, -21.1339],\n",
      "         ...,\n",
      "         [ 17.8043, -31.7421, -30.9357,  ..., -17.1047, -31.4593, -31.8802],\n",
      "         [ 17.8214, -31.8190, -30.9944,  ..., -17.2365, -31.5394, -31.9162],\n",
      "         [ 19.2091, -32.3057, -31.4685,  ..., -17.5423, -31.9527, -32.3649]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 이건 우리 건물입니다. 보험회사 헤드쿼터를 위한 본사 건물입니다. \n",
      "generate: 이것이 저희 짓고. 짓고.. 회사 의 사 의 입니다..\n",
      "output tensor([[[  2.2790, -19.4641, -20.9307,  ..., -10.8585, -20.5487, -20.0041],\n",
      "         [  0.1562, -18.8969, -19.4763,  ...,  -8.2655, -20.4613, -18.9153],\n",
      "         [ -0.4612, -15.4729, -15.8100,  ..., -10.4889, -16.9841, -15.9716],\n",
      "         ...,\n",
      "         [ 17.6191, -23.8769, -23.6720,  ..., -14.7570, -24.1048, -24.2005],\n",
      "         [ 17.9237, -24.4312, -24.2438,  ..., -15.1944, -24.7541, -24.8452],\n",
      "         [ 19.8417, -25.8995, -26.0183,  ..., -15.4288, -26.0888, -26.6158]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 오늘 이곳을 떠나는 여러분에게 저는 매우 개인적인 메시지를 남기고 싶습니다. 이 메세지는 제가 믿기로는 우리 모두가 개개인으로써 해야할 일입니다. 그리고 이것은 정말로 열린 마음을 갖는 것에 대한 얘기입니다. 전세계 사람들의 번영을 위한 우리의 희망과 꿈, 수십만에 이르는 사람들의 빈곤을 멈출 수 있을 만한 의미 있는 일은 열린 마음에 기반을 두고 있어야 할 것입니다 왜냐하면 이 시스템들은 좋은 점과 나쁜 점을 모두 갖고 있기 때문이죠. \n",
      "generate: 이 강연 제 마치고 마치고 제 제 제 제 을 을 저의 저의 드리고 드리고 싶습니다 이 싶습니다 싶습니다...\n",
      "output tensor([[[  2.8396, -22.4715, -23.7813,  ..., -13.8114, -23.3086, -22.7309],\n",
      "         [  0.7378, -23.6592, -24.1027,  ..., -13.8271, -23.4729, -23.6767],\n",
      "         [ -2.7283, -17.1837, -18.4838,  ...,  -8.6999, -17.7372, -17.9709],\n",
      "         ...,\n",
      "         [ 11.4671, -21.4480, -21.3904,  ..., -13.3663, -21.1482, -20.7905],\n",
      "         [ 10.7393, -21.0936, -20.8170,  ..., -13.1162, -20.5754, -20.0304],\n",
      "         [ 17.8353, -23.9412, -23.2539,  ..., -14.3928, -23.6882, -23.4251]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 즉, 기억력, 판단력, 충동 조절 능력이 저하됨을 의미합니다. 분노와 불안에 대한 뇌 영역이 활성화됩니다. \n",
      "generate: 즉 기억 기억 기억 력 력 인지 력 력 력, 력 력 은 불안 감정 감정 과 불안 불안 불안 민감 불안.. 의미..\n",
      "output tensor([[[  0.9814, -21.5461, -22.8884,  ..., -13.4428, -21.9757, -22.2934],\n",
      "         [ -2.8127, -21.4688, -21.0045,  ..., -14.0091, -21.3472, -20.3453],\n",
      "         [ -3.4757, -21.2312, -21.2463,  ..., -11.9699, -21.5077, -20.6646],\n",
      "         ...,\n",
      "         [  5.5437, -15.1676, -16.5358,  ..., -10.2867, -16.6307, -16.3640],\n",
      "         [  6.4862, -16.1872, -17.7543,  ...,  -9.8669, -17.5106, -17.1919],\n",
      "         [ 17.4666, -22.6663, -22.4991,  ..., -14.3033, -21.8624, -22.8370]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 17 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 2.642 | Test Loss: 4.195\n",
      "\tBLEU Score:\n",
      "\t\tavg: 1.246\n",
      "\t\t1-gram: 15.019\n",
      "\t\t2-gram: 1.648\n",
      "\t\t3-gram: 0.531\n",
      "\t\t4-gram: 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456043, 1.065565142789168, 1.1217228300472808, 1.1251005772205362, 0.9376270106656373, 0.945841750555376, 1.032552971972674, 1.108516565724771, 1.025004961153448, 1.246391054667423], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167303, 15.54081410196518, 15.068451007537302, 15.399544082311628, 15.2570938285224, 14.557690604799433, 15.290158268146262, 14.485009531511755, 14.7281302838836, 15.018685290694112], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.525142876466809, 1.551031253113687, 1.6259629568923126, 1.6052787078983652, 1.50159952993406, 1.3394397565795664, 1.5621974049448066, 1.6277358837594262, 1.5357446942701272, 1.6478496377993865], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.4751196866386188, 0.4233519513323135, 0.4630766532187335, 0.4637762630876256, 0.4086051547111825, 0.3815388734562736, 0.4589055275688358, 0.4702501469531709, 0.4510114099155195, 0.530596572066883], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.132895559724828, 0.1263351326518892, 0.1395436545351687, 0.1397650436293582, 0.0825639870899947, 0.1075770072076594, 0.1036998629680382, 0.1361874498027028, 0.1082055906221821, 0.18378216187832871]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:32<00:00, 14.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Time: 11m 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 190.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 그렇다면 전기뱀장어는 어떻게 자기가 만든 전기로부터 스스로를 보호할까요? \n",
      "generate: 어떻게 생명 체 어떻게 어떻게 어떻게 전기 전기 전기 전기 만들어 만들어 을\n",
      "output tensor([[[  2.3534, -22.0835, -23.2300,  ..., -12.0057, -22.4118, -22.4315],\n",
      "         [  2.5661, -21.5129, -20.8357,  ...,  -8.5284, -21.2858, -21.5113],\n",
      "         [ -1.0653, -17.2622, -16.7763,  ...,  -7.9231, -16.8835, -17.3124],\n",
      "         ...,\n",
      "         [ 18.0583, -27.9356, -27.4789,  ..., -17.3091, -27.9257, -28.4668],\n",
      "         [ 17.9923, -28.3227, -27.8976,  ..., -17.6706, -28.3164, -28.7978],\n",
      "         [ 19.0487, -32.4498, -31.7648,  ..., -18.2151, -32.4937, -32.8319]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 이 과정을 더 관찰해야하죠. \n",
      "generate: 우리는 많은 관찰 더 많은 이 이..\n",
      "output tensor([[[  0.7369, -22.2666, -23.6545,  ..., -14.9946, -22.7786, -22.5399],\n",
      "         [ -1.9967, -18.0172, -19.1051,  ..., -11.6754, -18.8404, -18.1632],\n",
      "         [ -1.8032, -17.1700, -19.1010,  ..., -12.5896, -18.5993, -18.5899],\n",
      "         ...,\n",
      "         [ 17.7100, -32.1214, -31.3806,  ..., -17.7098, -31.8453, -32.1923],\n",
      "         [ 17.7447, -32.1603, -31.4128,  ..., -17.7376, -31.8796, -32.2270],\n",
      "         [ 17.9148, -31.9740, -31.1744,  ..., -17.6210, -31.6941, -32.0436]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 이분들이 공통점을 하나 갖고 있는데, 무엇인지 아십니까? \n",
      "generate: 그들 공통 공통 점이 아시 십?\n",
      "output tensor([[[  1.4192, -20.5941, -22.1636,  ..., -12.9482, -21.2661, -21.2235],\n",
      "         [ -0.4716, -18.5393, -19.7117,  ..., -14.2788, -19.8362, -20.0247],\n",
      "         [ -1.5081, -15.8216, -16.8685,  ..., -12.8299, -16.7946, -16.8780],\n",
      "         ...,\n",
      "         [ 18.0514, -33.4553, -32.9493,  ..., -18.7780, -33.4261, -33.4608],\n",
      "         [ 18.1888, -33.5455, -33.0411,  ..., -19.0195, -33.5278, -33.5441],\n",
      "         [ 18.6556, -33.4518, -32.8934,  ..., -18.5559, -33.4438, -33.5221]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 이들도 그녀를 압니다. 그녀의 연구 보트를 알아봅니다. \n",
      "generate: 돌고 래 는 아는 를 를 그녀는. 를. 수.\n",
      "output tensor([[[  2.4470, -20.7849, -22.2214,  ..., -11.3704, -21.0072, -21.3719],\n",
      "         [ -2.6964, -19.5131, -20.0450,  ..., -10.0038, -19.4349, -20.5012],\n",
      "         [ -0.2991, -19.8342, -19.7158,  ..., -11.3555, -19.5290, -20.0776],\n",
      "         ...,\n",
      "         [ 17.4420, -32.0533, -31.3936,  ..., -17.7686, -31.8226, -32.0795],\n",
      "         [ 17.5237, -32.1977, -31.5304,  ..., -17.9315, -31.9674, -32.2264],\n",
      "         [ 17.8734, -31.1769, -30.8688,  ..., -17.2267, -31.1221, -31.3611]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 18 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 2.597 | Test Loss: 4.232\n",
      "\tBLEU Score:\n",
      "\t\tavg: 1.107\n",
      "\t\t1-gram: 14.776\n",
      "\t\t2-gram: 1.508\n",
      "\t\t3-gram: 0.462\n",
      "\t\t4-gram: 0.146\n",
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456043, 1.065565142789168, 1.1217228300472808, 1.1251005772205362, 0.9376270106656373, 0.945841750555376, 1.032552971972674, 1.108516565724771, 1.025004961153448, 1.246391054667423, 1.1066860083111192], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167303, 15.54081410196518, 15.068451007537302, 15.399544082311628, 15.2570938285224, 14.557690604799433, 15.290158268146262, 14.485009531511755, 14.7281302838836, 15.018685290694112, 14.776259456923347], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.525142876466809, 1.551031253113687, 1.6259629568923126, 1.6052787078983652, 1.50159952993406, 1.3394397565795664, 1.5621974049448066, 1.6277358837594262, 1.5357446942701272, 1.6478496377993863, 1.5076942246588998], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.4751196866386188, 0.4233519513323135, 0.4630766532187335, 0.4637762630876256, 0.4086051547111825, 0.3815388734562736, 0.4589055275688358, 0.4702501469531709, 0.4510114099155195, 0.530596572066883, 0.46174799853835163], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.132895559724828, 0.1263351326518892, 0.1395436545351687, 0.1397650436293582, 0.0825639870899947, 0.1075770072076594, 0.1036998629680382, 0.1361874498027028, 0.1082055906221821, 0.1837821618783287, 0.14581925525482803]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:32<00:00, 14.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Time: 11m 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 190.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 우리는 걸으면서 미국을 가까이서 봤습니다. \n",
      "generate: 우리는 먼 보면, 미국 미국으로 미국으로...\n",
      "output tensor([[[  2.9800, -24.9639, -26.3938,  ..., -18.0592, -25.4928, -25.8022],\n",
      "         [ -0.9292, -17.4091, -16.9815,  ..., -13.1890, -17.5374, -18.1824],\n",
      "         [ -1.6298, -19.4412, -19.5724,  ..., -15.1441, -19.1477, -19.8846],\n",
      "         ...,\n",
      "         [ 17.7302, -30.0018, -29.6782,  ..., -17.7570, -29.8359, -30.3491],\n",
      "         [ 17.7026, -29.8890, -29.5589,  ..., -17.6561, -29.7329, -30.2476],\n",
      "         [ 17.7666, -30.4683, -30.0380,  ..., -17.4429, -30.2289, -30.7702]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 휠체어를 타고 있는 남자였는데 필사적으로 움직이려는 중이었습니다. \n",
      "generate: 이 휠 휠 휠 체 체 체 려 위해 위해 위해 노력 노력.\n",
      "output tensor([[[ -0.3668, -23.8483, -24.6535,  ..., -14.2895, -24.2610, -24.0747],\n",
      "         [ -0.1415, -19.8136, -19.7369,  ..., -10.0761, -21.2002, -19.7765],\n",
      "         [  0.5945, -18.4728, -18.1193,  ...,  -8.5989, -19.1413, -17.6596],\n",
      "         ...,\n",
      "         [ 17.3200, -32.7039, -32.3304,  ..., -19.3551, -32.6333, -33.1077],\n",
      "         [ 17.3771, -32.8035, -32.3365,  ..., -18.9556, -32.6546, -33.1305],\n",
      "         [ 17.5139, -35.0126, -34.4141,  ..., -19.8382, -34.9443, -35.2936]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 이 실험은 우리가 물건을 어떻게 평가하는지에 대해 말해줍니다. \n",
      "generate: 물론 그것이 우리가 우리가 판단 판단 판단 하는 도 도 대한..\n",
      "output tensor([[[  2.4580, -22.8592, -23.7791,  ..., -14.8101, -23.1778, -22.5008],\n",
      "         [ -2.1324, -20.5284, -19.1026,  ...,  -8.6782, -20.1394, -19.7947],\n",
      "         [ -2.1283, -19.1554, -18.2952,  ..., -11.5660, -19.3422, -18.4404],\n",
      "         ...,\n",
      "         [ 16.3303, -30.1981, -29.5527,  ..., -18.5359, -29.9730, -30.0178],\n",
      "         [ 16.5995, -30.5622, -29.8775,  ..., -18.3934, -30.3602, -30.4484],\n",
      "         [ 17.6144, -33.0001, -32.1693,  ..., -18.8716, -32.9862, -32.9472]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence (웃음) 그리고 세번째로 가장 중요한.. (웃음) 사과하는 투로 말하지 마세요. \n",
      "generate: ( 웃음 ) 세 번째로 ) ). ( ) ) ) 부끄러 심 심 마세요 마세요 마세요.\n",
      "output tensor([[[  3.0090, -23.1678, -25.0906,  ..., -17.2161, -24.0181, -23.8023],\n",
      "         [  0.0434, -20.2598, -21.0840,  ..., -16.2001, -20.6952, -21.4726],\n",
      "         [  2.5166, -18.4070, -19.8124,  ..., -14.3231, -18.2119, -18.4337],\n",
      "         ...,\n",
      "         [ 17.5656, -27.6338, -27.5651,  ..., -15.3854, -27.7295, -27.9175],\n",
      "         [ 17.4944, -26.8083, -26.4251,  ..., -15.3814, -26.7669, -27.0429],\n",
      "         [ 17.8783, -32.0129, -31.5116,  ..., -18.0136, -31.9618, -32.3234]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 19 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 2.551 | Test Loss: 4.262\n",
      "\tBLEU Score:\n",
      "\t\tavg: 1.014\n",
      "\t\t1-gram: 14.369\n",
      "\t\t2-gram: 1.531\n",
      "\t\t3-gram: 0.463\n",
      "\t\t4-gram: 0.104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456043, 1.065565142789168, 1.1217228300472808, 1.1251005772205362, 0.9376270106656373, 0.945841750555376, 1.032552971972674, 1.108516565724771, 1.025004961153448, 1.246391054667423, 1.1066860083111192, 1.0136808173874745], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167303, 15.54081410196518, 15.068451007537302, 15.399544082311628, 15.2570938285224, 14.557690604799433, 15.290158268146262, 14.485009531511755, 14.7281302838836, 15.018685290694112, 14.776259456923349, 14.368787418717236], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.525142876466809, 1.551031253113687, 1.6259629568923126, 1.6052787078983652, 1.50159952993406, 1.3394397565795664, 1.5621974049448066, 1.6277358837594262, 1.5357446942701272, 1.6478496377993863, 1.5076942246588998, 1.5314959433589597], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.4751196866386188, 0.4233519513323135, 0.4630766532187335, 0.4637762630876256, 0.4086051547111825, 0.3815388734562736, 0.4589055275688358, 0.4702501469531709, 0.4510114099155195, 0.530596572066883, 0.4617479985383516, 0.4626484195541752], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.132895559724828, 0.1263351326518892, 0.1395436545351687, 0.1397650436293582, 0.0825639870899947, 0.1075770072076594, 0.1036998629680382, 0.1361874498027028, 0.1082055906221821, 0.1837821618783287, 0.145819255254828, 0.10370933729733467]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:32<00:00, 14.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Time: 11m 39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 194.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 알바니아와 같은 국가에서 행정부의 비리는 -- 그리스와 같다고 제가 말할 수 있는 것은 아니지만 -- 현대화를 통해 극복할 수 있는 문제입니다. \n",
      "generate: 그리고 국가 의, 부패,, 같은 같은 같은 같은 같은 같은 국가 부패 부패 부패 부패 부패 있습니다 있습니다.\n",
      "output tensor([[[  0.5730, -20.1150, -21.3876,  ..., -15.3380, -20.9503, -20.7876],\n",
      "         [ -1.2118, -19.6538, -19.5634,  ..., -11.1593, -20.0485, -19.6596],\n",
      "         [  0.9120, -12.7389, -12.4707,  ...,  -8.1278, -11.8149, -11.7274],\n",
      "         ...,\n",
      "         [  9.2934, -20.8626, -19.8543,  ..., -12.0362, -20.0219, -19.5131],\n",
      "         [  9.5549, -21.1305, -20.2955,  ..., -10.5942, -20.1682, -20.1128],\n",
      "         [ 17.4804, -27.3042, -26.7166,  ..., -15.5779, -27.1291, -26.4142]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 한번은 이런 이야기를 들었어요. 갤러리를 운영하는 한 여성의 종업원들이 있었는데, \n",
      "generate: 그리고 밤 밤 밤에 한 한 한 들었는데. 있었어요 사진에 한 한.....\n",
      "output tensor([[[  1.7386, -20.0600, -20.9884,  ..., -11.7478, -20.9829, -20.1330],\n",
      "         [  0.6032, -16.5964, -18.0390,  ...,  -8.7601, -16.3385, -17.3754],\n",
      "         [ -0.9380, -11.0290, -11.9607,  ...,  -9.0853, -12.2647, -12.3790],\n",
      "         ...,\n",
      "         [ 16.6162, -20.1884, -20.1606,  ..., -11.7150, -20.7086, -20.5412],\n",
      "         [ 15.8672, -21.1364, -20.9025,  ..., -13.3355, -21.3544, -21.2316],\n",
      "         [ 19.3253, -28.0237, -28.3794,  ..., -17.5597, -28.1762, -28.5529]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 그리고 저희가 판타날에서 작년 12월에 붙잡은 테드, 이 아기 테이퍼를 위해서도 계속할 것입니다. \n",
      "generate: 그래서 작년 에 에 10월 에 에 에 에 작년. 에 퍼 퍼 의 트 트 트 트 에 에 에서 에서 에서 랜드 에서 에서...\n",
      "output tensor([[[  0.0988, -20.0999, -22.0262,  ..., -14.7189, -21.4467, -20.8981],\n",
      "         [ -1.1342, -21.3675, -23.0062,  ..., -13.0048, -21.1950, -22.5574],\n",
      "         [ -1.1474, -15.4644, -16.1416,  ...,  -9.6043, -16.2092, -16.1468],\n",
      "         ...,\n",
      "         [  4.7334, -17.7632, -19.2613,  ..., -10.0687, -18.5450, -17.7880],\n",
      "         [  4.6112, -17.9876, -18.7447,  ...,  -9.9236, -18.2878, -17.5709],\n",
      "         [ 15.5320, -22.0816, -21.5725,  ..., -12.6879, -21.7533, -21.7420]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 우주적인 우리들과 그들, 그리고 가장 최악의 선호주의라는 죄가 있는 하나님? \n",
      "generate: 같은 같은, 저와 저 저 신이 악 한 한 악 악 악 악 악 악 인 인 인.?\n",
      "output tensor([[[ -0.7146, -20.3957, -21.9336,  ..., -16.3659, -22.0284, -21.6877],\n",
      "         [ -3.4184, -23.3659, -23.6507,  ..., -13.4389, -23.8879, -23.2396],\n",
      "         [ -2.6705, -26.5104, -26.7914,  ..., -17.8038, -28.0590, -26.4406],\n",
      "         ...,\n",
      "         [ 11.6341, -22.5488, -22.5296,  ..., -14.9415, -23.3705, -22.3653],\n",
      "         [ 15.6820, -25.5053, -25.2820,  ..., -16.6812, -25.9786, -25.8152],\n",
      "         [ 17.9273, -28.5559, -28.9904,  ..., -18.9210, -28.7480, -29.4439]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 20 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 2.509 | Test Loss: 4.293\n",
      "\tBLEU Score:\n",
      "\t\tavg: 0.895\n",
      "\t\t1-gram: 14.640\n",
      "\t\t2-gram: 1.472\n",
      "\t\t3-gram: 0.390\n",
      "\t\t4-gram: 0.076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456043, 1.065565142789168, 1.1217228300472808, 1.1251005772205362, 0.9376270106656373, 0.945841750555376, 1.032552971972674, 1.108516565724771, 1.025004961153448, 1.246391054667423, 1.1066860083111192, 1.0136808173874745, 0.8953404182688746], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167303, 15.54081410196518, 15.068451007537302, 15.399544082311628, 15.2570938285224, 14.557690604799433, 15.290158268146262, 14.485009531511755, 14.7281302838836, 15.018685290694112, 14.776259456923349, 14.368787418717236, 14.639612718144873], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.525142876466809, 1.551031253113687, 1.6259629568923126, 1.6052787078983652, 1.50159952993406, 1.3394397565795664, 1.5621974049448066, 1.6277358837594262, 1.5357446942701272, 1.6478496377993863, 1.5076942246588998, 1.5314959433589597, 1.4715230104246122], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.4751196866386188, 0.4233519513323135, 0.4630766532187335, 0.4637762630876256, 0.4086051547111825, 0.3815388734562736, 0.4589055275688358, 0.4702501469531709, 0.4510114099155195, 0.530596572066883, 0.4617479985383516, 0.4626484195541752, 0.3903068150963888], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.132895559724828, 0.1263351326518892, 0.1395436545351687, 0.1397650436293582, 0.0825639870899947, 0.1075770072076594, 0.1036998629680382, 0.1361874498027028, 0.1082055906221821, 0.1837821618783287, 0.145819255254828, 0.1037093372973346, 0.07642755759362375]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:32<00:00, 14.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Time: 11m 36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 191.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 그분들의 공통점은 정말 열심히 일했다는 것입니다. \n",
      "generate: 그들은 모두가 점은 점은 공통 공통 아주 열심히 열심히..\n",
      "output tensor([[[  2.7937, -22.8033, -24.0883,  ..., -14.8683, -23.5730, -23.0438],\n",
      "         [ -1.5605, -19.5320, -20.0425,  ..., -12.3743, -20.6249, -19.9991],\n",
      "         [ -0.9240, -17.9594, -18.0328,  ..., -11.6508, -18.1790, -17.2197],\n",
      "         ...,\n",
      "         [ 15.4625, -35.7732, -35.2361,  ..., -19.6781, -35.6255, -35.9527],\n",
      "         [ 15.2624, -36.1816, -35.6490,  ..., -19.8676, -36.0866, -36.3714],\n",
      "         [ 16.4272, -35.8777, -35.1219,  ..., -19.1506, -35.7629, -36.0733]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 그 뒤에야 기반 시설을 세우고 재정을 관리해 나갔습니다 \n",
      "generate: 그 당시,,,,,,, 을 었.\n",
      "output tensor([[[ -0.0700, -21.3981, -23.3066,  ..., -16.5392, -22.4138, -22.0739],\n",
      "         [ -2.9425, -18.4405, -18.0284,  ..., -15.3450, -19.4852, -18.8110],\n",
      "         [ -3.3392, -21.4756, -21.0368,  ..., -12.0274, -21.6967, -21.1632],\n",
      "         ...,\n",
      "         [ 16.5797, -28.2305, -27.8782,  ..., -17.2111, -28.1142, -28.4385],\n",
      "         [ 16.3267, -28.7543, -28.3593,  ..., -17.5247, -28.5798, -28.9006],\n",
      "         [ 18.1531, -33.9419, -33.2488,  ..., -19.3821, -33.7826, -33.9974]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 이걸 사용하는 건 어떨까요? 여기 3번과 결합해보세요. \n",
      "generate: 그렇다면 어떻게 할까요 할까요?????\n",
      "output tensor([[[  4.2004, -23.8755, -24.9608,  ..., -15.2027, -24.2860, -24.0337],\n",
      "         [ -0.6406, -19.7813, -20.2289,  ..., -11.3824, -19.6273, -20.2794],\n",
      "         [ -0.9582, -16.5261, -17.3897,  ..., -11.1642, -16.9335, -17.1470],\n",
      "         ...,\n",
      "         [ 17.6408, -28.2291, -27.9974,  ..., -16.9064, -28.2235, -28.4435],\n",
      "         [ 17.1660, -30.9308, -30.6092,  ..., -18.2405, -30.8713, -31.0652],\n",
      "         [ 16.7384, -38.3911, -37.8491,  ..., -21.2962, -38.2954, -38.4373]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 아시겠죠? 어떤 색인지 골라 보세요. \n",
      "generate: 무슨 뭔지 말해 말해 말해 말해\n",
      "output tensor([[[  3.4841, -24.2164, -25.7902,  ..., -15.6108, -24.8342, -24.6889],\n",
      "         [ -2.0672, -26.9314, -27.3445,  ..., -14.6078, -27.4428, -27.2434],\n",
      "         [  0.4589, -19.4827, -20.0907,  ..., -16.3947, -20.1267, -20.8340],\n",
      "         ...,\n",
      "         [ 17.4923, -32.9837, -31.8879,  ..., -18.3397, -32.7566, -33.2047],\n",
      "         [ 17.4727, -32.9785, -31.8867,  ..., -18.2799, -32.7509, -33.2140],\n",
      "         [ 18.9845, -32.5168, -31.3759,  ..., -16.9307, -32.0593, -32.7298]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 21 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 2.467 | Test Loss: 4.341\n",
      "\tBLEU Score:\n",
      "\t\tavg: 1.001\n",
      "\t\t1-gram: 14.577\n",
      "\t\t2-gram: 1.513\n",
      "\t\t3-gram: 0.443\n",
      "\t\t4-gram: 0.103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456043, 1.065565142789168, 1.1217228300472808, 1.1251005772205362, 0.9376270106656373, 0.945841750555376, 1.032552971972674, 1.108516565724771, 1.025004961153448, 1.246391054667423, 1.1066860083111192, 1.0136808173874745, 0.8953404182688746, 1.0005658195083458], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167303, 15.54081410196518, 15.068451007537302, 15.399544082311628, 15.2570938285224, 14.557690604799433, 15.290158268146262, 14.485009531511755, 14.7281302838836, 15.018685290694112, 14.776259456923349, 14.368787418717236, 14.639612718144871, 14.576825387557294], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.525142876466809, 1.551031253113687, 1.6259629568923126, 1.6052787078983652, 1.50159952993406, 1.3394397565795664, 1.5621974049448066, 1.6277358837594262, 1.5357446942701272, 1.6478496377993863, 1.5076942246588998, 1.5314959433589597, 1.4715230104246122, 1.5130375468948625], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.4751196866386188, 0.4233519513323135, 0.4630766532187335, 0.4637762630876256, 0.4086051547111825, 0.3815388734562736, 0.4589055275688358, 0.4702501469531709, 0.4510114099155195, 0.530596572066883, 0.4617479985383516, 0.4626484195541752, 0.3903068150963888, 0.4429312795425247], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.132895559724828, 0.1263351326518892, 0.1395436545351687, 0.1397650436293582, 0.0825639870899947, 0.1075770072076594, 0.1036998629680382, 0.1361874498027028, 0.1082055906221821, 0.1837821618783287, 0.145819255254828, 0.1037093372973346, 0.0764275575936237, 0.10259675935753201]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:31<00:00, 14.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Time: 11m 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 190.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence (박수) \n",
      "generate: ( 박수 )\n",
      "output tensor([[[  1.3457, -25.2497, -26.3496,  ..., -18.7886, -25.6974, -25.2443],\n",
      "         [  1.4290, -20.1923, -20.0781,  ..., -15.0377, -20.2765, -19.5536],\n",
      "         [  3.6743, -19.8989, -18.9453,  ..., -13.3403, -19.7748, -19.9535],\n",
      "         ...,\n",
      "         [ 15.3037, -29.3383, -28.6001,  ..., -20.3494, -29.1669, -29.8434],\n",
      "         [ 15.3330, -29.3498, -28.5802,  ..., -20.2738, -29.1804, -29.8571],\n",
      "         [ 15.2876, -29.7386, -28.8285,  ..., -20.1482, -29.5717, -30.0859]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence [호박 쓰레기 브레이크] (웃음) [땅콩 버터 슬라임] [딸기 크림 질병] (웃음) 이 맛들은 저희가 바랐던 것 만큼 맛있지 않습니다. \n",
      "generate: [ 카 잡 물 소리. ( [ [ [ [ [ [ [ ] ] [ ] ] ] ]... ],....\n",
      "output tensor([[[ -0.1473, -22.0362, -23.6669,  ..., -15.8572, -23.1240, -22.2349],\n",
      "         [ -0.8537, -15.6627, -16.1123,  ..., -11.2712, -15.8800, -16.1015],\n",
      "         [ -0.9789, -13.8658, -13.5319,  ...,  -7.2962, -12.9586, -13.7617],\n",
      "         ...,\n",
      "         [ -1.3457, -19.9950, -20.4469,  ..., -14.2096, -20.1608, -20.5731],\n",
      "         [  0.2956, -15.5728, -15.4457,  ...,  -9.2956, -15.8003, -16.5923],\n",
      "         [ 10.2107, -21.8037, -22.1536,  ..., -13.0118, -21.5672, -22.0859]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence (웃음) 그런데 말이죠. 그래도 괜찮아요. 저는 이미 MIT에서 정교수니까요. \n",
      "generate: ( 웃음 ) 알,, 저는. 평생...\n",
      "output tensor([[[  4.2066, -22.4940, -23.7823,  ..., -12.3478, -23.5914, -22.8223],\n",
      "         [  0.2833, -16.4288, -17.0564,  ...,  -7.3987, -16.5551, -16.4559],\n",
      "         [  0.9575, -14.5279, -15.0918,  ...,  -7.1795, -14.5450, -13.8571],\n",
      "         ...,\n",
      "         [ 19.0152, -21.9137, -21.9272,  ..., -11.3535, -22.7387, -22.3117],\n",
      "         [ 18.8725, -22.1503, -21.9541,  ..., -12.1075, -22.5603, -22.4857],\n",
      "         [ 18.3765, -28.1899, -27.6585,  ..., -15.8088, -28.6855, -28.7595]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 그래서 저는 그레타처럼 위험을 무릅쓰고 미국 권력의 중심지인 워싱턴 DC로 가서 학생들처럼 매주 금요일에 시위를 벌여야겠다고 마음먹었습니다. \n",
      "generate: 그래서 저는 커 와 와 처럼 처럼 미국 최 권 권 미국 미국 미국의 고 로 로 로 집중 로 집중.....\n",
      "output tensor([[[  0.3280, -21.9372, -23.3597,  ..., -16.6133, -22.8190, -22.8772],\n",
      "         [ -0.8649, -24.5998, -24.0198,  ..., -16.4240, -24.3384, -25.5298],\n",
      "         [ -0.3256, -19.8259, -20.6201,  ..., -18.5059, -20.5377, -20.9978],\n",
      "         ...,\n",
      "         [  9.0806, -16.0760, -15.5643,  ..., -11.0665, -16.0113, -16.1222],\n",
      "         [  9.0107, -15.8957, -15.2269,  ..., -11.5556, -15.5856, -15.9855],\n",
      "         [ 18.7299, -25.1229, -25.0975,  ..., -15.5212, -25.2955, -25.8299]]],\n",
      "       device='cuda:0')\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 187.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 2.427 | Test Loss: 4.359\n",
      "\tBLEU Score:\n",
      "\t\tavg: 1.058\n",
      "\t\t1-gram: 14.197\n",
      "\t\t2-gram: 1.435\n",
      "\t\t3-gram: 0.454\n",
      "\t\t4-gram: 0.135\n",
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456043, 1.065565142789168, 1.1217228300472808, 1.1251005772205362, 0.9376270106656373, 0.945841750555376, 1.032552971972674, 1.108516565724771, 1.025004961153448, 1.246391054667423, 1.1066860083111192, 1.0136808173874745, 0.8953404182688746, 1.0005658195083458, 1.0579186716815774], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167303, 15.54081410196518, 15.068451007537302, 15.399544082311628, 15.2570938285224, 14.557690604799433, 15.290158268146262, 14.485009531511755, 14.7281302838836, 15.018685290694112, 14.776259456923349, 14.368787418717236, 14.639612718144871, 14.576825387557294, 14.197495404411764], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.525142876466809, 1.551031253113687, 1.6259629568923126, 1.6052787078983652, 1.50159952993406, 1.3394397565795664, 1.5621974049448066, 1.6277358837594262, 1.5357446942701272, 1.6478496377993863, 1.5076942246588998, 1.5314959433589597, 1.4715230104246122, 1.5130375468948625, 1.4352754753778645], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.4751196866386188, 0.4233519513323135, 0.4630766532187335, 0.4637762630876256, 0.4086051547111825, 0.3815388734562736, 0.4589055275688358, 0.4702501469531709, 0.4510114099155195, 0.530596572066883, 0.4617479985383516, 0.4626484195541752, 0.3903068150963888, 0.4429312795425247, 0.45430944963655245], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.132895559724828, 0.1263351326518892, 0.1395436545351687, 0.1397650436293582, 0.0825639870899947, 0.1075770072076594, 0.1036998629680382, 0.1361874498027028, 0.1082055906221821, 0.1837821618783287, 0.145819255254828, 0.1037093372973346, 0.0764275575936237, 0.102596759357532, 0.1353039134054954]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:32<00:00, 14.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Time: 11m 39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:55<00:00, 44.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Test Time: 0m 55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 194.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 민주주의가 진정으로 필요한 약이기 때문입니다. \n",
      "generate: 우리 민주주의 민주주의 는 민주주의 필요한 필요한 필요한 입니다 입니다\n",
      "output tensor([[[ -0.4598, -25.7549, -26.8446,  ..., -19.1587, -26.2146, -25.9332],\n",
      "         [ -3.2337, -21.5273, -21.7065,  ..., -12.5526, -22.1064, -21.3788],\n",
      "         [ -5.7061, -22.9318, -23.4448,  ..., -13.1273, -23.7338, -22.7266],\n",
      "         ...,\n",
      "         [ 17.4394, -33.9156, -33.5301,  ..., -20.3694, -34.0960, -34.2916],\n",
      "         [ 17.5271, -33.9439, -33.5175,  ..., -20.2799, -34.1019, -34.2980],\n",
      "         [ 18.1377, -35.1391, -34.5153,  ..., -19.8293, -35.1576, -35.3166]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 암은 참 거지 같죠. 암에 걸리게 되면 병원에서 사생활은 거의 없어지죠. 대부분의 시간 동안 벌거벗고 있습니다. \n",
      "generate: 암 암 걸리 걸리 때 때 제약 생활 생활 생활을 없을.. 대부분의 인 인 으로 으로 으로 을....\n",
      "output tensor([[[ -1.2799, -24.4791, -25.7868,  ..., -16.5246, -25.2652, -25.1331],\n",
      "         [ -4.1804, -17.7301, -18.9048,  ...,  -8.5397, -18.0854, -17.7125],\n",
      "         [ -2.7913, -16.5982, -18.0030,  ..., -12.4173, -17.0303, -18.5409],\n",
      "         ...,\n",
      "         [  9.8746, -17.7317, -16.9713,  ..., -10.5606, -17.6098, -17.2434],\n",
      "         [ 10.1562, -17.9068, -17.4964,  ..., -10.8635, -18.1450, -17.6491],\n",
      "         [ 17.9630, -26.6336, -26.5725,  ..., -15.3666, -26.7585, -26.7824]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 저는 조금 다르게 사용하고 있습니다. \n",
      "generate: 하지만 저는 접근 다른 접근 접근 달랐 달랐..\n",
      "output tensor([[[ -1.2148, -25.3486, -26.5580,  ..., -18.0093, -26.0875, -26.2760],\n",
      "         [ -1.6858, -12.5371, -12.8650,  ...,  -7.2134, -12.1858, -13.8462],\n",
      "         [ -1.3856, -13.4753, -14.6431,  ...,  -8.3269, -14.7831, -15.5952],\n",
      "         ...,\n",
      "         [ 18.1350, -31.5046, -30.7984,  ..., -18.0137, -31.4250, -32.0740],\n",
      "         [ 18.1534, -31.0927, -30.3388,  ..., -17.5936, -30.9970, -31.6158],\n",
      "         [ 19.0369, -30.8572, -30.0444,  ..., -16.4402, -30.6870, -31.2091]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 이틀 전부터, 나이로비 외곽의 작은 농장에서 일하는 한 분과 일을 시작했는데 태양열로 작동되는 관개용 펌프 덕에 생산성이 높아졌다고 자랑하셨어요. \n",
      "generate: 몇 달 전 농 나이 잠깐 나이 부를 농 소규모 농 소규모 농 농 농 한 부 부 부 부들 부들 부들 농장 농장 농장 부가 할머니 부가..\n",
      "output tensor([[[ -1.1064, -20.8560, -21.9745,  ..., -11.6353, -21.5740, -21.4686],\n",
      "         [ -1.9264, -17.8396, -17.0455,  ...,  -2.0723, -16.7574, -16.6157],\n",
      "         [ -0.5783, -18.1666, -17.2613,  ...,  -7.4899, -18.3724, -17.6789],\n",
      "         ...,\n",
      "         [  0.9537, -17.6051, -17.4794,  ..., -11.3435, -17.9249, -16.6851],\n",
      "         [  1.4614, -17.4591, -17.2222,  ...,  -9.2222, -16.9340, -16.8300],\n",
      "         [ 12.9566, -19.7705, -20.3334,  ..., -13.0109, -20.0263, -20.0013]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 23 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 2.390 | Test Loss: 4.411\n",
      "\tBLEU Score:\n",
      "\t\tavg: 1.052\n",
      "\t\t1-gram: 14.849\n",
      "\t\t2-gram: 1.531\n",
      "\t\t3-gram: 0.440\n",
      "\t\t4-gram: 0.122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456043, 1.065565142789168, 1.1217228300472808, 1.1251005772205362, 0.9376270106656373, 0.945841750555376, 1.032552971972674, 1.108516565724771, 1.025004961153448, 1.246391054667423, 1.1066860083111192, 1.0136808173874745, 0.8953404182688746, 1.0005658195083458, 1.0579186716815774, 1.0521420193171727], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167303, 15.54081410196518, 15.068451007537302, 15.399544082311628, 15.2570938285224, 14.557690604799433, 15.290158268146262, 14.485009531511755, 14.7281302838836, 15.018685290694112, 14.776259456923349, 14.368787418717236, 14.639612718144871, 14.576825387557294, 14.197495404411764, 14.849490400568856], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.525142876466809, 1.551031253113687, 1.6259629568923126, 1.6052787078983652, 1.50159952993406, 1.3394397565795664, 1.5621974049448066, 1.6277358837594262, 1.5357446942701272, 1.6478496377993863, 1.5076942246588998, 1.5314959433589597, 1.4715230104246122, 1.5130375468948625, 1.4352754753778645, 1.530612244897959], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.4751196866386188, 0.4233519513323135, 0.4630766532187335, 0.4637762630876256, 0.4086051547111825, 0.3815388734562736, 0.4589055275688358, 0.4702501469531709, 0.4510114099155195, 0.530596572066883, 0.4617479985383516, 0.4626484195541752, 0.3903068150963888, 0.4429312795425247, 0.4543094496365524, 0.44030653401452], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.132895559724828, 0.1263351326518892, 0.1395436545351687, 0.1397650436293582, 0.0825639870899947, 0.1075770072076594, 0.1036998629680382, 0.1361874498027028, 0.1082055906221821, 0.1837821618783287, 0.145819255254828, 0.1037093372973346, 0.0764275575936237, 0.102596759357532, 0.1353039134054954, 0.1224519196139163]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:32<00:00, 14.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Time: 11m 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 192.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 우리에게 점점 이야기보다 센세이션이 주가 된 메뉴가 제공되고 있읍니다. \n",
      "generate: 우리는 이런 이러한 코에 감각 전달 전달 각 감동... 모든 텔 모든 관심을 모든 관심을..\n",
      "output tensor([[[  2.7108, -22.0936, -23.1274,  ..., -16.9671, -22.7249, -22.1860],\n",
      "         [ -3.6381, -20.2044, -20.1803,  ..., -14.5446, -20.2167, -19.9452],\n",
      "         [ -4.2756, -18.9220, -18.2482,  ...,  -9.8756, -18.8426, -18.7972],\n",
      "         ...,\n",
      "         [ 15.0691, -28.5437, -27.8147,  ..., -15.0598, -28.2371, -28.9527],\n",
      "         [ 17.1369, -23.9248, -24.2820,  ..., -13.5376, -24.0919, -24.5470],\n",
      "         [ 19.2806, -27.8303, -27.8861,  ..., -15.8402, -27.8764, -28.2398]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 올 연말까지 백만달러 이상의 가치를 빈곤자의 건강 증진에 공헌 했습니다. 올 1/4분기에 34만달러이며, 평균 매월 8만 5천 달러 입니다. 정부가 이렇게 하지 않는 것은 정부는 다른 문제들도 해결 해야 하기 때문 입니다. \n",
      "generate: 올해 말 우리는 우리는 우리는 에 에 만 들 할..... 걸리는 걸리는 과 환자 들 들. 치료 과 할.. 투자가..\n",
      "output tensor([[[ -1.9773, -23.1036, -24.8147,  ..., -17.6415, -24.3083, -24.0714],\n",
      "         [ -1.3789,  -9.8437, -11.2586,  ...,  -8.3489, -11.9993, -10.7212],\n",
      "         [  0.1825, -14.5964, -15.9506,  ..., -10.8451, -15.6335, -14.8406],\n",
      "         ...,\n",
      "         [  3.4563, -17.9115, -18.8305,  ..., -11.2685, -18.4379, -18.4765],\n",
      "         [  4.3643, -17.2786, -18.6113,  ..., -12.4178, -18.0348, -18.4331],\n",
      "         [ 14.5711, -26.6837, -27.4636,  ..., -17.1546, -27.0643, -27.0073]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 부정행위로부터 거리감을 느낄수록 가령 돈과 같은 대상과 거리가 멀수록 부정행위가 늘어납니다. \n",
      "generate: 우리가 뇌물 과 저축 부정 부정 부정 부정, 율 율 부정 부정 율 수록 수록 니..\n",
      "output tensor([[[  0.3326, -20.3868, -21.9119,  ..., -15.5641, -21.3951, -21.1139],\n",
      "         [ -4.2247, -19.0258, -19.4518,  ..., -12.1321, -18.8371, -19.5320],\n",
      "         [ -1.8487, -16.6938, -16.5992,  ...,  -9.3945, -16.1490, -17.6229],\n",
      "         ...,\n",
      "         [ 17.0796, -18.3837, -18.4288,  ..., -10.8845, -18.9084, -19.1318],\n",
      "         [ 16.4131, -19.3638, -19.0086,  ..., -11.3218, -19.5533, -19.6153],\n",
      "         [ 20.3512, -29.6361, -29.3159,  ..., -17.1555, -29.7608, -29.8960]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence KA: 포기하실려는 생각은 없으셨나요. \n",
      "generate: : 그 포기 포기 하지 하지 하지???\n",
      "output tensor([[[ -0.0689, -20.4678, -21.5967,  ..., -13.5356, -21.0909, -20.9362],\n",
      "         [ -2.1212, -19.0540, -17.7761,  ...,  -6.6673, -18.9481, -17.7545],\n",
      "         [ -1.8287, -22.0681, -21.9114,  ...,  -7.1403, -23.2301, -21.4763],\n",
      "         ...,\n",
      "         [ 18.0249, -34.4650, -34.1662,  ..., -20.1585, -34.1947, -34.8678],\n",
      "         [ 18.1473, -34.7917, -34.4696,  ..., -20.2272, -34.4973, -35.1791],\n",
      "         [ 19.7486, -37.0694, -36.7777,  ..., -20.5381, -36.7157, -37.4577]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 24 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 2.354 | Test Loss: 4.467\n",
      "\tBLEU Score:\n",
      "\t\tavg: 0.911\n",
      "\t\t1-gram: 14.559\n",
      "\t\t2-gram: 1.518\n",
      "\t\t3-gram: 0.399\n",
      "\t\t4-gram: 0.078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456043, 1.065565142789168, 1.1217228300472808, 1.1251005772205362, 0.9376270106656373, 0.945841750555376, 1.032552971972674, 1.108516565724771, 1.025004961153448, 1.246391054667423, 1.1066860083111192, 1.0136808173874745, 0.8953404182688746, 1.0005658195083458, 1.0579186716815774, 1.0521420193171729, 0.9113153109680574], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167303, 15.54081410196518, 15.068451007537302, 15.399544082311628, 15.2570938285224, 14.557690604799433, 15.290158268146262, 14.485009531511755, 14.7281302838836, 15.018685290694112, 14.776259456923349, 14.368787418717236, 14.639612718144871, 14.576825387557294, 14.197495404411764, 14.849490400568856, 14.558521560574949], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.525142876466809, 1.551031253113687, 1.6259629568923126, 1.6052787078983652, 1.50159952993406, 1.3394397565795664, 1.5621974049448066, 1.6277358837594262, 1.5357446942701272, 1.6478496377993863, 1.5076942246588998, 1.5314959433589597, 1.4715230104246122, 1.5130375468948625, 1.4352754753778645, 1.530612244897959, 1.5176067310688688], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.4751196866386188, 0.4233519513323135, 0.4630766532187335, 0.4637762630876256, 0.4086051547111825, 0.3815388734562736, 0.4589055275688358, 0.4702501469531709, 0.4510114099155195, 0.530596572066883, 0.4617479985383516, 0.4626484195541752, 0.3903068150963888, 0.4429312795425247, 0.4543094496365524, 0.44030653401452, 0.3988035892323031], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.132895559724828, 0.1263351326518892, 0.1395436545351687, 0.1397650436293582, 0.0825639870899947, 0.1075770072076594, 0.1036998629680382, 0.1361874498027028, 0.1082055906221821, 0.1837821618783287, 0.145819255254828, 0.1037093372973346, 0.0764275575936237, 0.102596759357532, 0.1353039134054954, 0.1224519196139163, 0.07827788649706457]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:32<00:00, 14.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Time: 11m 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 189.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 중요한 점은 그 의미의 뜻을 우리가 정한다는 것입니다. \n",
      "generate: 우리는 에 에 에 에 에 에 정의 합니다..\n",
      "output tensor([[[ -2.4665, -22.9316, -24.2135,  ..., -16.8081, -23.8446, -23.0463],\n",
      "         [ -1.8364, -23.0346, -23.9041,  ..., -15.2190, -23.8834, -22.8765],\n",
      "         [ -4.9469, -20.6395, -21.3377,  ..., -17.0214, -21.2545, -21.2450],\n",
      "         ...,\n",
      "         [ 17.2961, -33.6012, -33.2979,  ..., -20.2701, -33.3542, -33.6227],\n",
      "         [ 17.3350, -33.8901, -33.5965,  ..., -20.4182, -33.6611, -33.9414],\n",
      "         [ 17.6846, -35.8387, -35.4676,  ..., -20.5923, -35.5160, -35.8355]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 그리고 그들은 거리에서 변화를 야기할, 주로 여성들과 다소의 남성들로 이루어진 수 만의 사람들을 모을 수가 있었습니다. \n",
      "generate: 그들은 만 명의 명의 명의 과 과 과 들 들 들 들 들 거리 거리 거리 거리 거리 여성 거리 행 행 행....\n",
      "output tensor([[[ -3.6607, -23.1501, -24.2037,  ..., -16.4183, -23.4691, -23.2197],\n",
      "         [ -3.8379, -29.8109, -30.1519,  ..., -16.0398, -30.4395, -30.1894],\n",
      "         [ -2.8518, -18.8329, -19.4430,  ..., -10.6272, -20.0230, -19.5716],\n",
      "         ...,\n",
      "         [  4.7973, -21.2104, -20.9137,  ..., -15.0049, -21.1737, -21.4199],\n",
      "         [  5.1427, -21.4886, -20.8867,  ..., -14.9689, -21.1991, -21.3880],\n",
      "         [ 13.7195, -21.4114, -21.5748,  ..., -12.8887, -20.8078, -21.4614]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 제가 말했습니다. \n",
      "generate: 제가 이렇게.. \" \" 하라...\n",
      "output tensor([[[ -1.7886, -20.9374, -22.2620,  ..., -13.6450, -21.7381, -21.2761],\n",
      "         [ -0.3069, -23.2361, -23.7057,  ..., -15.5324, -22.9950, -23.3192],\n",
      "         [  1.3238, -17.1108, -16.7310,  ..., -15.0623, -17.6959, -17.8299],\n",
      "         ...,\n",
      "         [ 16.8043, -29.0629, -28.7645,  ..., -17.5340, -29.1095, -29.3603],\n",
      "         [ 16.9487, -29.1685, -28.9194,  ..., -17.3980, -29.2196, -29.4303],\n",
      "         [ 18.4907, -29.6767, -29.5792,  ..., -16.7163, -29.5593, -30.1097]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence (박수) \n",
      "generate: ( 박수 )\n",
      "output tensor([[[  1.2884, -26.0832, -26.8238,  ..., -19.0832, -26.2328, -25.6829],\n",
      "         [  2.4634, -21.0909, -20.8394,  ..., -13.9167, -20.9846, -20.6279],\n",
      "         [  5.4179, -19.4774, -18.7838,  ..., -12.6977, -19.1777, -19.5105],\n",
      "         ...,\n",
      "         [ 16.2360, -30.0241, -29.2723,  ..., -21.5029, -29.6317, -30.1228],\n",
      "         [ 16.2732, -29.8814, -29.1129,  ..., -21.2604, -29.4937, -30.0056],\n",
      "         [ 16.2996, -28.4510, -27.6602,  ..., -19.8859, -28.0428, -28.5564]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 25 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 2.325 | Test Loss: 4.498\n",
      "\tBLEU Score:\n",
      "\t\tavg: 1.027\n",
      "\t\t1-gram: 14.135\n",
      "\t\t2-gram: 1.613\n",
      "\t\t3-gram: 0.463\n",
      "\t\t4-gram: 0.105\n",
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456043, 1.065565142789168, 1.1217228300472808, 1.1251005772205362, 0.9376270106656373, 0.945841750555376, 1.032552971972674, 1.108516565724771, 1.025004961153448, 1.246391054667423, 1.1066860083111192, 1.0136808173874745, 0.8953404182688746, 1.0005658195083458, 1.0579186716815774, 1.0521420193171729, 0.9113153109680574, 1.0266675521574615], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167303, 15.54081410196518, 15.068451007537302, 15.399544082311628, 15.2570938285224, 14.557690604799433, 15.290158268146262, 14.485009531511755, 14.7281302838836, 15.018685290694112, 14.776259456923349, 14.368787418717236, 14.639612718144871, 14.576825387557294, 14.197495404411764, 14.849490400568856, 14.558521560574947, 14.13503366903045], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.525142876466809, 1.551031253113687, 1.6259629568923126, 1.6052787078983652, 1.50159952993406, 1.3394397565795664, 1.5621974049448066, 1.6277358837594262, 1.5357446942701272, 1.6478496377993863, 1.5076942246588998, 1.5314959433589597, 1.4715230104246122, 1.5130375468948625, 1.4352754753778645, 1.530612244897959, 1.5176067310688688, 1.612698815030733], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.4751196866386188, 0.4233519513323135, 0.4630766532187335, 0.4637762630876256, 0.4086051547111825, 0.3815388734562736, 0.4589055275688358, 0.4702501469531709, 0.4510114099155195, 0.530596572066883, 0.4617479985383516, 0.4626484195541752, 0.3903068150963888, 0.4429312795425247, 0.4543094496365524, 0.44030653401452, 0.3988035892323031, 0.46343278533252147], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.132895559724828, 0.1263351326518892, 0.1395436545351687, 0.1397650436293582, 0.0825639870899947, 0.1075770072076594, 0.1036998629680382, 0.1361874498027028, 0.1082055906221821, 0.1837821618783287, 0.145819255254828, 0.1037093372973346, 0.0764275575936237, 0.102596759357532, 0.1353039134054954, 0.1224519196139163, 0.0782778864970645, 0.10516772438803264]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:32<00:00, 14.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Time: 11m 36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 192.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 당신의 삶은 가사상태에 빠져버리게 됩니다. \n",
      "generate: 여러분은 생활에 피 삶이 는 갑니다...\n",
      "output tensor([[[  1.2688, -27.0667, -27.9430,  ..., -19.6115, -26.9903, -26.8049],\n",
      "         [ -2.3097, -21.5362, -21.1425,  ..., -13.1668, -20.6646, -20.3581],\n",
      "         [ -1.0047, -22.4936, -22.2765,  ..., -14.4277, -22.4542, -21.2691],\n",
      "         ...,\n",
      "         [ 17.3300, -28.1591, -27.6547,  ..., -17.2544, -28.0007, -28.5095],\n",
      "         [ 17.4419, -28.5918, -28.0807,  ..., -17.2688, -28.4130, -28.8468],\n",
      "         [ 18.7876, -31.5774, -31.1764,  ..., -18.1035, -31.5063, -31.7205]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 모하마드는 허물어진 돌무더기 위에서 목욕통을 놓고 그의 아이들에게 매일 아침 거품 목욕을 시켜주었어요. \n",
      "generate: 모 하 하 트 터 로 도 파 에 에 에 매일 매일 매일 매일 수 수 있게 록.\n",
      "output tensor([[[  0.4389, -23.4570, -24.3156,  ..., -14.0133, -23.5480, -23.3670],\n",
      "         [  0.1257, -17.8447, -18.3594,  ...,  -7.2389, -19.4188, -18.3983],\n",
      "         [ -0.6214, -17.6879, -18.2471,  ..., -10.3849, -18.6257, -17.9516],\n",
      "         ...,\n",
      "         [ 15.5787, -21.7592, -21.1541,  ..., -11.4603, -21.4365, -21.4124],\n",
      "         [ 15.5595, -21.9068, -21.4102,  ..., -12.1131, -21.6144, -21.6172],\n",
      "         [ 16.7388, -27.9183, -27.1237,  ..., -14.1129, -27.2691, -28.2240]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence \"내 암이 커지고 있는 걸 느낍니다.\" \n",
      "generate: \" 암 \" 수 수 수 수 수 \" 수 수 걸.\n",
      "output tensor([[[ -2.1812, -24.1799, -25.4846,  ..., -17.9738, -25.0683, -24.5004],\n",
      "         [ -2.5438, -17.5330, -17.2665,  ...,  -9.0951, -17.1000, -16.8225],\n",
      "         [ -2.3672, -22.3616, -23.4717,  ..., -15.8973, -23.0225, -22.5922],\n",
      "         ...,\n",
      "         [ 15.0059, -29.8385, -29.4152,  ..., -19.0284, -29.5209, -30.0422],\n",
      "         [ 15.1641, -30.8186, -30.3358,  ..., -19.3009, -30.3998, -30.9970],\n",
      "         [ 15.9762, -34.2589, -33.8586,  ..., -20.4901, -33.7859, -34.2460]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 자신에게 초점을 맞추느냐와 다른 사람에게 초점을 맞추느냐에는 매우 미묘한 차이가 있습니다. \n",
      "generate: 그리고 과 이들 다른 사이에 사이에 보면 보면 차이 차이 아주 차이 매우 매우 매우....\n",
      "output tensor([[[ -2.1865, -24.9781, -26.2015,  ..., -19.5868, -25.7761, -25.3964],\n",
      "         [ -3.8814, -26.5547, -27.5586,  ..., -18.3006, -27.6739, -27.3955],\n",
      "         [ -2.4800, -22.6616, -22.5183,  ..., -14.3959, -22.1138, -22.9221],\n",
      "         ...,\n",
      "         [ 17.0848, -28.1883, -28.2371,  ..., -18.3756, -28.3027, -28.7853],\n",
      "         [ 17.3484, -28.1462, -28.0483,  ..., -18.5389, -28.0987, -28.6284],\n",
      "         [ 17.0211, -29.9359, -29.7103,  ..., -19.5292, -29.6697, -30.2385]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 26 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 2.288 | Test Loss: 4.535\n",
      "\tBLEU Score:\n",
      "\t\tavg: 0.981\n",
      "\t\t1-gram: 14.636\n",
      "\t\t2-gram: 1.482\n",
      "\t\t3-gram: 0.423\n",
      "\t\t4-gram: 0.101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456043, 1.065565142789168, 1.1217228300472808, 1.1251005772205362, 0.9376270106656373, 0.945841750555376, 1.032552971972674, 1.108516565724771, 1.025004961153448, 1.246391054667423, 1.1066860083111192, 1.0136808173874745, 0.8953404182688746, 1.0005658195083458, 1.0579186716815774, 1.0521420193171729, 0.9113153109680574, 1.0266675521574615, 0.9812579918643997], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167303, 15.54081410196518, 15.068451007537302, 15.399544082311628, 15.2570938285224, 14.557690604799433, 15.290158268146262, 14.485009531511755, 14.7281302838836, 15.018685290694112, 14.776259456923349, 14.368787418717236, 14.639612718144871, 14.576825387557294, 14.197495404411764, 14.849490400568856, 14.558521560574947, 14.13503366903045, 14.635902753773475], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.525142876466809, 1.551031253113687, 1.6259629568923126, 1.6052787078983652, 1.50159952993406, 1.3394397565795664, 1.5621974049448066, 1.6277358837594262, 1.5357446942701272, 1.6478496377993863, 1.5076942246588998, 1.5314959433589597, 1.4715230104246122, 1.5130375468948625, 1.4352754753778645, 1.530612244897959, 1.5176067310688688, 1.612698815030733, 1.482455067856706], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.4751196866386188, 0.4233519513323135, 0.4630766532187335, 0.4637762630876256, 0.4086051547111825, 0.3815388734562736, 0.4589055275688358, 0.4702501469531709, 0.4510114099155195, 0.530596572066883, 0.4617479985383516, 0.4626484195541752, 0.3903068150963888, 0.4429312795425247, 0.4543094496365524, 0.44030653401452, 0.3988035892323031, 0.4634327853325214, 0.4232321916916265], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.132895559724828, 0.1263351326518892, 0.1395436545351687, 0.1397650436293582, 0.0825639870899947, 0.1075770072076594, 0.1036998629680382, 0.1361874498027028, 0.1082055906221821, 0.1837821618783287, 0.145819255254828, 0.1037093372973346, 0.0764275575936237, 0.102596759357532, 0.1353039134054954, 0.1224519196139163, 0.0782778864970645, 0.1051677243880326, 0.10096086895975491]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:31<00:00, 14.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Time: 11m 36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 188.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 그런데, 바로 저 형상은, 바로 저 형상은 제가 단지 아홉살때 제가 받은건데, 아주 어렸을때부터 제가 의사가 되도록 도우려는것이었죠. \n",
      "generate: 보트,,,, 던 제가 제가 제가 모형 모형 이 모형 모형 로봇 점에서 장난감 장난감 장난감 에 장난감..\n",
      "output tensor([[[  1.7191, -23.9506, -24.8252,  ..., -18.7219, -24.2606, -23.7320],\n",
      "         [  0.5790, -15.0250, -14.4590,  ...,  -6.0770, -15.5814, -14.1200],\n",
      "         [ -2.4410, -16.0163, -15.3502,  ..., -11.4812, -15.9203, -15.2698],\n",
      "         ...,\n",
      "         [ 14.1493, -24.1345, -23.3633,  ..., -16.7213, -23.6737, -23.1964],\n",
      "         [ 15.1296, -21.6146, -21.4251,  ..., -15.6739, -21.5377, -20.7679],\n",
      "         [ 17.5494, -26.8588, -26.7707,  ..., -17.4404, -26.4907, -27.2047]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 삼협 댐에서 벌어지고 있는 일들 중 다른 하나는 바로 여기 왼쪽에 보이는 무수한 농경지가 유실되었다는 것입니다. 세계에서 가장 비옥한 농경지 중 일부가 사라진 거죠. \n",
      "generate: 그리고 링 링 링 n 또 또 다른 다른.. 인데요 왼쪽,,, 보시면 에는 에는 에는 에는 많은,, 많은.....\n",
      "output tensor([[[ -2.0469, -27.9872, -29.6033,  ..., -20.1436, -28.7098, -28.6298],\n",
      "         [ -0.5731, -20.2519, -21.5546,  ...,  -9.9317, -21.1715, -21.1215],\n",
      "         [  0.2117, -18.6779, -19.8882,  ..., -12.5739, -18.6182, -18.5277],\n",
      "         ...,\n",
      "         [  3.6040, -17.5780, -16.9507,  ...,  -6.7902, -18.0023, -17.3006],\n",
      "         [  4.3988, -17.7003, -17.1741,  ...,  -7.7474, -18.3868, -17.1633],\n",
      "         [ 14.7466, -21.4977, -21.2360,  ..., -11.9674, -21.0559, -21.4908]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 모든 살아있는 세포들, 지금까지의 모든 세포들은 4개의 유전자 철자를 사용하여 단백질을 만들 수 있었습니다. \n",
      "generate: 모든 모든 세포 세포 모든 모든 모든 살아있는 모든 단백질 단백질 단백질 단백질 단백질 만들어 만들어 만들어 만들어 만들어 만들어 만들어 만들어 만들어...\n",
      "output tensor([[[ -1.1282, -28.3121, -29.1684,  ..., -20.4154, -28.5017, -28.1101],\n",
      "         [ -3.5145, -24.0302, -23.9121,  ..., -11.3213, -23.8511, -23.2033],\n",
      "         [ -0.9457, -19.0048, -19.0804,  ..., -11.4370, -18.9413, -18.6563],\n",
      "         ...,\n",
      "         [  5.2467, -23.1155, -22.7919,  ..., -15.1184, -22.1138, -22.4005],\n",
      "         [  6.0628, -24.8022, -24.5095,  ..., -17.6413, -24.1015, -23.9042],\n",
      "         [ 15.8183, -23.4955, -23.6863,  ..., -13.1535, -23.1631, -23.2467]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 그들 계획을 읽으면서 든 생각은 \"칫! 비현실적이야 \n",
      "generate: 저는 이 이런 들을 들을 으 이렇게 이렇게,,,, 정말 정말.\n",
      "output tensor([[[  3.4114, -24.1937, -25.3188,  ..., -18.7807, -24.7667, -24.0987],\n",
      "         [ -0.3565, -13.8964, -13.3268,  ...,  -7.4359, -12.9156, -13.7094],\n",
      "         [ -1.6250, -18.5027, -17.7087,  ..., -13.0571, -18.2324, -18.9353],\n",
      "         ...,\n",
      "         [ 16.4034, -23.7942, -23.2909,  ..., -17.3465, -23.9996, -23.3537],\n",
      "         [ 16.3309, -23.5021, -22.9950,  ..., -16.9911, -23.5734, -23.0565],\n",
      "         [ 16.9021, -28.0452, -27.5457,  ..., -19.2767, -28.1974, -27.9560]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 27 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 2.257 | Test Loss: 4.559\n",
      "\tBLEU Score:\n",
      "\t\tavg: 0.777\n",
      "\t\t1-gram: 14.169\n",
      "\t\t2-gram: 1.259\n",
      "\t\t3-gram: 0.335\n",
      "\t\t4-gram: 0.061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456043, 1.065565142789168, 1.1217228300472808, 1.1251005772205362, 0.9376270106656373, 0.945841750555376, 1.032552971972674, 1.108516565724771, 1.025004961153448, 1.246391054667423, 1.1066860083111192, 1.0136808173874745, 0.8953404182688746, 1.0005658195083458, 1.0579186716815774, 1.0521420193171729, 0.9113153109680574, 1.0266675521574615, 0.9812579918643995, 0.7768509255100765], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167303, 15.54081410196518, 15.068451007537302, 15.399544082311628, 15.2570938285224, 14.557690604799433, 15.290158268146262, 14.485009531511755, 14.7281302838836, 15.018685290694112, 14.776259456923349, 14.368787418717236, 14.639612718144871, 14.576825387557294, 14.197495404411764, 14.849490400568856, 14.558521560574947, 14.13503366903045, 14.635902753773475, 14.169275293839702], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.525142876466809, 1.551031253113687, 1.6259629568923126, 1.6052787078983652, 1.50159952993406, 1.3394397565795664, 1.5621974049448066, 1.6277358837594262, 1.5357446942701272, 1.6478496377993863, 1.5076942246588998, 1.5314959433589597, 1.4715230104246122, 1.5130375468948625, 1.4352754753778645, 1.530612244897959, 1.5176067310688688, 1.612698815030733, 1.482455067856706, 1.2585525076894106], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.4751196866386188, 0.4233519513323135, 0.4630766532187335, 0.4637762630876256, 0.4086051547111825, 0.3815388734562736, 0.4589055275688358, 0.4702501469531709, 0.4510114099155195, 0.530596572066883, 0.4617479985383516, 0.4626484195541752, 0.3903068150963888, 0.4429312795425247, 0.4543094496365524, 0.44030653401452, 0.3988035892323031, 0.4634327853325214, 0.4232321916916265, 0.3348625389277701], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.132895559724828, 0.1263351326518892, 0.1395436545351687, 0.1397650436293582, 0.0825639870899947, 0.1075770072076594, 0.1036998629680382, 0.1361874498027028, 0.1082055906221821, 0.1837821618783287, 0.145819255254828, 0.1037093372973346, 0.0764275575936237, 0.102596759357532, 0.1353039134054954, 0.1224519196139163, 0.0782778864970645, 0.1051677243880326, 0.1009608689597549, 0.06099092311555986]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:31<00:00, 14.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Time: 11m 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 188.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 여러분은 거실 카펫에 앉아서 여러분의 딸 마리앤과 놀고 있습니다. \n",
      "generate: 그녀는 당신의 카펫 있는 앉아 앉아 앉아 과 와 함께 과 앨리스 함께..\n",
      "output tensor([[[  0.3367, -27.5661, -28.7260,  ..., -17.8438, -28.4305, -27.8005],\n",
      "         [ -0.2137, -16.4908, -14.4596,  ...,  -9.5795, -16.1307, -15.3111],\n",
      "         [  0.9220, -12.3833, -11.1168,  ...,  -6.9209, -13.2192, -12.1945],\n",
      "         ...,\n",
      "         [ 19.2468, -24.1268, -23.3511,  ..., -15.5365, -24.1920, -24.6065],\n",
      "         [ 18.7691, -25.6612, -24.9148,  ..., -16.7617, -25.6621, -26.0719],\n",
      "         [ 18.3031, -33.0185, -32.4971,  ..., -19.3231, -33.3506, -33.4775]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 우리는 어릴 때부터 경찰관, 체포, 수갑이라는 개념을 받아들이게 됩니다. 그래서 이런 것들이 타인의 신체를 장악하는데 얼마나 모욕적이고 강압적인 지를 종종 잊어버립니다. \n",
      "generate: 우리는 어린 들은 경찰 배 관 자 자 비난 비난 고 것을 것을 것을 니..... 수.......\n",
      "output tensor([[[ -1.0995, -26.7786, -28.4516,  ..., -19.3934, -27.6318, -27.3543],\n",
      "         [ -3.2901, -18.9550, -18.4396,  ...,  -9.8048, -19.0720, -18.2628],\n",
      "         [ -3.4142, -24.6691, -25.2447,  ..., -14.9228, -25.1362, -24.7672],\n",
      "         ...,\n",
      "         [  2.4683, -17.0515, -16.9674,  ..., -14.2078, -16.3039, -16.2554],\n",
      "         [  3.5725, -17.5279, -17.4659,  ..., -13.7685, -17.2104, -16.7720],\n",
      "         [ 15.0065, -24.3383, -24.6113,  ..., -13.6194, -24.3090, -24.4667]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 더 좋은 절연제도 있습니다. \n",
      "generate: 여러분은 더 진 환경 환경 나은 나은 보실 수 수\n",
      "output tensor([[[ -0.8787, -25.6967, -26.7854,  ..., -19.0513, -26.1657, -25.8336],\n",
      "         [ -3.4212, -22.0327, -21.5790,  ..., -16.7450, -22.4825, -22.1242],\n",
      "         [ -2.7423, -21.0316, -21.1606,  ..., -16.8137, -21.0651, -20.2303],\n",
      "         ...,\n",
      "         [ 17.6623, -28.0866, -27.6101,  ..., -18.8794, -28.1438, -28.4745],\n",
      "         [ 17.4906, -28.2900, -27.8013,  ..., -18.9575, -28.3151, -28.6109],\n",
      "         [ 20.3218, -32.8119, -32.3554,  ..., -18.3409, -32.8132, -33.0395]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 전 친구에게 이 정의를 읽어주면서 처음에는 너무 황당해서 웃었는데, ‘짓이기다’를 읽는 순간에 목이 메였고, 이런 단어들의 폭력성에서 받은 심리적 충격을 참기 위해서 읽는 것을 멈출 수 밖에 없었어요. \n",
      "generate: 저는 저는 친구 에게 에게 을, 처음엔 처음엔. 처음에는 기 재미 \" \" \" \" \" \" \" \" 많이 \" \" \" \" \" \" \" \"\n",
      "output tensor([[[ -1.8296, -25.3993, -26.6849,  ..., -17.3999, -25.9407, -26.0321],\n",
      "         [ -1.7882, -20.4822, -21.0845,  ..., -12.9049, -20.6278, -21.4095],\n",
      "         [ -3.9534, -16.1373, -16.0337,  ..., -10.3653, -16.3789, -15.8410],\n",
      "         ...,\n",
      "         [  2.2674, -14.9879, -14.6114,  ...,  -8.8405, -14.3508, -14.2959],\n",
      "         [  2.9436, -14.4590, -14.8579,  ..., -10.3803, -13.8389, -13.7542],\n",
      "         [ 10.7363, -21.7123, -21.9811,  ..., -11.5946, -21.2453, -21.4421]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 28 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 2.225 | Test Loss: 4.596\n",
      "\tBLEU Score:\n",
      "\t\tavg: 1.069\n",
      "\t\t1-gram: 14.487\n",
      "\t\t2-gram: 1.495\n",
      "\t\t3-gram: 0.469\n",
      "\t\t4-gram: 0.129\n",
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456043, 1.065565142789168, 1.1217228300472808, 1.1251005772205362, 0.9376270106656373, 0.945841750555376, 1.032552971972674, 1.108516565724771, 1.025004961153448, 1.246391054667423, 1.1066860083111192, 1.0136808173874745, 0.8953404182688746, 1.0005658195083458, 1.0579186716815774, 1.0521420193171729, 0.9113153109680574, 1.0266675521574615, 0.9812579918643995, 0.7768509255100765, 1.0693715832453634], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167303, 15.54081410196518, 15.068451007537302, 15.399544082311628, 15.2570938285224, 14.557690604799433, 15.290158268146262, 14.485009531511755, 14.7281302838836, 15.018685290694112, 14.776259456923349, 14.368787418717236, 14.639612718144871, 14.576825387557294, 14.197495404411764, 14.849490400568856, 14.558521560574947, 14.13503366903045, 14.635902753773475, 14.169275293839702, 14.487367844899605], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.525142876466809, 1.551031253113687, 1.6259629568923126, 1.6052787078983652, 1.50159952993406, 1.3394397565795664, 1.5621974049448066, 1.6277358837594262, 1.5357446942701272, 1.6478496377993863, 1.5076942246588998, 1.5314959433589597, 1.4715230104246122, 1.5130375468948625, 1.4352754753778645, 1.530612244897959, 1.5176067310688688, 1.612698815030733, 1.482455067856706, 1.2585525076894106, 1.4948185736557331], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.4751196866386188, 0.4233519513323135, 0.4630766532187335, 0.4637762630876256, 0.4086051547111825, 0.3815388734562736, 0.4589055275688358, 0.4702501469531709, 0.4510114099155195, 0.530596572066883, 0.4617479985383516, 0.4626484195541752, 0.3903068150963888, 0.4429312795425247, 0.4543094496365524, 0.44030653401452, 0.3988035892323031, 0.4634327853325214, 0.4232321916916265, 0.3348625389277701, 0.46885683586754795], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.132895559724828, 0.1263351326518892, 0.1395436545351687, 0.1397650436293582, 0.0825639870899947, 0.1075770072076594, 0.1036998629680382, 0.1361874498027028, 0.1082055906221821, 0.1837821618783287, 0.145819255254828, 0.1037093372973346, 0.0764275575936237, 0.102596759357532, 0.1353039134054954, 0.1224519196139163, 0.0782778864970645, 0.1051677243880326, 0.1009608689597549, 0.0609909231155598, 0.12879420774157616]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:32<00:00, 14.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Time: 11m 36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 190.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 아니 -- 글쎄요, 예, 하지만 전세계 통계에서 상어는 그다지 중요하지 않습니다. 제가 말하고자 하는 바는 그거에요. \n",
      "generate: 하지만... 은 은 은 위험 위험 위험. 세계적으로 통계 전세계 적 통계 통계 않습니다 않습니다\n",
      "output tensor([[[  2.2759, -25.1567, -26.6445,  ..., -20.1173, -25.6157, -25.2869],\n",
      "         [ -0.8093, -21.1540, -21.7976,  ..., -13.3229, -20.5683, -20.8882],\n",
      "         [  1.7529, -21.0873, -21.1947,  ..., -14.9235, -20.4321, -19.8128],\n",
      "         ...,\n",
      "         [ 14.5016, -22.3789, -21.9194,  ...,  -9.4503, -22.2783, -22.4741],\n",
      "         [ 14.2579, -23.3163, -22.8369,  ..., -10.4024, -23.2065, -23.2013],\n",
      "         [ 17.5722, -28.6335, -28.3487,  ..., -16.6008, -28.6769, -28.7750]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 대화를 하는 것 같았어요. \n",
      "generate: 아이 그 잘 잘 수..\n",
      "output tensor([[[  2.3010, -25.8060, -26.4242,  ..., -19.5889, -26.1187, -25.8557],\n",
      "         [ -4.0179, -15.5877, -15.0249,  ...,  -5.7606, -14.5440, -15.1844],\n",
      "         [ -0.4070, -16.5006, -15.0092,  ...,  -8.7982, -16.0998, -16.1063],\n",
      "         ...,\n",
      "         [ 17.1592, -30.4206, -29.7504,  ..., -16.6744, -30.4004, -30.5603],\n",
      "         [ 17.2910, -29.9607, -29.2653,  ..., -16.2788, -29.9640, -30.1058],\n",
      "         [ 17.8986, -28.8817, -28.2409,  ..., -15.4522, -28.9407, -29.0957]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 체스 플레이용 컴퓨터는 수 십 년 간 개발되어 왔습니다. 하지만 딥 블루가 1997년 체스 챔피언 개리 카스파로브를 꺾은 일은 당시 인간 챔피언을 상대로 우승한 최초의 사건이었습니다. \n",
      "generate: 수십 는 는 수십 년 년 해 왔습니다..,, 에 에 아일랜드 카 카 카 레 물리 스파 카 프 프 프 프 를, 이 죠\n",
      "output tensor([[[ -2.1030, -24.5922, -25.7858,  ..., -20.4270, -24.7933, -24.7494],\n",
      "         [ -2.2580, -17.9180, -17.5588,  ..., -12.1220, -17.0572, -18.1007],\n",
      "         [ -3.8249, -14.1293, -14.9824,  ..., -10.4271, -14.0008, -15.1152],\n",
      "         ...,\n",
      "         [ -0.3069, -15.1054, -14.3676,  ..., -13.3864, -15.4093, -14.2721],\n",
      "         [  1.0999, -15.9058, -15.4128,  ..., -14.4412, -15.8179, -14.7870],\n",
      "         [ 11.7728, -21.9097, -21.3591,  ..., -12.2837, -21.5793, -22.0427]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 이따금 아이의 새까만 눈동자는 타호 호수의 푸른 빛으로 변했고 다른 이들의 눈을 골똘히 바라보기도 했어요. \n",
      "generate: 그녀의 눈 장미 눈 빛 빛 빛 희 희 처럼 으로 가 빛 파란 파란 파란 록 흰 것을 것을 것을 것을 것을..\n",
      "output tensor([[[  0.1796, -25.4399, -26.6570,  ..., -19.2736, -25.9450, -25.7734],\n",
      "         [ -1.6373, -18.6185, -18.5582,  ...,  -7.9133, -18.6799, -19.7226],\n",
      "         [ -0.6522, -12.9415, -13.0519,  ...,  -3.5308, -13.4351, -13.6923],\n",
      "         ...,\n",
      "         [ 13.2798, -20.0758, -19.9357,  ..., -11.4285, -20.6006, -20.8298],\n",
      "         [ 13.7546, -21.6418, -21.3431,  ..., -11.5111, -22.1101, -22.3109],\n",
      "         [ 18.9522, -25.9114, -25.9246,  ..., -16.1648, -26.0119, -26.4353]]],\n",
      "       device='cuda:0')\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 185.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 2.196 | Test Loss: 4.651\n",
      "\tBLEU Score:\n",
      "\t\tavg: 1.000\n",
      "\t\t1-gram: 14.277\n",
      "\t\t2-gram: 1.552\n",
      "\t\t3-gram: 0.445\n",
      "\t\t4-gram: 0.102\n",
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456043, 1.065565142789168, 1.1217228300472808, 1.1251005772205362, 0.9376270106656373, 0.945841750555376, 1.032552971972674, 1.108516565724771, 1.025004961153448, 1.246391054667423, 1.1066860083111192, 1.0136808173874745, 0.8953404182688746, 1.0005658195083458, 1.0579186716815774, 1.0521420193171729, 0.9113153109680574, 1.0266675521574615, 0.9812579918643995, 0.7768509255100765, 1.0693715832453634, 1.0003935586158077], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167303, 15.54081410196518, 15.068451007537302, 15.399544082311628, 15.2570938285224, 14.557690604799433, 15.290158268146262, 14.485009531511755, 14.7281302838836, 15.018685290694112, 14.776259456923349, 14.368787418717236, 14.639612718144871, 14.576825387557294, 14.197495404411764, 14.849490400568856, 14.558521560574947, 14.13503366903045, 14.635902753773475, 14.169275293839702, 14.487367844899603, 14.277029960920538], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.525142876466809, 1.551031253113687, 1.6259629568923126, 1.6052787078983652, 1.50159952993406, 1.3394397565795664, 1.5621974049448066, 1.6277358837594262, 1.5357446942701272, 1.6478496377993863, 1.5076942246588998, 1.5314959433589597, 1.4715230104246122, 1.5130375468948625, 1.4352754753778645, 1.530612244897959, 1.5176067310688688, 1.612698815030733, 1.482455067856706, 1.2585525076894106, 1.4948185736557331, 1.5516976494085113], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.4751196866386188, 0.4233519513323135, 0.4630766532187335, 0.4637762630876256, 0.4086051547111825, 0.3815388734562736, 0.4589055275688358, 0.4702501469531709, 0.4510114099155195, 0.530596572066883, 0.4617479985383516, 0.4626484195541752, 0.3903068150963888, 0.4429312795425247, 0.4543094496365524, 0.44030653401452, 0.3988035892323031, 0.4634327853325214, 0.4232321916916265, 0.3348625389277701, 0.4688568358675479, 0.44524472090358486], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.132895559724828, 0.1263351326518892, 0.1395436545351687, 0.1397650436293582, 0.0825639870899947, 0.1075770072076594, 0.1036998629680382, 0.1361874498027028, 0.1082055906221821, 0.1837821618783287, 0.145819255254828, 0.1037093372973346, 0.0764275575936237, 0.102596759357532, 0.1353039134054954, 0.1224519196139163, 0.0782778864970645, 0.1051677243880326, 0.1009608689597549, 0.0609909231155598, 0.1287942077415761, 0.1015406162464986]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:32<00:00, 14.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Time: 11m 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:55<00:00, 44.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Test Time: 0m 55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 190.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 고맙습니다. \n",
      "generate: 감사합니다.\n",
      "output tensor([[[  3.9220, -23.7609, -25.0274,  ..., -19.2695, -24.4886, -23.8111],\n",
      "         [  2.2579, -23.0378, -23.4946,  ..., -13.5663, -24.0394, -23.2710],\n",
      "         [  3.9188, -12.5712, -12.4819,  ...,  -8.8366, -12.7163, -12.2802],\n",
      "         ...,\n",
      "         [ 18.4383, -29.1362, -28.8212,  ..., -17.7208, -29.6523, -29.6332],\n",
      "         [ 18.4936, -29.1513, -28.8397,  ..., -17.6089, -29.6722, -29.6761],\n",
      "         [ 19.6947, -29.2452, -28.8635,  ..., -17.1688, -29.6675, -29.6414]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 그 분들은 나미비아와 그 아름다운 모래언덕을 사랑합니다. 언덕 높이가 엠파이어 스테이트 빌딩보다도 훨씬 높죠. (譯者註: 엠파이어 스테이트 빌딩 높이 = 310 미터) \n",
      "generate: 그 그 나 미 미 젤 를 를 비 기. 이... 트 ( 파이어 파이어 보다 보다 보다 보다 더 더. 많기.\n",
      "output tensor([[[ -1.7879, -22.6482, -23.0985,  ..., -17.1094, -22.8474, -22.1309],\n",
      "         [ -3.7968, -31.9661, -31.3717,  ..., -15.5722, -31.7507, -31.0428],\n",
      "         [ -5.3590, -31.1823, -30.1941,  ..., -19.2347, -31.1580, -31.1309],\n",
      "         ...,\n",
      "         [  9.0713, -15.3339, -15.1140,  ...,  -8.8923, -15.5570, -15.3044],\n",
      "         [ 10.3526, -16.4490, -16.1388,  ...,  -9.7748, -16.2096, -16.2714],\n",
      "         [ 15.4503, -26.3589, -25.9422,  ..., -15.2832, -25.2576, -26.1614]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 누가 전원을 꺼버릴 수도 있잖아. \n",
      "generate: 사실 누가 켜 꺼 해고 건 건 거 했..\n",
      "output tensor([[[ -1.6829, -25.3722, -26.9092,  ..., -20.4713, -26.2626, -26.0951],\n",
      "         [ -3.1470, -26.2074, -25.1483,  ..., -13.7010, -25.5357, -25.2109],\n",
      "         [ -3.1683, -20.6367, -20.4362,  ..., -16.8130, -20.7633, -20.9959],\n",
      "         ...,\n",
      "         [ 18.8431, -31.3806, -31.0770,  ..., -17.8581, -31.3295, -31.6260],\n",
      "         [ 18.9804, -31.2975, -31.0337,  ..., -17.9437, -31.2935, -31.6067],\n",
      "         [ 20.1331, -31.9806, -31.6501,  ..., -17.7180, -32.1049, -32.2368]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 여러분은 젊고 잘생긴 청년이 될 것이고 그리고 저는 현명한 비즈니스맨이 될 것입니다. \n",
      "generate: 여러분이 젊은 젊은 젊은 젊은 서 성공한 그리고 기업 성공한 가 가..\n",
      "output tensor([[[  2.2280, -23.7769, -25.0055,  ..., -18.3978, -24.6187, -24.1559],\n",
      "         [ -4.9606, -21.2792, -21.2674,  ..., -16.2570, -21.7297, -21.2058],\n",
      "         [ -3.5001, -20.7686, -21.1885,  ..., -15.5796, -21.2805, -21.3992],\n",
      "         ...,\n",
      "         [ 18.3744, -28.4842, -27.6731,  ..., -15.1407, -28.5395, -28.4268],\n",
      "         [ 20.4311, -22.7378, -22.7552,  ..., -14.6249, -22.9225, -22.8692],\n",
      "         [ 19.4955, -28.0483, -27.7723,  ..., -17.9469, -28.3109, -28.4906]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 30 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 2.166 | Test Loss: 4.665\n",
      "\tBLEU Score:\n",
      "\t\tavg: 0.827\n",
      "\t\t1-gram: 14.328\n",
      "\t\t2-gram: 1.366\n",
      "\t\t3-gram: 0.365\n",
      "\t\t4-gram: 0.065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456043, 1.065565142789168, 1.1217228300472808, 1.1251005772205362, 0.9376270106656373, 0.945841750555376, 1.032552971972674, 1.108516565724771, 1.025004961153448, 1.246391054667423, 1.1066860083111192, 1.0136808173874745, 0.8953404182688746, 1.0005658195083458, 1.0579186716815774, 1.0521420193171729, 0.9113153109680574, 1.0266675521574615, 0.9812579918643995, 0.7768509255100765, 1.0693715832453634, 1.0003935586158077, 0.8266103868732955], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167303, 15.54081410196518, 15.068451007537302, 15.399544082311628, 15.2570938285224, 14.557690604799433, 15.290158268146262, 14.485009531511755, 14.7281302838836, 15.018685290694112, 14.776259456923349, 14.368787418717236, 14.639612718144871, 14.576825387557294, 14.197495404411764, 14.849490400568856, 14.558521560574947, 14.13503366903045, 14.635902753773475, 14.169275293839702, 14.487367844899603, 14.277029960920538, 14.328287042555727], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.525142876466809, 1.551031253113687, 1.6259629568923126, 1.6052787078983652, 1.50159952993406, 1.3394397565795664, 1.5621974049448066, 1.6277358837594262, 1.5357446942701272, 1.6478496377993863, 1.5076942246588998, 1.5314959433589597, 1.4715230104246122, 1.5130375468948625, 1.4352754753778645, 1.530612244897959, 1.5176067310688688, 1.612698815030733, 1.482455067856706, 1.2585525076894106, 1.4948185736557331, 1.5516976494085113, 1.3658258334389657], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.4751196866386188, 0.4233519513323135, 0.4630766532187335, 0.4637762630876256, 0.4086051547111825, 0.3815388734562736, 0.4589055275688358, 0.4702501469531709, 0.4510114099155195, 0.530596572066883, 0.4617479985383516, 0.4626484195541752, 0.3903068150963888, 0.4429312795425247, 0.4543094496365524, 0.44030653401452, 0.3988035892323031, 0.4634327853325214, 0.4232321916916265, 0.3348625389277701, 0.4688568358675479, 0.4452447209035848, 0.3654080389768575], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.132895559724828, 0.1263351326518892, 0.1395436545351687, 0.1397650436293582, 0.0825639870899947, 0.1075770072076594, 0.1036998629680382, 0.1361874498027028, 0.1082055906221821, 0.1837821618783287, 0.145819255254828, 0.1037093372973346, 0.0764275575936237, 0.102596759357532, 0.1353039134054954, 0.1224519196139163, 0.0782778864970645, 0.1051677243880326, 0.1009608689597549, 0.0609909231155598, 0.1287942077415761, 0.1015406162464986, 0.06528835690968444]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:32<00:00, 14.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | Train Time: 11m 39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:55<00:00, 44.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | Test Time: 0m 55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 189.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 우리가 가진 체계는 선생님들에게 맞지 않습니다. \n",
      "generate: 지금은 시스템이 시스템은 불 불 불 시스템이.\n",
      "output tensor([[[ -3.1499, -27.9611, -28.7760,  ..., -23.3311, -28.1017, -28.0492],\n",
      "         [ -3.8802, -31.6649, -31.1556,  ..., -25.5697, -31.7808, -31.3767],\n",
      "         [ -1.9941, -24.7883, -24.2532,  ..., -19.7783, -24.1344, -24.7938],\n",
      "         ...,\n",
      "         [ 16.7384, -31.0697, -30.5116,  ..., -19.7485, -30.8289, -31.2338],\n",
      "         [ 16.7253, -30.9108, -30.3259,  ..., -19.7671, -30.6380, -31.0606],\n",
      "         [ 18.4293, -30.6408, -30.1501,  ..., -19.1322, -30.4881, -30.8564]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 그러니까 이런 방법으로 악기를 알아가는 시간이 필요한겁니다 사람들의 내면을 이해하기 위해서는 시간이 필요해요 \n",
      "generate: 그래서 때문에 시간을 귀 귀 필요 귀 느껴 처럼 필요 서 들여 시간을 들여 들여 들여 시간을 할 할 느껴 느껴....\n",
      "output tensor([[[ -2.6869, -26.7908, -27.5050,  ..., -17.3296, -27.2501, -26.5161],\n",
      "         [ -2.2453, -18.9342, -18.7952,  ...,  -9.6710, -19.2767, -18.8593],\n",
      "         [ -1.5736, -18.4309, -18.1346,  ...,  -8.2938, -18.8688, -18.2178],\n",
      "         ...,\n",
      "         [ 13.8628, -22.0664, -22.6238,  ..., -13.3655, -22.6678, -21.7600],\n",
      "         [ 13.2098, -22.2480, -23.0632,  ..., -14.2793, -23.1666, -21.8332],\n",
      "         [ 17.6739, -26.9964, -27.1398,  ..., -15.6359, -27.3090, -26.8624]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 해가 둘이면 '번창함' [창성할 창] \n",
      "generate: 우리는 \" 승 \" \" 을 을 \" 을 을 을..\n",
      "output tensor([[[ -1.2230, -23.4559, -25.1480,  ..., -18.9539, -24.3971, -24.1895],\n",
      "         [ -0.1191, -11.9424, -14.2702,  ...,  -6.9617, -12.8608, -12.1433],\n",
      "         [  0.3134, -13.1448, -13.5757,  ..., -12.0958, -14.6257, -13.0901],\n",
      "         ...,\n",
      "         [ 17.6099, -29.8372, -29.6656,  ..., -18.0085, -29.9744, -30.1883],\n",
      "         [ 17.6606, -30.1645, -29.9561,  ..., -17.9823, -30.2823, -30.5107],\n",
      "         [ 19.2721, -31.3712, -31.1272,  ..., -18.3171, -31.6026, -31.8046]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 과거 몇 년 동안 우리 도시는 네트워크와 전자장치로 뒤덮였습니다. \n",
      "generate: 인터넷 최근 년 전부터 네트워크를 전기 년 은 시설 시설 시설 왔습니다.\n",
      "output tensor([[[ -0.3071, -26.9726, -28.3697,  ..., -21.1562, -27.6575, -27.3849],\n",
      "         [ -4.3073, -27.2429, -28.3358,  ..., -13.4545, -26.3996, -26.7407],\n",
      "         [ -3.3083, -17.9788, -18.2322,  ...,  -9.9002, -17.5074, -17.2404],\n",
      "         ...,\n",
      "         [ 17.0878, -30.6942, -30.7625,  ..., -18.8045, -30.8400, -31.0721],\n",
      "         [ 17.0533, -30.8923, -30.9796,  ..., -18.9397, -31.0239, -31.2432],\n",
      "         [ 18.6141, -32.3983, -32.1048,  ..., -18.5279, -32.5930, -32.8227]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 31 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 2.141 | Test Loss: 4.689\n",
      "\tBLEU Score:\n",
      "\t\tavg: 0.889\n",
      "\t\t1-gram: 14.044\n",
      "\t\t2-gram: 1.362\n",
      "\t\t3-gram: 0.390\n",
      "\t\t4-gram: 0.083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456043, 1.065565142789168, 1.1217228300472808, 1.1251005772205362, 0.9376270106656373, 0.945841750555376, 1.032552971972674, 1.108516565724771, 1.025004961153448, 1.246391054667423, 1.1066860083111192, 1.0136808173874745, 0.8953404182688746, 1.0005658195083458, 1.0579186716815774, 1.0521420193171729, 0.9113153109680574, 1.0266675521574615, 0.9812579918643995, 0.7768509255100765, 1.0693715832453634, 1.0003935586158077, 0.8266103868732955, 0.888504001036279], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167303, 15.54081410196518, 15.068451007537302, 15.399544082311628, 15.2570938285224, 14.557690604799433, 15.290158268146262, 14.485009531511755, 14.7281302838836, 15.018685290694112, 14.776259456923349, 14.368787418717236, 14.639612718144871, 14.576825387557294, 14.197495404411764, 14.849490400568856, 14.558521560574947, 14.13503366903045, 14.635902753773475, 14.169275293839702, 14.487367844899603, 14.277029960920538, 14.328287042555727, 14.043520810546314], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.525142876466809, 1.551031253113687, 1.6259629568923126, 1.6052787078983652, 1.50159952993406, 1.3394397565795664, 1.5621974049448066, 1.6277358837594262, 1.5357446942701272, 1.6478496377993863, 1.5076942246588998, 1.5314959433589597, 1.4715230104246122, 1.5130375468948625, 1.4352754753778645, 1.530612244897959, 1.5176067310688688, 1.612698815030733, 1.482455067856706, 1.2585525076894106, 1.4948185736557331, 1.5516976494085113, 1.3658258334389657, 1.3621648036161504], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.4751196866386188, 0.4233519513323135, 0.4630766532187335, 0.4637762630876256, 0.4086051547111825, 0.3815388734562736, 0.4589055275688358, 0.4702501469531709, 0.4510114099155195, 0.530596572066883, 0.4617479985383516, 0.4626484195541752, 0.3903068150963888, 0.4429312795425247, 0.4543094496365524, 0.44030653401452, 0.3988035892323031, 0.4634327853325214, 0.4232321916916265, 0.3348625389277701, 0.4688568358675479, 0.4452447209035848, 0.3654080389768575, 0.3903454557283196], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.132895559724828, 0.1263351326518892, 0.1395436545351687, 0.1397650436293582, 0.0825639870899947, 0.1075770072076594, 0.1036998629680382, 0.1361874498027028, 0.1082055906221821, 0.1837821618783287, 0.145819255254828, 0.1037093372973346, 0.0764275575936237, 0.102596759357532, 0.1353039134054954, 0.1224519196139163, 0.0782778864970645, 0.1051677243880326, 0.1009608689597549, 0.0609909231155598, 0.1287942077415761, 0.1015406162464986, 0.0652883569096844, 0.08346084295451384]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:32<00:00, 14.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | Train Time: 11m 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 190.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 지난 번 먹었던 햄버거를 생각해보세요. \n",
      "generate: 최근에 최근에 요구르트 를 을 한번 생각해보 생각해보 세 요.\n",
      "output tensor([[[ -2.6757, -26.6559, -28.3050,  ..., -21.4978, -27.3810, -27.3045],\n",
      "         [ -3.7823, -20.9030, -21.3833,  ..., -11.9754, -19.6868, -20.7624],\n",
      "         [ -0.5809,  -9.5212,  -9.8252,  ...,  -7.8515,  -8.3929,  -9.0033],\n",
      "         ...,\n",
      "         [ 17.9355, -29.6005, -29.3093,  ..., -17.9994, -29.5876, -29.9126],\n",
      "         [ 17.8192, -29.5911, -29.3074,  ..., -17.8952, -29.5874, -29.9038],\n",
      "         [ 18.4456, -28.8209, -28.6125,  ..., -17.5262, -28.9660, -29.2042]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 결국 나이든 사람이 구해주어 가족을 찾는 겁니다. \n",
      "generate: 마침내 이 와서 와서 와서 모 가족 가족 을 모 모 준비를 올.\n",
      "output tensor([[[ -0.5699, -26.5997, -28.3863,  ..., -20.5973, -27.6410, -27.3797],\n",
      "         [ -1.6933, -20.4317, -19.6868,  ..., -12.1883, -20.0779, -19.5712],\n",
      "         [ -1.3937, -22.2179, -21.5091,  ..., -10.6693, -22.1521, -21.7789],\n",
      "         ...,\n",
      "         [ 18.0451, -27.3889, -27.2581,  ..., -17.1243, -27.4550, -27.9308],\n",
      "         [ 18.1795, -26.7492, -26.5785,  ..., -16.6668, -26.7143, -27.2148],\n",
      "         [ 18.0626, -28.0669, -27.8197,  ..., -16.9775, -28.0927, -28.5676]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence (웃음) 제 요점은 사람들이 선택의 자유를 가지고 있다는 거죠 -- 인도 여자들이 사리를 입을 수 있고 일본 여자들이 기모노를 입을 수 있는것이나 마찬가지죠. \n",
      "generate: ( 웃음 ) 제 점은 점은 점은 사람들이 이 는 -. -.. 마치 마치 처럼 가. 수 그녀를 있는 있는...\n",
      "output tensor([[[  0.9681, -24.6181, -26.1062,  ..., -19.8748, -25.5164, -25.1625],\n",
      "         [ -3.4057, -19.0368, -19.8885,  ..., -13.2576, -19.7393, -19.8514],\n",
      "         [ -1.3433, -21.3467, -22.2223,  ..., -14.6613, -22.1976, -21.9466],\n",
      "         ...,\n",
      "         [  6.2864, -16.5415, -17.2983,  ..., -15.8367, -17.4726, -16.9151],\n",
      "         [  5.8638, -15.7399, -16.7277,  ..., -15.2590, -16.4608, -15.5898],\n",
      "         [ 14.7044, -22.5528, -22.4477,  ..., -14.1188, -22.2508, -23.1996]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 이런 규모의 산업에도 불구하고 수익은 놀랍게도 적어요. \n",
      "generate: 이 적 적 규모 인 놀라 놀라 도 적. 도 수익 수익 수익 수익...\n",
      "output tensor([[[ -2.5598, -27.3079, -28.6834,  ..., -20.0687, -28.1336, -27.7433],\n",
      "         [ -6.7190, -29.7829, -29.5750,  ..., -14.6648, -29.1173, -28.5914],\n",
      "         [ -4.8864, -24.0369, -24.0808,  ..., -12.3014, -23.3804, -23.8778],\n",
      "         ...,\n",
      "         [ 19.6624, -21.8668, -21.8634,  ..., -15.1393, -21.7469, -22.3926],\n",
      "         [ 18.5065, -23.8221, -23.6560,  ..., -15.8780, -23.6161, -24.1179],\n",
      "         [ 17.8863, -29.2719, -29.0489,  ..., -19.2364, -29.2760, -29.2959]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 32 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 2.114 | Test Loss: 4.709\n",
      "\tBLEU Score:\n",
      "\t\tavg: 1.198\n",
      "\t\t1-gram: 14.282\n",
      "\t\t2-gram: 1.527\n",
      "\t\t3-gram: 0.526\n",
      "\t\t4-gram: 0.180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456043, 1.065565142789168, 1.1217228300472808, 1.1251005772205362, 0.9376270106656373, 0.945841750555376, 1.032552971972674, 1.108516565724771, 1.025004961153448, 1.246391054667423, 1.1066860083111192, 1.0136808173874745, 0.8953404182688746, 1.0005658195083458, 1.0579186716815774, 1.0521420193171729, 0.9113153109680574, 1.0266675521574615, 0.9812579918643995, 0.7768509255100765, 1.0693715832453634, 1.0003935586158077, 0.8266103868732955, 0.888504001036279, 1.198148680752794], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167303, 15.54081410196518, 15.068451007537302, 15.399544082311628, 15.2570938285224, 14.557690604799433, 15.290158268146262, 14.485009531511755, 14.7281302838836, 15.018685290694112, 14.776259456923349, 14.368787418717236, 14.639612718144871, 14.576825387557294, 14.197495404411764, 14.849490400568856, 14.558521560574947, 14.13503366903045, 14.635902753773475, 14.169275293839702, 14.487367844899603, 14.277029960920538, 14.328287042555727, 14.043520810546314, 14.282336249704422], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.525142876466809, 1.551031253113687, 1.6259629568923126, 1.6052787078983652, 1.50159952993406, 1.3394397565795664, 1.5621974049448066, 1.6277358837594262, 1.5357446942701272, 1.6478496377993863, 1.5076942246588998, 1.5314959433589597, 1.4715230104246122, 1.5130375468948625, 1.4352754753778645, 1.530612244897959, 1.5176067310688688, 1.612698815030733, 1.482455067856706, 1.2585525076894106, 1.4948185736557331, 1.5516976494085113, 1.3658258334389657, 1.3621648036161504, 1.5267655189746168], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.4751196866386188, 0.4233519513323135, 0.4630766532187335, 0.4637762630876256, 0.4086051547111825, 0.3815388734562736, 0.4589055275688358, 0.4702501469531709, 0.4510114099155195, 0.530596572066883, 0.4617479985383516, 0.4626484195541752, 0.3903068150963888, 0.4429312795425247, 0.4543094496365524, 0.44030653401452, 0.3988035892323031, 0.4634327853325214, 0.4232321916916265, 0.3348625389277701, 0.4688568358675479, 0.4452447209035848, 0.3654080389768575, 0.3903454557283196, 0.5262805041566103], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.132895559724828, 0.1263351326518892, 0.1395436545351687, 0.1397650436293582, 0.0825639870899947, 0.1075770072076594, 0.1036998629680382, 0.1361874498027028, 0.1082055906221821, 0.1837821618783287, 0.145819255254828, 0.1037093372973346, 0.0764275575936237, 0.102596759357532, 0.1353039134054954, 0.1224519196139163, 0.0782778864970645, 0.1051677243880326, 0.1009608689597549, 0.0609909231155598, 0.1287942077415761, 0.1015406162464986, 0.0652883569096844, 0.0834608429545138, 0.1795783500341199]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:32<00:00, 14.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 | Train Time: 11m 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 191.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 이러한 냄새를 맡을 수 없는 것은 후각 상실증이라 불리는데, 약 100가지 정도의 알려진 예가 있습니다. \n",
      "generate: 후 각 각 각 각 각 각 각 각 각 있고 있고, 수백, 가지 사례 사례...\n",
      "output tensor([[[ -0.4280, -28.6143, -29.7821,  ..., -22.7685, -29.1283, -28.9851],\n",
      "         [ -3.2909, -23.2823, -23.0416,  ..., -12.0692, -22.7944, -23.1466],\n",
      "         [ -3.3922, -18.3869, -17.9049,  ..., -15.5739, -18.0467, -18.9975],\n",
      "         ...,\n",
      "         [ 15.0301, -27.3850, -27.1816,  ..., -20.2281, -27.3057, -27.5432],\n",
      "         [ 14.8818, -24.9349, -24.8639,  ..., -15.6393, -24.4897, -25.0369],\n",
      "         [ 15.7005, -29.2666, -29.3622,  ..., -19.6231, -29.0104, -29.1043]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 수 백에서 수 천개의 분열된 끝단을 가지고 있어요. 그게 비결이죠. 그것 때문에 벽에 잘 붙을 수 있는 겁니다. \n",
      "generate: 그리고 개의 개의 수천 이르는 들이 겠 가. 요.. 니. 다 더 더 더 더 더 더.. 쉽고, 수 더 더 더 냐\n",
      "output tensor([[[ -1.7932, -26.2934, -27.4168,  ..., -21.6707, -26.6954, -26.5837],\n",
      "         [ -1.9340, -13.7205, -13.9947,  ...,  -5.7566, -13.2779, -13.3651],\n",
      "         [ -2.0965, -19.8806, -19.6599,  ...,  -9.5370, -19.5770, -20.1473],\n",
      "         ...,\n",
      "         [ -1.4584, -21.4316, -21.8449,  ...,  -9.5104, -21.2016, -21.6991],\n",
      "         [ -0.4876, -20.6414, -20.0431,  ...,  -9.5112, -20.4275, -20.0324],\n",
      "         [ 12.2542, -21.2771, -21.2056,  ..., -12.5602, -20.5958, -20.6193]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 결국 우리가 할 수 있는 일들은 많아요. 알츠하이머병이 발병되는 시기를 늦추거나 예방할 수 있습니다. \n",
      "generate: 그래서 우리는 하이 하이 하이 예방 기 치매 치매 치매 하이 같은 를 같은 있습니다 있습니다 있습니다.\n",
      "output tensor([[[  0.7236, -28.3931, -29.4089,  ..., -22.2856, -29.2239, -28.5374],\n",
      "         [ -4.9507, -25.2211, -26.2177,  ..., -14.2395, -26.7706, -26.0629],\n",
      "         [ -3.5978, -16.9143, -18.2542,  ...,  -9.4049, -18.1304, -18.7572],\n",
      "         ...,\n",
      "         [ 18.2241, -20.4621, -20.6091,  ..., -12.3951, -20.7202, -20.4805],\n",
      "         [ 17.4008, -20.7904, -20.9562,  ..., -12.3856, -20.8930, -20.6472],\n",
      "         [ 18.0703, -28.4179, -28.8732,  ..., -16.1384, -28.5262, -28.5035]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 여러분이 좋은 여성이라면 그럴 수 있을 거예요. \n",
      "generate: 좋은 당신이 라면 모두 할 해줄 수 있습니다\n",
      "output tensor([[[ -1.3827, -28.1683, -29.5976,  ..., -23.4537, -29.1424, -28.9024],\n",
      "         [ -3.1497, -20.6815, -20.9532,  ..., -13.9203, -20.4020, -20.3831],\n",
      "         [ -3.5065, -22.7718, -23.6300,  ..., -15.7664, -23.2725, -23.5757],\n",
      "         ...,\n",
      "         [ 16.9886, -31.4966, -31.0782,  ..., -18.7880, -31.1468, -31.4152],\n",
      "         [ 17.0376, -31.9219, -31.5052,  ..., -18.5997, -31.6031, -31.8554],\n",
      "         [ 17.5813, -34.5709, -34.2008,  ..., -19.1944, -34.3638, -34.6149]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 33 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 2.087 | Test Loss: 4.755\n",
      "\tBLEU Score:\n",
      "\t\tavg: 0.926\n",
      "\t\t1-gram: 14.311\n",
      "\t\t2-gram: 1.526\n",
      "\t\t3-gram: 0.451\n",
      "\t\t4-gram: 0.075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456043, 1.065565142789168, 1.1217228300472808, 1.1251005772205362, 0.9376270106656373, 0.945841750555376, 1.032552971972674, 1.108516565724771, 1.025004961153448, 1.246391054667423, 1.1066860083111192, 1.0136808173874745, 0.8953404182688746, 1.0005658195083458, 1.0579186716815774, 1.0521420193171729, 0.9113153109680574, 1.0266675521574615, 0.9812579918643995, 0.7768509255100765, 1.0693715832453634, 1.0003935586158077, 0.8266103868732955, 0.888504001036279, 1.198148680752794, 0.925786344677888], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167303, 15.54081410196518, 15.068451007537302, 15.399544082311628, 15.2570938285224, 14.557690604799433, 15.290158268146262, 14.485009531511755, 14.7281302838836, 15.018685290694112, 14.776259456923349, 14.368787418717236, 14.639612718144871, 14.576825387557294, 14.197495404411764, 14.849490400568856, 14.558521560574947, 14.13503366903045, 14.635902753773475, 14.169275293839702, 14.487367844899603, 14.277029960920538, 14.328287042555727, 14.043520810546314, 14.282336249704422, 14.310534016093635], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.525142876466809, 1.551031253113687, 1.6259629568923126, 1.6052787078983652, 1.50159952993406, 1.3394397565795664, 1.5621974049448066, 1.6277358837594262, 1.5357446942701272, 1.6478496377993863, 1.5076942246588998, 1.5314959433589597, 1.4715230104246122, 1.5130375468948625, 1.4352754753778645, 1.530612244897959, 1.5176067310688688, 1.612698815030733, 1.482455067856706, 1.2585525076894106, 1.4948185736557331, 1.5516976494085113, 1.3658258334389657, 1.3621648036161504, 1.5267655189746168, 1.5255777720072707], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.4751196866386188, 0.4233519513323135, 0.4630766532187335, 0.4637762630876256, 0.4086051547111825, 0.3815388734562736, 0.4589055275688358, 0.4702501469531709, 0.4510114099155195, 0.530596572066883, 0.4617479985383516, 0.4626484195541752, 0.3903068150963888, 0.4429312795425247, 0.4543094496365524, 0.44030653401452, 0.3988035892323031, 0.4634327853325214, 0.4232321916916265, 0.3348625389277701, 0.4688568358675479, 0.4452447209035848, 0.3654080389768575, 0.3903454557283196, 0.5262805041566103, 0.45126353790613716], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.132895559724828, 0.1263351326518892, 0.1395436545351687, 0.1397650436293582, 0.0825639870899947, 0.1075770072076594, 0.1036998629680382, 0.1361874498027028, 0.1082055906221821, 0.1837821618783287, 0.145819255254828, 0.1037093372973346, 0.0764275575936237, 0.102596759357532, 0.1353039134054954, 0.1224519196139163, 0.0782778864970645, 0.1051677243880326, 0.1009608689597549, 0.0609909231155598, 0.1287942077415761, 0.1015406162464986, 0.0652883569096844, 0.0834608429545138, 0.1795783500341199, 0.07456287514446557]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:32<00:00, 14.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 | Train Time: 11m 39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 189.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 아프리카 이야기가 어떻게 전해지는지 말씀드리려고요. 또 누가 그것을 말하고 있는지도요. \n",
      "generate: 아프리카 의 이야기를 이야기는 어떻게 어떻게 되고 되고, 이야기 이야기 이야기 이야기 이야기 이야기를 말해 이야기를.\n",
      "output tensor([[[ -2.0668, -30.7582, -31.7010,  ..., -20.2010, -31.5036, -31.2075],\n",
      "         [ -3.4174, -22.0537, -21.6621,  ..., -13.1802, -22.2274, -21.6626],\n",
      "         [ -4.5628, -21.5198, -21.6419,  ..., -19.9875, -22.7645, -22.4384],\n",
      "         ...,\n",
      "         [ 15.2931, -31.2249, -30.4396,  ..., -20.9683, -31.5387, -30.7133],\n",
      "         [ 17.9079, -29.1502, -28.6140,  ..., -19.5253, -28.9312, -28.9946],\n",
      "         [ 16.9119, -30.0489, -29.7346,  ..., -19.1743, -29.9310, -30.2262]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 1957년에 선교사 다섯명이 접촉을 시도했는데 중대한 실수를 범하게 됩니다. \n",
      "generate: 191 7년 에 명의 명의 명의 명의 들이 들이 려 려 했지만 했지만.. 실수를 저질 저질 실수를.\n",
      "output tensor([[[ -1.3258, -27.0806, -28.4448,  ..., -18.5647, -27.5728, -27.9151],\n",
      "         [ -1.4303, -15.4919, -16.0185,  ...,  -2.9147, -14.6817, -15.6885],\n",
      "         [ -3.8776, -15.1762, -14.7669,  ...,  -5.4871, -14.6726, -14.7721],\n",
      "         ...,\n",
      "         [ 17.5836, -26.2598, -25.9802,  ..., -18.5186, -26.1904, -26.3417],\n",
      "         [ 16.5510, -31.5654, -31.1954,  ..., -19.1024, -31.2893, -31.5160],\n",
      "         [ 18.2272, -31.3659, -31.0507,  ..., -19.2601, -30.7091, -31.4338]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 한 예로, 이것은 매우 유명한 머리털자리 은하단 입니다. \n",
      "generate: 여기 하나,,, 매우 싶은데요 유명한 유명한 가장 은하....\n",
      "output tensor([[[ -1.9746, -28.0032, -29.2646,  ..., -20.9625, -28.6420, -28.4399],\n",
      "         [ -0.7710, -23.0890, -23.2551,  ..., -20.0962, -22.4841, -22.9837],\n",
      "         [ -2.2105, -21.0645, -20.5581,  ..., -17.0975, -20.2513, -20.8174],\n",
      "         ...,\n",
      "         [ 17.4122, -26.3434, -26.1967,  ..., -18.8002, -26.0486, -26.4980],\n",
      "         [ 17.2864, -26.8139, -26.7345,  ..., -19.3324, -26.4765, -27.0940],\n",
      "         [ 18.9293, -28.4675, -28.6820,  ..., -18.7784, -28.4132, -29.0653]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 모두가 직장을 구할 수 없을 거라 했습니다. \n",
      "generate: 사람들은 제가 더 일을 줄 거라고 했습니다.\n",
      "output tensor([[[ -2.9229, -26.8600, -28.1333,  ..., -18.6830, -27.7647, -28.0204],\n",
      "         [ -3.6382, -20.1648, -20.1088,  ...,  -9.6590, -19.7900, -20.1682],\n",
      "         [ -5.6984, -19.5437, -20.0793,  ..., -11.0368, -19.6740, -20.8377],\n",
      "         ...,\n",
      "         [ 17.7572, -32.5445, -32.0385,  ..., -19.8445, -32.4275, -32.7398],\n",
      "         [ 17.7254, -32.7504, -32.2417,  ..., -19.8906, -32.6123, -32.9082],\n",
      "         [ 17.1213, -34.6630, -34.1992,  ..., -20.2895, -34.6505, -34.8743]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 34 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 2.063 | Test Loss: 4.770\n",
      "\tBLEU Score:\n",
      "\t\tavg: 1.060\n",
      "\t\t1-gram: 14.630\n",
      "\t\t2-gram: 1.542\n",
      "\t\t3-gram: 0.473\n",
      "\t\t4-gram: 0.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456043, 1.065565142789168, 1.1217228300472808, 1.1251005772205362, 0.9376270106656373, 0.945841750555376, 1.032552971972674, 1.108516565724771, 1.025004961153448, 1.246391054667423, 1.1066860083111192, 1.0136808173874745, 0.8953404182688746, 1.0005658195083458, 1.0579186716815774, 1.0521420193171729, 0.9113153109680574, 1.0266675521574615, 0.9812579918643995, 0.7768509255100765, 1.0693715832453634, 1.0003935586158077, 0.8266103868732955, 0.888504001036279, 1.198148680752794, 0.925786344677888, 1.0602270375907268], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167303, 15.54081410196518, 15.068451007537302, 15.399544082311628, 15.2570938285224, 14.557690604799433, 15.290158268146262, 14.485009531511755, 14.7281302838836, 15.018685290694112, 14.776259456923349, 14.368787418717236, 14.639612718144871, 14.576825387557294, 14.197495404411764, 14.849490400568856, 14.558521560574947, 14.13503366903045, 14.635902753773475, 14.169275293839702, 14.487367844899603, 14.277029960920538, 14.328287042555727, 14.043520810546314, 14.282336249704422, 14.310534016093635, 14.630489316917044], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.525142876466809, 1.551031253113687, 1.6259629568923126, 1.6052787078983652, 1.50159952993406, 1.3394397565795664, 1.5621974049448066, 1.6277358837594262, 1.5357446942701272, 1.6478496377993863, 1.5076942246588998, 1.5314959433589597, 1.4715230104246122, 1.5130375468948625, 1.4352754753778645, 1.530612244897959, 1.5176067310688688, 1.612698815030733, 1.482455067856706, 1.2585525076894106, 1.4948185736557331, 1.5516976494085113, 1.3658258334389657, 1.3621648036161504, 1.5267655189746168, 1.5255777720072707, 1.5421804718337873], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.4751196866386188, 0.4233519513323135, 0.4630766532187335, 0.4637762630876256, 0.4086051547111825, 0.3815388734562736, 0.4589055275688358, 0.4702501469531709, 0.4510114099155195, 0.530596572066883, 0.4617479985383516, 0.4626484195541752, 0.3903068150963888, 0.4429312795425247, 0.4543094496365524, 0.44030653401452, 0.3988035892323031, 0.4634327853325214, 0.4232321916916265, 0.3348625389277701, 0.4688568358675479, 0.4452447209035848, 0.3654080389768575, 0.3903454557283196, 0.5262805041566103, 0.4512635379061371, 0.4726051953978032], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.132895559724828, 0.1263351326518892, 0.1395436545351687, 0.1397650436293582, 0.0825639870899947, 0.1075770072076594, 0.1036998629680382, 0.1361874498027028, 0.1082055906221821, 0.1837821618783287, 0.145819255254828, 0.1037093372973346, 0.0764275575936237, 0.102596759357532, 0.1353039134054954, 0.1224519196139163, 0.0782778864970645, 0.1051677243880326, 0.1009608689597549, 0.0609909231155598, 0.1287942077415761, 0.1015406162464986, 0.0652883569096844, 0.0834608429545138, 0.1795783500341199, 0.0745628751444655, 0.11849580036942808]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:32<00:00, 14.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 | Train Time: 11m 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 193.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 우리가 어떻게 하는지 실제 예를 하나 보여드리려고 합니다. \n",
      "generate: 저는 일이 작용 지 지 예를 예를.\n",
      "output tensor([[[ -2.8865, -30.8775, -32.1059,  ..., -23.5203, -31.7813, -31.4726],\n",
      "         [ -4.8568, -25.7773, -25.3478,  ..., -21.6029, -25.5411, -25.2676],\n",
      "         [ -4.3959, -22.3963, -23.1133,  ..., -20.9649, -22.4202, -21.9911],\n",
      "         ...,\n",
      "         [ 17.9126, -31.0734, -30.2609,  ..., -22.1812, -30.5654, -30.4562],\n",
      "         [ 17.9715, -31.6123, -30.8151,  ..., -22.4798, -31.1227, -31.0318],\n",
      "         [ 17.9299, -34.7088, -33.7989,  ..., -22.3156, -34.1571, -34.2308]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 이 사람은 월든호수에서 소로우의 작품을 책으로 만들고 있는 에릭 엘드레드씨입니다. \n",
      "generate: 벤 엑 슬 드 드 드 어 의 버 레이 의 의 에 입니다 입니다 데 입니다 입니다\n",
      "output tensor([[[  0.0879, -30.2819, -30.9156,  ..., -21.6738, -30.8535, -30.5898],\n",
      "         [ -2.7770, -18.6711, -18.8466,  ..., -11.1318, -19.2754, -18.9069],\n",
      "         [ -3.6216, -23.9723, -24.4523,  ..., -14.0483, -24.1372, -23.6937],\n",
      "         ...,\n",
      "         [ 13.6935, -19.4607, -19.1540,  ..., -11.3608, -18.8283, -18.2243],\n",
      "         [ 14.0213, -21.0874, -20.7498,  ..., -11.8662, -20.4537, -19.9655],\n",
      "         [ 17.8919, -25.8453, -26.0080,  ..., -14.4899, -25.8845, -26.1653]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 그래서 대규모로 구하면 어떤 것을 쓸까요? \n",
      "generate: 그럼, 규모를 을 생산 무엇이 어떻게 어떻게 요??\n",
      "output tensor([[[ -4.7515, -31.6670, -32.9831,  ..., -23.7156, -32.4521, -32.3040],\n",
      "         [ -3.4443, -21.4998, -20.8656,  ..., -11.5596, -21.5100, -20.8702],\n",
      "         [ -1.3198, -15.1220, -13.9588,  ...,  -8.6159, -14.3747, -14.6505],\n",
      "         ...,\n",
      "         [ 16.7097, -34.5333, -34.3071,  ..., -21.6184, -34.4736, -34.8160],\n",
      "         [ 16.6311, -35.2699, -35.0667,  ..., -21.8573, -35.1870, -35.5544],\n",
      "         [ 17.5690, -38.3470, -37.9153,  ..., -21.9950, -38.0117, -38.4293]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 경고의 측면에서 실수를 저지르는 것이 낫습니다. \n",
      "generate: 웬만하면 하 하 하지 하지 하지 하지 마세요.\n",
      "output tensor([[[ -1.1153, -29.8127, -30.8985,  ..., -22.2368, -30.3186, -30.2670],\n",
      "         [ -4.7284, -13.8342, -13.1498,  ...,  -5.1479, -13.3661, -12.6803],\n",
      "         [ -2.8233, -12.7767, -13.2206,  ...,  -6.9710, -12.7253, -12.6043],\n",
      "         ...,\n",
      "         [ 17.3136, -32.9145, -32.1437,  ..., -20.9688, -32.2514, -32.4275],\n",
      "         [ 17.7401, -32.4334, -31.6637,  ..., -20.6520, -31.8410, -32.0013],\n",
      "         [ 18.1732, -32.5512, -31.9264,  ..., -19.1914, -32.0203, -32.3195]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 35 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 2.039 | Test Loss: 4.813\n",
      "\tBLEU Score:\n",
      "\t\tavg: 0.896\n",
      "\t\t1-gram: 13.996\n",
      "\t\t2-gram: 1.347\n",
      "\t\t3-gram: 0.376\n",
      "\t\t4-gram: 0.091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456043, 1.065565142789168, 1.1217228300472808, 1.1251005772205362, 0.9376270106656373, 0.945841750555376, 1.032552971972674, 1.108516565724771, 1.025004961153448, 1.246391054667423, 1.1066860083111192, 1.0136808173874745, 0.8953404182688746, 1.0005658195083458, 1.0579186716815774, 1.0521420193171729, 0.9113153109680574, 1.0266675521574615, 0.9812579918643995, 0.7768509255100765, 1.0693715832453634, 1.0003935586158077, 0.8266103868732955, 0.888504001036279, 1.198148680752794, 0.925786344677888, 1.0602270375907268, 0.8957322671890489], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167303, 15.54081410196518, 15.068451007537302, 15.399544082311628, 15.2570938285224, 14.557690604799433, 15.290158268146262, 14.485009531511755, 14.7281302838836, 15.018685290694112, 14.776259456923349, 14.368787418717236, 14.639612718144871, 14.576825387557294, 14.197495404411764, 14.849490400568856, 14.558521560574947, 14.13503366903045, 14.635902753773475, 14.169275293839702, 14.487367844899603, 14.277029960920538, 14.328287042555727, 14.043520810546314, 14.282336249704422, 14.310534016093635, 14.630489316917044, 13.995837669094692], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.525142876466809, 1.551031253113687, 1.6259629568923126, 1.6052787078983652, 1.50159952993406, 1.3394397565795664, 1.5621974049448066, 1.6277358837594262, 1.5357446942701272, 1.6478496377993863, 1.5076942246588998, 1.5314959433589597, 1.4715230104246122, 1.5130375468948625, 1.4352754753778645, 1.530612244897959, 1.5176067310688688, 1.612698815030733, 1.482455067856706, 1.2585525076894106, 1.4948185736557331, 1.5516976494085113, 1.3658258334389657, 1.3621648036161504, 1.5267655189746168, 1.5255777720072707, 1.5421804718337873, 1.3467910173027364], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.4751196866386188, 0.4233519513323135, 0.4630766532187335, 0.4637762630876256, 0.4086051547111825, 0.3815388734562736, 0.4589055275688358, 0.4702501469531709, 0.4510114099155195, 0.530596572066883, 0.4617479985383516, 0.4626484195541752, 0.3903068150963888, 0.4429312795425247, 0.4543094496365524, 0.44030653401452, 0.3988035892323031, 0.4634327853325214, 0.4232321916916265, 0.3348625389277701, 0.4688568358675479, 0.4452447209035848, 0.3654080389768575, 0.3903454557283196, 0.5262805041566103, 0.4512635379061371, 0.4726051953978032, 0.3758538418799229], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.132895559724828, 0.1263351326518892, 0.1395436545351687, 0.1397650436293582, 0.0825639870899947, 0.1075770072076594, 0.1036998629680382, 0.1361874498027028, 0.1082055906221821, 0.1837821618783287, 0.145819255254828, 0.1037093372973346, 0.0764275575936237, 0.102596759357532, 0.1353039134054954, 0.1224519196139163, 0.0782778864970645, 0.1051677243880326, 0.1009608689597549, 0.0609909231155598, 0.1287942077415761, 0.1015406162464986, 0.0652883569096844, 0.0834608429545138, 0.1795783500341199, 0.0745628751444655, 0.118495800369428, 0.0908646117285245]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:31<00:00, 14.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 | Train Time: 11m 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 190.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 만약 기하학이 우주에 쓰여진 언어라면 이 스케치는 우리가 우주의 어떤 요소 내에도 존재할 수 있음을 말합니다. \n",
      "generate: 어떻게, 하 학 가 우주 우주 언어 가 어떨까요 라면, 우리가 우리가 우리가 수? 수? 수\n",
      "output tensor([[[ -4.1076, -28.0006, -28.9928,  ..., -19.3300, -28.7506, -28.4069],\n",
      "         [ -4.1415, -26.6030, -27.1542,  ..., -16.8131, -26.4951, -25.9161],\n",
      "         [ -1.4671, -22.9990, -23.3136,  ..., -15.9291, -23.4453, -23.2751],\n",
      "         ...,\n",
      "         [  4.9796, -22.0537, -22.3432,  ..., -19.1418, -22.5554, -21.5155],\n",
      "         [  4.8989, -20.6714, -20.9183,  ..., -18.2628, -20.9314, -20.1575],\n",
      "         [ 12.0059, -22.3692, -22.3724,  ..., -14.6683, -23.0032, -22.2020]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 다른 나라들이 제게 눈이 먼 천문학자는 없기 때문에 감각의 연구는 천문학을 공부하는 것과는 연관이 없다고 말했을 때 남아프리카는 제게 이렇게 말했습니다. \"우리는 장애가 있는 사람들도 학문이 기여할 수 있기를 바란다.\" \n",
      "generate: 다른 다른 들은 문학 공 학 문학 문학 문학 문학 않은 되지 천 에 집중 천, 지식이 언어 억 있다고 있다고 했습니다.\n",
      "output tensor([[[ -3.7494, -25.1558, -26.2527,  ..., -16.1010, -25.4506, -25.6097],\n",
      "         [ -3.8238, -21.6462, -21.7493,  ..., -12.5966, -22.0976, -21.5953],\n",
      "         [ -1.0498, -20.2227, -19.3953,  ...,  -9.8847, -19.2358, -18.8116],\n",
      "         ...,\n",
      "         [  8.3620, -22.2516, -22.5390,  ..., -16.2061, -22.2599, -22.1148],\n",
      "         [  9.0875, -22.7633, -22.7430,  ..., -16.5511, -22.5638, -21.7667],\n",
      "         [ 19.0559, -26.2766, -26.1602,  ..., -13.8439, -25.7145, -26.0193]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 그 아이디어는 아주 단순하지만 뛰어난 발상이어서, 왜 예전에는 이런게 없었나 의아할 것입니다. \n",
      "generate: 어떻게 간단한 간단한 간단한,, 생각. 생각 생각 생각을 한번도 어떻게 했을 생각해 못했을 못했을 요 요\n",
      "output tensor([[[ -2.5968, -25.1994, -26.5385,  ..., -18.2432, -25.6057, -25.9655],\n",
      "         [ -5.6504, -21.8903, -22.8664,  ..., -11.0648, -22.2088, -22.0395],\n",
      "         [ -3.3529, -18.7434, -18.8035,  ..., -11.8922, -18.0996, -18.1035],\n",
      "         ...,\n",
      "         [ 17.0798, -26.5910, -26.3838,  ..., -18.4247, -26.5663, -26.7542],\n",
      "         [ 16.6050, -26.9135, -26.7275,  ..., -18.3046, -26.7938, -27.0210],\n",
      "         [ 18.4517, -33.0105, -32.6427,  ..., -20.7466, -32.9486, -32.8044]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 서로 다른 수 많은 관측 결과에 빠짐없이 부합하는 가설을 찾는 작업은 결코 주먹구구식으로 이루어질 수 없습니다. 여러분 손가락이 아무리 많더라도요. \n",
      "generate: 모든 모든 결과를 결과를 들을 때 수 결과, 큰 큰 큰 큰 큰 거. 않네요.\n",
      "output tensor([[[ -1.3987, -28.2336, -29.2213,  ..., -20.6116, -28.7540, -28.4816],\n",
      "         [ -2.7890, -23.6606, -22.3763,  ..., -12.6875, -22.8722, -22.3955],\n",
      "         [ -2.7811, -22.7649, -22.6383,  ..., -14.1147, -22.4054, -22.1570],\n",
      "         ...,\n",
      "         [ 12.5618, -23.5520, -23.3570,  ..., -16.7706, -23.4020, -23.1365],\n",
      "         [ 13.1194, -24.1057, -23.9190,  ..., -16.4794, -23.7628, -23.7707],\n",
      "         [ 16.7903, -31.1995, -31.7729,  ..., -19.7090, -31.1227, -30.8505]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 36 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 2.016 | Test Loss: 4.850\n",
      "\tBLEU Score:\n",
      "\t\tavg: 0.981\n",
      "\t\t1-gram: 14.648\n",
      "\t\t2-gram: 1.525\n",
      "\t\t3-gram: 0.429\n",
      "\t\t4-gram: 0.097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456043, 1.065565142789168, 1.1217228300472808, 1.1251005772205362, 0.9376270106656373, 0.945841750555376, 1.032552971972674, 1.108516565724771, 1.025004961153448, 1.246391054667423, 1.1066860083111192, 1.0136808173874745, 0.8953404182688746, 1.0005658195083458, 1.0579186716815774, 1.0521420193171729, 0.9113153109680574, 1.0266675521574615, 0.9812579918643995, 0.7768509255100765, 1.0693715832453634, 1.0003935586158077, 0.8266103868732955, 0.888504001036279, 1.198148680752794, 0.925786344677888, 1.0602270375907268, 0.8957322671890489, 0.9814428243438064], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167303, 15.54081410196518, 15.068451007537302, 15.399544082311628, 15.2570938285224, 14.557690604799433, 15.290158268146262, 14.485009531511755, 14.7281302838836, 15.018685290694112, 14.776259456923349, 14.368787418717236, 14.639612718144871, 14.576825387557294, 14.197495404411764, 14.849490400568856, 14.558521560574947, 14.13503366903045, 14.635902753773475, 14.169275293839702, 14.487367844899603, 14.277029960920538, 14.328287042555727, 14.043520810546314, 14.282336249704422, 14.310534016093635, 14.630489316917044, 13.995837669094692, 14.648120256342105], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.525142876466809, 1.551031253113687, 1.6259629568923126, 1.6052787078983652, 1.50159952993406, 1.3394397565795664, 1.5621974049448066, 1.6277358837594262, 1.5357446942701272, 1.6478496377993863, 1.5076942246588998, 1.5314959433589597, 1.4715230104246122, 1.5130375468948625, 1.4352754753778645, 1.530612244897959, 1.5176067310688688, 1.612698815030733, 1.482455067856706, 1.2585525076894106, 1.4948185736557331, 1.5516976494085113, 1.3658258334389657, 1.3621648036161504, 1.5267655189746168, 1.5255777720072707, 1.5421804718337873, 1.3467910173027364, 1.5253758513543203], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.4751196866386188, 0.4233519513323135, 0.4630766532187335, 0.4637762630876256, 0.4086051547111825, 0.3815388734562736, 0.4589055275688358, 0.4702501469531709, 0.4510114099155195, 0.530596572066883, 0.4617479985383516, 0.4626484195541752, 0.3903068150963888, 0.4429312795425247, 0.4543094496365524, 0.44030653401452, 0.3988035892323031, 0.4634327853325214, 0.4232321916916265, 0.3348625389277701, 0.4688568358675479, 0.4452447209035848, 0.3654080389768575, 0.3903454557283196, 0.5262805041566103, 0.4512635379061371, 0.4726051953978032, 0.3758538418799229, 0.42865275777770334], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.132895559724828, 0.1263351326518892, 0.1395436545351687, 0.1397650436293582, 0.0825639870899947, 0.1075770072076594, 0.1036998629680382, 0.1361874498027028, 0.1082055906221821, 0.1837821618783287, 0.145819255254828, 0.1037093372973346, 0.0764275575936237, 0.102596759357532, 0.1353039134054954, 0.1224519196139163, 0.0782778864970645, 0.1051677243880326, 0.1009608689597549, 0.0609909231155598, 0.1287942077415761, 0.1015406162464986, 0.0652883569096844, 0.0834608429545138, 0.1795783500341199, 0.0745628751444655, 0.118495800369428, 0.0908646117285245, 0.09687141216991964]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:33<00:00, 14.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 | Train Time: 11m 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:55<00:00, 44.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 | Test Time: 0m 55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 190.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 여기 한 사례가 있는데요. 1960년대에 영국에서 초등학교에서 중학교로 올라가는 학생들을 상대로 실험을 한 적이 있습니다. \n",
      "generate: 2002년, 년 년 년 년 년 년 에 에 연구 에 에 프로젝트 프로젝트 일어났..\n",
      "output tensor([[[ -1.5874, -25.0037, -26.2873,  ..., -20.6294, -25.7459, -26.0713],\n",
      "         [ -2.8133, -13.7543, -14.5207,  ..., -11.6215, -15.0032, -14.2347],\n",
      "         [ -0.5845, -13.7354, -13.8216,  ..., -12.4648, -15.2906, -14.8209],\n",
      "         ...,\n",
      "         [ 16.8641, -25.0173, -24.7491,  ..., -17.4029, -24.4319, -24.9640],\n",
      "         [ 16.6930, -25.0636, -24.7436,  ..., -17.5985, -24.3263, -24.8137],\n",
      "         [ 18.1451, -27.6681, -27.1481,  ..., -17.7026, -26.9575, -27.2458]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 저는 얼마나 도시들이 가치가 있고 그 도시들에 드는 비용보다 도시들이 얼마나 값어치가 있는 지에 대한 요지를 설명하려고 노력했습니다. \n",
      "generate: 저는 도시 것은 것은 도시를 도시를 것보다 더 더 더 더 들 들 것을 들을 것을 합니다..\n",
      "output tensor([[[ -0.9102, -28.7946, -29.6170,  ..., -22.3982, -28.8725, -29.5144],\n",
      "         [ -0.1326, -17.3360, -17.0132,  ..., -11.1280, -17.2893, -18.0778],\n",
      "         [ -3.5440, -18.8947, -18.2684,  ..., -15.7653, -18.7953, -19.4898],\n",
      "         ...,\n",
      "         [ 13.4839, -23.8287, -23.6416,  ..., -17.1521, -23.4685, -23.6036],\n",
      "         [ 14.7044, -23.9094, -23.7628,  ..., -16.9099, -23.4792, -23.6121],\n",
      "         [ 17.5630, -28.2429, -28.3381,  ..., -17.7966, -27.6802, -28.0198]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 그리고 저는 대형 트럭에 천연가스를 사용해야 한다고 생각했죠. \n",
      "generate: 전 목표는 대형 트럭 트럭 것이.\n",
      "output tensor([[[ -2.8826, -26.1961, -27.6205,  ..., -21.5383, -26.4337, -27.1028],\n",
      "         [ -1.0564, -20.0528, -19.3949,  ..., -14.6639, -19.2832, -19.6940],\n",
      "         [ -2.5530, -16.3166, -16.5057,  ..., -12.6525, -15.1483, -16.3506],\n",
      "         ...,\n",
      "         [ 18.0595, -32.8025, -32.2889,  ..., -20.0350, -32.2504, -32.6683],\n",
      "         [ 17.9090, -33.0469, -32.5171,  ..., -20.1555, -32.4835, -32.8844],\n",
      "         [ 18.2277, -34.4112, -33.9299,  ..., -20.1956, -34.1778, -34.2984]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 저는 그 사실에 자부심을 느낍니다. \n",
      "generate: 전 전 스 럽 럽.\n",
      "output tensor([[[ -1.4849, -28.3886, -29.5094,  ..., -23.0543, -28.8934, -29.1956],\n",
      "         [ -3.8369, -17.8939, -18.5991,  ..., -14.8892, -17.6232, -18.3433],\n",
      "         [ -4.1697, -18.2057, -18.5039,  ..., -12.4860, -17.6651, -18.9305],\n",
      "         ...,\n",
      "         [ 16.7578, -35.2676, -34.7035,  ..., -22.6294, -34.7305, -34.9330],\n",
      "         [ 16.6625, -35.2342, -34.6353,  ..., -22.5330, -34.6829, -34.8668],\n",
      "         [ 16.9771, -34.9879, -34.3131,  ..., -21.3906, -34.6533, -34.7667]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 37 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 1.996 | Test Loss: 4.893\n",
      "\tBLEU Score:\n",
      "\t\tavg: 1.174\n",
      "\t\t1-gram: 14.474\n",
      "\t\t2-gram: 1.686\n",
      "\t\t3-gram: 0.511\n",
      "\t\t4-gram: 0.153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456043, 1.065565142789168, 1.1217228300472808, 1.1251005772205362, 0.9376270106656373, 0.945841750555376, 1.032552971972674, 1.108516565724771, 1.025004961153448, 1.246391054667423, 1.1066860083111192, 1.0136808173874745, 0.8953404182688746, 1.0005658195083458, 1.0579186716815774, 1.0521420193171729, 0.9113153109680574, 1.0266675521574615, 0.9812579918643995, 0.7768509255100765, 1.0693715832453634, 1.0003935586158077, 0.8266103868732955, 0.888504001036279, 1.198148680752794, 0.925786344677888, 1.0602270375907268, 0.8957322671890489, 0.9814428243438064, 1.1743677925211478], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167303, 15.54081410196518, 15.068451007537302, 15.399544082311628, 15.2570938285224, 14.557690604799433, 15.290158268146262, 14.485009531511755, 14.7281302838836, 15.018685290694112, 14.776259456923349, 14.368787418717236, 14.639612718144871, 14.576825387557294, 14.197495404411764, 14.849490400568856, 14.558521560574947, 14.13503366903045, 14.635902753773475, 14.169275293839702, 14.487367844899603, 14.277029960920538, 14.328287042555727, 14.043520810546314, 14.282336249704422, 14.310534016093635, 14.630489316917044, 13.995837669094692, 14.648120256342104, 14.473953910573629], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.525142876466809, 1.551031253113687, 1.6259629568923126, 1.6052787078983652, 1.50159952993406, 1.3394397565795664, 1.5621974049448066, 1.6277358837594262, 1.5357446942701272, 1.6478496377993863, 1.5076942246588998, 1.5314959433589597, 1.4715230104246122, 1.5130375468948625, 1.4352754753778645, 1.530612244897959, 1.5176067310688688, 1.612698815030733, 1.482455067856706, 1.2585525076894106, 1.4948185736557331, 1.5516976494085113, 1.3658258334389657, 1.3621648036161504, 1.5267655189746168, 1.5255777720072707, 1.5421804718337873, 1.3467910173027364, 1.5253758513543203, 1.6857951541165126], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.4751196866386188, 0.4233519513323135, 0.4630766532187335, 0.4637762630876256, 0.4086051547111825, 0.3815388734562736, 0.4589055275688358, 0.4702501469531709, 0.4510114099155195, 0.530596572066883, 0.4617479985383516, 0.4626484195541752, 0.3903068150963888, 0.4429312795425247, 0.4543094496365524, 0.44030653401452, 0.3988035892323031, 0.4634327853325214, 0.4232321916916265, 0.3348625389277701, 0.4688568358675479, 0.4452447209035848, 0.3654080389768575, 0.3903454557283196, 0.5262805041566103, 0.4512635379061371, 0.4726051953978032, 0.3758538418799229, 0.4286527577777033, 0.5107455558503582], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.132895559724828, 0.1263351326518892, 0.1395436545351687, 0.1397650436293582, 0.0825639870899947, 0.1075770072076594, 0.1036998629680382, 0.1361874498027028, 0.1082055906221821, 0.1837821618783287, 0.145819255254828, 0.1037093372973346, 0.0764275575936237, 0.102596759357532, 0.1353039134054954, 0.1224519196139163, 0.0782778864970645, 0.1051677243880326, 0.1009608689597549, 0.0609909231155598, 0.1287942077415761, 0.1015406162464986, 0.0652883569096844, 0.0834608429545138, 0.1795783500341199, 0.0745628751444655, 0.118495800369428, 0.0908646117285245, 0.0968714121699196, 0.15262298573152552]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:32<00:00, 14.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 | Train Time: 11m 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:55<00:00, 44.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 | Test Time: 0m 55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 189.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 자, 이전의 그 어느때보다, 지금은 맹목적으로 추종하고 맹목적으로 수용하고 맹목적으로 신뢰하는 시대가 아닙니다. \n",
      "generate: 이제 비해, 진보 에 에 에 시선 하지 맹 맹 때보다 해야 해야..\n",
      "output tensor([[[ -3.4289, -31.3549, -32.6366,  ..., -24.2420, -32.3220, -32.4094],\n",
      "         [ -5.3186, -25.9030, -26.2123,  ..., -12.6708, -25.9933, -25.2342],\n",
      "         [ -1.7544, -19.5246, -19.8379,  ..., -15.4363, -20.6635, -19.6838],\n",
      "         ...,\n",
      "         [ 16.0704, -20.8797, -21.3662,  ..., -12.7913, -21.3111, -21.3081],\n",
      "         [ 15.7144, -21.5736, -21.8521,  ..., -13.0434, -21.6152, -21.7978],\n",
      "         [ 19.1768, -26.7064, -27.0320,  ..., -15.2355, -26.6792, -27.0018]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 우선 -- 이게 제가 제일 좋아하는 건데요 -- 제가 찾아본 한, 상원은 공식적으로 결코 대통령(president)라는 호칭을 인준한 적이 없습니다. \n",
      "generate: 무엇보다 번째로, 가장, 제가 제가 제가 제가 제가 제가 수 들 장 들 서 에 트 트 대부분의 들 를 에 알아 있음을 있음을..\n",
      "output tensor([[[ -3.1495, -25.6045, -26.5552,  ..., -22.0892, -25.8072, -26.1773],\n",
      "         [ -3.5303, -13.3066, -14.1993,  ...,  -7.3433, -13.8822, -13.6456],\n",
      "         [ -1.3521, -20.7350, -21.1165,  ..., -14.6999, -21.4639, -20.9067],\n",
      "         ...,\n",
      "         [  8.5573, -17.3276, -17.7761,  ..., -10.3548, -17.5013, -17.8052],\n",
      "         [ 10.3178, -18.8503, -19.1102,  ..., -12.3604, -19.0067, -18.8192],\n",
      "         [ 18.0433, -22.3572, -22.3998,  ..., -11.4400, -21.9693, -22.3429]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 그녀는 매일의 소비를 충당시키기에 충분한 만큼의 수입이 있습니다. \n",
      "generate: 그녀는 지역의 이 을 수 지불..\n",
      "output tensor([[[ -1.0103, -24.6313, -25.8253,  ..., -20.1278, -25.2385, -25.5854],\n",
      "         [ -3.9108, -12.0245, -10.8751,  ...,  -9.4150, -12.4223, -11.9602],\n",
      "         [ -5.0342, -14.3435, -13.9586,  ...,  -5.6800, -15.0048, -14.0691],\n",
      "         ...,\n",
      "         [ 18.3832, -29.3618, -28.7329,  ..., -18.9580, -29.1935, -29.2958],\n",
      "         [ 18.4009, -29.6410, -29.0485,  ..., -19.1268, -29.5189, -29.6319],\n",
      "         [ 19.7184, -26.5008, -25.9726,  ..., -15.2723, -26.4070, -26.5741]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence (웃음) 이들은 행성의 이름을 짓는 사람들이고 퍼스트 네임을 쓰지 않는군요. \n",
      "generate: ( 웃음 ) 이 사람들은 이름을 이름을 이름을 이름을 이름을 이름을 이름을 이름을 이름을 이름을 이름을 않는 않는..\n",
      "output tensor([[[ -3.6139, -28.1685, -29.3987,  ..., -22.0104, -28.5054, -28.6741],\n",
      "         [ -2.1566, -19.4397, -20.5972,  ..., -14.5407, -20.1929, -20.3898],\n",
      "         [  1.4164, -24.2257, -24.7230,  ..., -13.7908, -24.5958, -24.9056],\n",
      "         ...,\n",
      "         [ 14.0449, -21.2375, -21.7996,  ..., -13.7946, -21.4448, -21.3267],\n",
      "         [ 14.9935, -21.5123, -21.9700,  ..., -13.7353, -21.5696, -21.2735],\n",
      "         [ 15.6701, -27.8000, -28.0521,  ..., -15.4760, -27.7046, -28.1587]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 38 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 1.972 | Test Loss: 4.862\n",
      "\tBLEU Score:\n",
      "\t\tavg: 0.995\n",
      "\t\t1-gram: 14.399\n",
      "\t\t2-gram: 1.410\n",
      "\t\t3-gram: 0.452\n",
      "\t\t4-gram: 0.107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456043, 1.065565142789168, 1.1217228300472808, 1.1251005772205362, 0.9376270106656373, 0.945841750555376, 1.032552971972674, 1.108516565724771, 1.025004961153448, 1.246391054667423, 1.1066860083111192, 1.0136808173874745, 0.8953404182688746, 1.0005658195083458, 1.0579186716815774, 1.0521420193171729, 0.9113153109680574, 1.0266675521574615, 0.9812579918643995, 0.7768509255100765, 1.0693715832453634, 1.0003935586158077, 0.8266103868732955, 0.888504001036279, 1.198148680752794, 0.925786344677888, 1.0602270375907268, 0.8957322671890489, 0.9814428243438064, 1.1743677925211478, 0.9951812437001133], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167303, 15.54081410196518, 15.068451007537302, 15.399544082311628, 15.2570938285224, 14.557690604799433, 15.290158268146262, 14.485009531511755, 14.7281302838836, 15.018685290694112, 14.776259456923349, 14.368787418717236, 14.639612718144871, 14.576825387557294, 14.197495404411764, 14.849490400568856, 14.558521560574947, 14.13503366903045, 14.635902753773475, 14.169275293839702, 14.487367844899603, 14.277029960920538, 14.328287042555727, 14.043520810546314, 14.282336249704422, 14.310534016093635, 14.630489316917044, 13.995837669094692, 14.648120256342104, 14.473953910573629, 14.39894319682959], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.525142876466809, 1.551031253113687, 1.6259629568923126, 1.6052787078983652, 1.50159952993406, 1.3394397565795664, 1.5621974049448066, 1.6277358837594262, 1.5357446942701272, 1.6478496377993863, 1.5076942246588998, 1.5314959433589597, 1.4715230104246122, 1.5130375468948625, 1.4352754753778645, 1.530612244897959, 1.5176067310688688, 1.612698815030733, 1.482455067856706, 1.2585525076894106, 1.4948185736557331, 1.5516976494085113, 1.3658258334389657, 1.3621648036161504, 1.5267655189746168, 1.5255777720072707, 1.5421804718337873, 1.3467910173027364, 1.5253758513543203, 1.6857951541165126, 1.4096366755028849], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.4751196866386188, 0.4233519513323135, 0.4630766532187335, 0.4637762630876256, 0.4086051547111825, 0.3815388734562736, 0.4589055275688358, 0.4702501469531709, 0.4510114099155195, 0.530596572066883, 0.4617479985383516, 0.4626484195541752, 0.3903068150963888, 0.4429312795425247, 0.4543094496365524, 0.44030653401452, 0.3988035892323031, 0.4634327853325214, 0.4232321916916265, 0.3348625389277701, 0.4688568358675479, 0.4452447209035848, 0.3654080389768575, 0.3903454557283196, 0.5262805041566103, 0.4512635379061371, 0.4726051953978032, 0.3758538418799229, 0.4286527577777033, 0.5107455558503582, 0.45235323465824046], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.132895559724828, 0.1263351326518892, 0.1395436545351687, 0.1397650436293582, 0.0825639870899947, 0.1075770072076594, 0.1036998629680382, 0.1361874498027028, 0.1082055906221821, 0.1837821618783287, 0.145819255254828, 0.1037093372973346, 0.0764275575936237, 0.102596759357532, 0.1353039134054954, 0.1224519196139163, 0.0782778864970645, 0.1051677243880326, 0.1009608689597549, 0.0609909231155598, 0.1287942077415761, 0.1015406162464986, 0.0652883569096844, 0.0834608429545138, 0.1795783500341199, 0.0745628751444655, 0.118495800369428, 0.0908646117285245, 0.0968714121699196, 0.1526229857315255, 0.10682999786340004]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:32<00:00, 14.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 | Train Time: 11m 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 189.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 도전으로 가득차 있는 곳이니까요 \n",
      "generate: 어려운 에 이 이 가득 었 습 니\n",
      "output tensor([[[ -0.9254, -30.5903, -31.6776,  ..., -23.3565, -31.1684, -31.4832],\n",
      "         [ -4.8470, -26.3421, -26.6166,  ..., -14.6541, -27.1156, -26.3080],\n",
      "         [ -1.6047, -19.6580, -18.5580,  ..., -13.7429, -19.1382, -18.9007],\n",
      "         ...,\n",
      "         [ 18.0115, -31.6980, -31.3475,  ..., -19.5947, -31.4641, -31.7389],\n",
      "         [ 18.0230, -31.0013, -30.6737,  ..., -19.4953, -30.9522, -31.0693],\n",
      "         [ 20.1784, -29.8664, -29.6721,  ..., -18.5323, -30.1228, -30.1976]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 다른 사람을 돕기 위해 자선활동을 하면, 지속되고 또 지속됩니다. \n",
      "generate: 하지만 다른 사람을 주는 하는 하면 계속 계속...\n",
      "output tensor([[[ -0.9216, -31.7748, -32.8617,  ..., -27.8450, -32.3978, -32.5543],\n",
      "         [ -2.7468, -17.8516, -17.9963,  ..., -11.7952, -18.5809, -18.6201],\n",
      "         [ -3.1784, -16.3712, -16.0860,  ..., -12.8726, -16.6504, -16.6377],\n",
      "         ...,\n",
      "         [ 18.2911, -28.7725, -28.7378,  ..., -19.1729, -28.8452, -29.1574],\n",
      "         [ 18.1639, -30.1945, -30.1599,  ..., -19.8478, -30.3317, -30.4672],\n",
      "         [ 19.4162, -31.5063, -31.4414,  ..., -19.7085, -31.7057, -31.8539]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 기후는 굉장히 복잡하고 일관성이 없는 시스템을 가지고 있어요. 종잡을 수 없는 긍정적인 피드백, 보이지 않은 장애물들과 돌이킬 수 없는 시점들이 존재하죠. \n",
      "generate: 기후 은 이것은 예측 비 하고 선 적 극 으로 성 점.. 의 의 의 의 의 의 의 에..\n",
      "output tensor([[[ -1.6997, -28.9662, -29.9325,  ..., -25.9065, -29.2073, -29.3622],\n",
      "         [ -5.9054, -26.4344, -26.0492,  ..., -17.9845, -26.3896, -26.5130],\n",
      "         [ -4.6933, -24.2208, -24.3630,  ..., -20.3737, -23.6054, -24.1458],\n",
      "         ...,\n",
      "         [ 16.3227, -21.1207, -20.9477,  ..., -14.0503, -20.6256, -20.5185],\n",
      "         [ 15.7175, -23.2028, -23.4483,  ..., -14.3068, -22.7959, -22.6833],\n",
      "         [ 16.5499, -32.2010, -31.9211,  ..., -18.1098, -31.1178, -31.6747]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 그들은 매니저들을 들어오도록 허용하는 법적인 시스템과 또한 외부의 법 시스템을 실시하고 있습니다. \n",
      "generate: 이들이 관리 의사 있는 있는 있는 있는 있는 있는 집행 있는 기관 시스템을 시스템을 만들고 만들고 만들고.\n",
      "output tensor([[[ -1.7340, -26.5730, -27.8362,  ..., -24.9531, -27.4745, -27.2617],\n",
      "         [ -6.4280, -24.0473, -23.5549,  ..., -17.4870, -24.9348, -23.8795],\n",
      "         [ -4.3444, -20.5872, -21.4849,  ..., -14.1801, -20.4812, -20.4624],\n",
      "         ...,\n",
      "         [ 18.2016, -21.5115, -21.2906,  ..., -14.6091, -20.9792, -21.3135],\n",
      "         [ 16.5841, -28.6248, -27.9305,  ..., -16.2827, -28.1708, -28.8357],\n",
      "         [ 18.9914, -27.7157, -27.5539,  ..., -17.9653, -27.4516, -28.0097]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 39 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 1.952 | Test Loss: 4.907\n",
      "\tBLEU Score:\n",
      "\t\tavg: 0.949\n",
      "\t\t1-gram: 13.975\n",
      "\t\t2-gram: 1.387\n",
      "\t\t3-gram: 0.423\n",
      "\t\t4-gram: 0.099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456043, 1.065565142789168, 1.1217228300472808, 1.1251005772205362, 0.9376270106656373, 0.945841750555376, 1.032552971972674, 1.108516565724771, 1.025004961153448, 1.246391054667423, 1.1066860083111192, 1.0136808173874745, 0.8953404182688746, 1.0005658195083458, 1.0579186716815774, 1.0521420193171729, 0.9113153109680574, 1.0266675521574615, 0.9812579918643995, 0.7768509255100765, 1.0693715832453634, 1.0003935586158077, 0.8266103868732955, 0.888504001036279, 1.198148680752794, 0.925786344677888, 1.0602270375907268, 0.8957322671890489, 0.9814428243438064, 1.1743677925211478, 0.9951812437001132, 0.9488503984580591], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167303, 15.54081410196518, 15.068451007537302, 15.399544082311628, 15.2570938285224, 14.557690604799433, 15.290158268146262, 14.485009531511755, 14.7281302838836, 15.018685290694112, 14.776259456923349, 14.368787418717236, 14.639612718144871, 14.576825387557294, 14.197495404411764, 14.849490400568856, 14.558521560574947, 14.13503366903045, 14.635902753773475, 14.169275293839702, 14.487367844899603, 14.277029960920538, 14.328287042555727, 14.043520810546314, 14.282336249704422, 14.310534016093635, 14.630489316917044, 13.995837669094692, 14.648120256342104, 14.473953910573629, 14.39894319682959, 13.975327364460906], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.525142876466809, 1.551031253113687, 1.6259629568923126, 1.6052787078983652, 1.50159952993406, 1.3394397565795664, 1.5621974049448066, 1.6277358837594262, 1.5357446942701272, 1.6478496377993863, 1.5076942246588998, 1.5314959433589597, 1.4715230104246122, 1.5130375468948625, 1.4352754753778645, 1.530612244897959, 1.5176067310688688, 1.612698815030733, 1.482455067856706, 1.2585525076894106, 1.4948185736557331, 1.5516976494085113, 1.3658258334389657, 1.3621648036161504, 1.5267655189746168, 1.5255777720072707, 1.5421804718337873, 1.3467910173027364, 1.5253758513543203, 1.6857951541165126, 1.4096366755028849, 1.3874694168292607], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.4751196866386188, 0.4233519513323135, 0.4630766532187335, 0.4637762630876256, 0.4086051547111825, 0.3815388734562736, 0.4589055275688358, 0.4702501469531709, 0.4510114099155195, 0.530596572066883, 0.4617479985383516, 0.4626484195541752, 0.3903068150963888, 0.4429312795425247, 0.4543094496365524, 0.44030653401452, 0.3988035892323031, 0.4634327853325214, 0.4232321916916265, 0.3348625389277701, 0.4688568358675479, 0.4452447209035848, 0.3654080389768575, 0.3903454557283196, 0.5262805041566103, 0.4512635379061371, 0.4726051953978032, 0.3758538418799229, 0.4286527577777033, 0.5107455558503582, 0.4523532346582404, 0.4225817101353582], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.132895559724828, 0.1263351326518892, 0.1395436545351687, 0.1397650436293582, 0.0825639870899947, 0.1075770072076594, 0.1036998629680382, 0.1361874498027028, 0.1082055906221821, 0.1837821618783287, 0.145819255254828, 0.1037093372973346, 0.0764275575936237, 0.102596759357532, 0.1353039134054954, 0.1224519196139163, 0.0782778864970645, 0.1051677243880326, 0.1009608689597549, 0.0609909231155598, 0.1287942077415761, 0.1015406162464986, 0.0652883569096844, 0.0834608429545138, 0.1795783500341199, 0.0745628751444655, 0.118495800369428, 0.0908646117285245, 0.0968714121699196, 0.1526229857315255, 0.1068299978634, 0.09892245186362833]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9731/9731 [11:32<00:00, 14.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 | Train Time: 11m 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2433/2433 [00:54<00:00, 44.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 | Test Time: 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 192.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1996 ====================\n",
      "target_sentence 어쩌면 이름도 찾을 수 있을 거라 생각했죠. \n",
      "generate: 그의 그의 그의 수도 수도 수도..\n",
      "output tensor([[[ -3.3905, -25.7671, -26.9997,  ..., -23.3591, -26.4347, -26.5365],\n",
      "         [ -3.0778, -16.0905, -16.0967,  ..., -12.2835, -16.1458, -15.8019],\n",
      "         [ -5.4896, -21.5881, -21.5394,  ..., -16.8208, -21.6566, -20.8290],\n",
      "         ...,\n",
      "         [ 17.5489, -28.0747, -28.4570,  ..., -18.2183, -28.3265, -28.2192],\n",
      "         [ 17.4480, -28.3858, -28.7118,  ..., -18.2511, -28.6367, -28.4997],\n",
      "         [ 18.6261, -28.8529, -28.8756,  ..., -16.3906, -29.0546, -29.0334]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1997 ====================\n",
      "target_sentence 할 수 있는 거라곤 그저 하늘을 올려다 보는 것 뿐입니다. \n",
      "generate: 제가 할 할 수 수 곤 하늘을 하늘을 하늘을 었 었 었 었. 니\n",
      "output tensor([[[ -3.4990, -26.7106, -27.3171,  ..., -22.7104, -27.1019, -27.2993],\n",
      "         [ -4.2071, -23.7665, -23.7585,  ..., -13.9000, -23.0015, -23.0268],\n",
      "         [ -5.3243, -24.2033, -23.5056,  ..., -17.8157, -23.8512, -23.3809],\n",
      "         ...,\n",
      "         [ 19.7265, -26.6423, -26.5318,  ..., -16.5553, -26.7701, -26.9282],\n",
      "         [ 19.6999, -26.7195, -26.5695,  ..., -16.5742, -26.9003, -27.0206],\n",
      "         [ 20.2922, -27.4083, -27.1220,  ..., -16.2201, -27.6444, -27.7834]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1998 ====================\n",
      "target_sentence 다윈은 초창기 인간의 두 종족이 만나서 경쟁하는 시나리오를 썼습니다. \n",
      "generate: 그는 이런 는 는 는 는 부족 두 부족 두 가지의 나누 나누 가지의 가지의..\n",
      "output tensor([[[ -4.8945, -28.1861, -28.8350,  ..., -25.2221, -28.1442, -28.5413],\n",
      "         [ -3.7625, -21.7536, -22.2314,  ..., -14.5867, -22.8148, -21.9088],\n",
      "         [ -6.9068, -25.3493, -25.8143,  ..., -17.1924, -25.8141, -25.9634],\n",
      "         ...,\n",
      "         [ 15.6749, -23.4442, -23.6405,  ..., -19.3155, -23.4588, -24.1248],\n",
      "         [ 15.8445, -25.6323, -25.7640,  ..., -20.8720, -25.6038, -26.1837],\n",
      "         [ 19.3102, -28.4685, -28.7098,  ..., -19.6733, -28.6034, -28.9292]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "i= 1999 ====================\n",
      "target_sentence 후원자가 있는 건 정말 엄청나게 중요합니다. \n",
      "generate: 저는 자가 들 중요한 중요 그렇게 지 말할 수 수.\n",
      "output tensor([[[ -0.0481, -29.3757, -30.0239,  ..., -25.8438, -29.7427, -29.5713],\n",
      "         [ -4.2530, -19.5575, -19.9905,  ..., -15.8058, -19.8320, -19.9191],\n",
      "         [ -2.2239, -20.5550, -20.6035,  ..., -18.2655, -21.0278, -20.5620],\n",
      "         ...,\n",
      "         [ 19.2095, -24.5844, -24.4022,  ..., -15.9923, -24.7690, -24.7793],\n",
      "         [ 18.3218, -26.5331, -26.3164,  ..., -16.6043, -26.7272, -26.6706],\n",
      "         [ 18.5044, -26.9933, -26.6177,  ..., -15.6438, -27.1130, -27.2185]]],\n",
      "       device='cuda:0')\n",
      "====================\n",
      "Epoch 40 | Eval Time: 0m 10s\n",
      "\tTrain Loss: 1.932 | Test Loss: 4.940\n",
      "\tBLEU Score:\n",
      "\t\tavg: 0.933\n",
      "\t\t1-gram: 14.154\n",
      "\t\t2-gram: 1.420\n",
      "\t\t3-gram: 0.411\n",
      "\t\t4-gram: 0.092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': [0.1049915270848691, 1.2451767395632234, 1.3669241551835052, 0.8852178342349843, 1.3252992662540422, 1.1715614544214363, 1.101279312520716, 1.116692289279721, 1.0994305499456043, 1.065565142789168, 1.1217228300472808, 1.1251005772205362, 0.9376270106656373, 0.945841750555376, 1.032552971972674, 1.108516565724771, 1.025004961153448, 1.246391054667423, 1.1066860083111192, 1.0136808173874745, 0.8953404182688746, 1.0005658195083458, 1.0579186716815774, 1.0521420193171729, 0.9113153109680574, 1.0266675521574615, 0.9812579918643995, 0.7768509255100765, 1.0693715832453634, 1.0003935586158077, 0.8266103868732955, 0.888504001036279, 1.198148680752794, 0.925786344677888, 1.0602270375907268, 0.8957322671890489, 0.9814428243438064, 1.1743677925211478, 0.9951812437001132, 0.9488503984580592, 0.9328340569054522], '1-gram': [0.2652519893899204, 16.846767726908244, 16.48216925684203, 15.98264456931503, 16.705720192970364, 15.949596212754107, 14.785531370038411, 15.060960281548518, 15.172151658167303, 15.54081410196518, 15.068451007537302, 15.399544082311628, 15.2570938285224, 14.557690604799433, 15.290158268146262, 14.485009531511755, 14.7281302838836, 15.018685290694112, 14.776259456923349, 14.368787418717236, 14.639612718144871, 14.576825387557294, 14.197495404411764, 14.849490400568856, 14.558521560574947, 14.13503366903045, 14.635902753773475, 14.169275293839702, 14.487367844899603, 14.277029960920538, 14.328287042555727, 14.043520810546314, 14.282336249704422, 14.310534016093635, 14.630489316917044, 13.995837669094692, 14.648120256342104, 14.473953910573629, 14.39894319682959, 13.975327364460906, 14.154016169371255], '2-gram': [0.1424501424501424, 1.7732401934443849, 1.7292970116193216, 1.3936748602496365, 1.754256106587713, 1.66492068243041, 1.6210115933107625, 1.555793991416309, 1.525142876466809, 1.551031253113687, 1.6259629568923126, 1.6052787078983652, 1.50159952993406, 1.3394397565795664, 1.5621974049448066, 1.6277358837594262, 1.5357446942701272, 1.6478496377993863, 1.5076942246588998, 1.5314959433589597, 1.4715230104246122, 1.5130375468948625, 1.4352754753778645, 1.530612244897959, 1.5176067310688688, 1.612698815030733, 1.482455067856706, 1.2585525076894106, 1.4948185736557331, 1.5516976494085113, 1.3658258334389657, 1.3621648036161504, 1.5267655189746168, 1.5255777720072707, 1.5421804718337873, 1.3467910173027364, 1.5253758513543203, 1.6857951541165126, 1.4096366755028849, 1.3874694168292607, 1.4203668251713704], '3-gram': [0.0769230769230769, 0.6531825757917024, 0.6193907217798003, 0.3814420166673576, 0.5914794980417233, 0.537851827887415, 0.484528135667878, 0.4636118598382749, 0.4751196866386188, 0.4233519513323135, 0.4630766532187335, 0.4637762630876256, 0.4086051547111825, 0.3815388734562736, 0.4589055275688358, 0.4702501469531709, 0.4510114099155195, 0.530596572066883, 0.4617479985383516, 0.4626484195541752, 0.3903068150963888, 0.4429312795425247, 0.4543094496365524, 0.44030653401452, 0.3988035892323031, 0.4634327853325214, 0.4232321916916265, 0.3348625389277701, 0.4688568358675479, 0.4452447209035848, 0.3654080389768575, 0.3903454557283196, 0.5262805041566103, 0.4512635379061371, 0.4726051953978032, 0.3758538418799229, 0.4286527577777033, 0.5107455558503582, 0.4523532346582404, 0.4225817101353582, 0.4113736589218719], '4-gram': [0.0418060200668896, 0.1582669766061625, 0.1977557027225901, 0.0722706535977234, 0.1779745626600685, 0.1319029194512838, 0.1266624445851805, 0.1431445372949551, 0.132895559724828, 0.1263351326518892, 0.1395436545351687, 0.1397650436293582, 0.0825639870899947, 0.1075770072076594, 0.1036998629680382, 0.1361874498027028, 0.1082055906221821, 0.1837821618783287, 0.145819255254828, 0.1037093372973346, 0.0764275575936237, 0.102596759357532, 0.1353039134054954, 0.1224519196139163, 0.0782778864970645, 0.1051677243880326, 0.1009608689597549, 0.0609909231155598, 0.1287942077415761, 0.1015406162464986, 0.0652883569096844, 0.0834608429545138, 0.1795783500341199, 0.0745628751444655, 0.118495800369428, 0.0908646117285245, 0.0968714121699196, 0.1526229857315255, 0.1068299978634, 0.0989224518636283, 0.09155896749656654]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|██████████████████████████████████████████████████████████████████████████████▌                                                                                    | 4693/9731 [05:34<05:58, 14.04it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m bleu_scores \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 8\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./MODELS/translation_model(\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m).pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     10\u001b[0m epoch_mins, epoch_secs \u001b[38;5;241m=\u001b[39m epoch_time(start_time, end_time)\n",
      "Cell \u001b[0;32mIn[27], line 26\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     23\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     24\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 26\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     28\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), path)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 訓練模型\n",
    "for epoch in range(num_epochs):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    bleu_scores = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_loss = train(path='./MODELS/translation_model({}).pth'.format(model_name))\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    #break\n",
    "    print(f'Epoch {epoch+1:02} | Train Time: {epoch_mins}m {epoch_secs}s')\n",
    "\n",
    "    start_time = time.time()\n",
    "    test_loss = evaluate()\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    print(f'Epoch {epoch+1:02} | Test Time: {epoch_mins}m {epoch_secs}s')\n",
    "\n",
    "    start_time = time.time()\n",
    "    samples = get_samples(TEST_ZSENT,TEST_KSENT,num=2000)\n",
    "    test_score = sacrebleu_score(model, source_sentences=samples['zh'],target_sentences=samples['ko'])\n",
    "    #test_score = sacrebleu_score(model, source_sentences=TEST_ZSENT,target_sentences=TEST_KSENT)\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    print(f'Epoch {epoch+1:02} | Eval Time: {epoch_mins}m {epoch_secs}s')\n",
    "\n",
    "    wandb.log({\"Train_loss\": train_loss, \"Test_loss\": test_loss})\n",
    "    wandb.log({'BLEU_score(avg)':test_score['avg'],'1-gram':test_score['1-gram'],'2-gram':test_score['2-gram'],'3-gram':test_score['3-gram'],'4-gram':test_score['4-gram']})\n",
    "\n",
    "    # 儲存訓練好的模型\n",
    "    if(test_score['avg'] > best_score or test_loss < best_loss):\n",
    "    #if(test_loss < best_loss):\n",
    "      best_score = test_score['avg']\n",
    "      best_loss = test_loss\n",
    "      torch.save(model.state_dict(), './MODELS/best_translation_model({}).pth'.format(model_name))\n",
    "      print('== save model ==')\n",
    "    print('\\tTrain Loss: {:.3f} | Test Loss: {:.3f}'.format(train_loss, test_loss))\n",
    "    print('\\tBLEU Score:')\n",
    "    for k in test_score.keys():\n",
    "        print('\\t\\t{}: {:.3f}'.format(k,test_score[k]))\n",
    "\n",
    "\n",
    "    if(test_score['avg'] == 0):\n",
    "      try:\n",
    "        model.load_state_dict(torch.load('./MODELS/best_translation_model({}).pth'.format(model_name)))\n",
    "        print('-'*5,'load_best_model','-'*5)\n",
    "      except:\n",
    "        model = TranslationModel(my_model).to(device)\n",
    "        print('-'*5,'initialize','-'*5)\n",
    "        #'nothing'\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    bleu_scores.append(test_score)\n",
    "\n",
    "    loss_history(train_losses, test_losses, path=model_name, to_show=False)\n",
    "    sacrebleu_history(bleu_scores, path=model_name, to_show=False)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ceNwfHY0W3rq"
   },
   "outputs": [],
   "source": [
    "bleu_score(test_source_sentences,model,tokenizer,max_length,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d0aItTP3JE9b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "je6JQhwGJE9c"
   },
   "outputs": [],
   "source": [
    "from sacrebleu.metrics import BLEU\n",
    "\n",
    "def sacrebleu_score(source_sentences,target_sentences,lang='ko'):\n",
    "  global zh_tokenizer, ko_tokenizer, model, max_length, device\n",
    "  model.eval()\n",
    "  bleu = BLEU()\n",
    "  bleu.trg_lang = lang\n",
    "  avg_score = {'avg':0,'1-gram':0,'2-gram':0,'3-gram':0,'4-gram':0}\n",
    "\n",
    "  # 生成目標語句\n",
    "  generated_sentences = []\n",
    "  with tqdm(total = len(source_sentences)) as pbar:\n",
    "    for i in range(len(source_sentences)):\n",
    "        source_sentence = source_sentences[i]\n",
    "        target_sentence = target_sentences[i]\n",
    "        source_tokens = zh_tokenizer(source_sentence, padding=True, truncation=True, return_tensors='pt', max_length=max_length).to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(input_ids=source_tokens.input_ids, attention_mask=source_tokens.attention_mask)\n",
    "        generated_sentence = ko_tokenizer.decode(output[0].argmax(dim=-1), skip_special_tokens=True)\n",
    "        gen_sent = ''\n",
    "        for sent in generated_sentence:\n",
    "            gen_sent += sent\n",
    "        bleu_score = bleu.corpus_score([gen_sent],[[target_sentence]])\n",
    "        #print([gen_sent],[[target_sentence]])\n",
    "        #print(bleu_score)\n",
    "        avg_score['avg'] += bleu_score.score\n",
    "        avg_score['1-gram'] += bleu_score.precisions[0]\n",
    "        avg_score['2-gram'] += bleu_score.precisions[1]\n",
    "        avg_score['3-gram'] += bleu_score.precisions[2]\n",
    "        avg_score['4-gram'] += bleu_score.precisions[3]\n",
    "        pbar.update(1)\n",
    "  avg_score['avg'] /= len(source_sentences)\n",
    "  avg_score['1-gram'] /= len(source_sentences)\n",
    "  avg_score['2-gram'] /= len(source_sentences)\n",
    "  avg_score['3-gram'] /= len(source_sentences)\n",
    "  avg_score['4-gram'] /= len(source_sentences)\n",
    "\n",
    "  #print('gen:',generated_sentences,'tar:',[[sent] for sent in target_sentences],'sor',source_sentences)\n",
    "  #print('BLEU Score:',bleu.score)\n",
    "\n",
    "  return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zuOJRIdhJE9c"
   },
   "outputs": [],
   "source": [
    "train_score = sacrebleu_score(TRAIN_ZSENT,TRAIN_KSENT)\n",
    "test_score = sacrebleu_score(TEST_ZSENT,TEST_KSENT)\n",
    "print('Train:',train_score)\n",
    "print('Test:',test_score)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1ujERMOwPFmGoruZE_6CcVWyk3EPAGwP3",
     "timestamp": 1716394033678
    },
    {
     "file_id": "1_EEW5tkhh2ILfM2VDVsWwM_CRutS5n2N",
     "timestamp": 1712825273579
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0563cfc3dc7a4334a53b03abea67bf34": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0938947be70f49b4a2668b30e45b1aae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82a629771ba64d33bd22296eea4422c9",
      "placeholder": "​",
      "style": "IPY_MODEL_f8101c683be54ab8896726653a59bf9f",
      "value": "config.json: 100%"
     }
    },
    "0adc71bb095f43799268b2919bb13a99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_32df952cd1364acdbb0b19240b4adf48",
       "IPY_MODEL_715c99ee56c244d6b9f79384e293333b",
       "IPY_MODEL_76b82f63b5cc49ebbbd4e97ff4820a50"
      ],
      "layout": "IPY_MODEL_2d912a15a80142c686e2a4d85ee083d3"
     }
    },
    "0b8c98a0d9b7446396cfbebb7356f676": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c734c2af04840a3af651a31e0ae33ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "134d4d993a884a6e8c4fc86dedb75b21": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14c4da599454480886928b62d789a0d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_46738251f2a847faaa21f90ce1c8725f",
      "max": 49,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6531766795024285ab5dcb1828072349",
      "value": 49
     }
    },
    "14c72a7544d547e19e3b04474ed198c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1586223071164a14abc0a26dc6c39df0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_66de85187d564d16953e5d45a48466d5",
       "IPY_MODEL_527e76b798d444fb9c088467f8fa9e4c",
       "IPY_MODEL_b4da9eee63a84ad383f189e13a6d0fa9"
      ],
      "layout": "IPY_MODEL_538dd1ab4c82412b83dee2d6f709f994"
     }
    },
    "1cba16906e3147ecadbc6706de0c39d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1de1d369d5294e5a85c9916b298fe2f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22c2517d14394a4e8f3acd48feec8d56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a150d2dafa1478cb605c03ae1b6f11c",
      "max": 344259,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7c3c148f9b90423385d516070de18258",
      "value": 344259
     }
    },
    "238e7b4c12d644f9aa05c4f4c593d4cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_da264c4adb1b4347a7a06dab0ce3dd57",
      "placeholder": "​",
      "style": "IPY_MODEL_918e1783d17e44f79cfd44a9e9e1e009",
      "value": " 80.0/80.0 [00:00&lt;00:00, 2.23kB/s]"
     }
    },
    "23bacab63696486ca08b8a72ab7f9390": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ee853e912fec4f14ad6edacb24cf7f01",
       "IPY_MODEL_8d5911ca7c2241d8a2bdb3a5f77a31e6",
       "IPY_MODEL_ff694afd3f42475fb6829485061c9a72"
      ],
      "layout": "IPY_MODEL_cfc8e231b76a49b7b7bcb877d5865a34"
     }
    },
    "26327b0bfc984ae0ac60478845121aa0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2cd96637c2054f7e8489493d5281508c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5db7d093c33b4e2a8082774769259371",
      "max": 625,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bb325f7be9334219a976b70c49578c28",
      "value": 625
     }
    },
    "2d912a15a80142c686e2a4d85ee083d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30c4c0cd48464741b15fd40e0c450e77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32d07b4c240d44f5b7b9894bca42540f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32df952cd1364acdbb0b19240b4adf48": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_26327b0bfc984ae0ac60478845121aa0",
      "placeholder": "​",
      "style": "IPY_MODEL_f9c5eddf3686461280d275049ee72790",
      "value": "pytorch_model.bin: 100%"
     }
    },
    "3348d44475c94cb1b98061bfcb53900e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34720f0f64834830b1c090e5b86ca5c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3a35087770b400fa5877ce0e6842536",
      "max": 1961828,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_89cac8a78da644598575401b3bd024d9",
      "value": 1961828
     }
    },
    "3bb347ee412446e19040d3499a68a31c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f5d8280b13f4a86a3604fd8a697a381",
      "max": 714290682,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dd0d07a703ed49a98f58ec914582192c",
      "value": 714290682
     }
    },
    "3f5d8280b13f4a86a3604fd8a697a381": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "422d1a5b399e4941bbec1937d5dee18a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46738251f2a847faaa21f90ce1c8725f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4696479d8ba840738d9a0bbec847c17b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ed194bf6757a450f96d791fd7e0ecbd0",
       "IPY_MODEL_3bb347ee412446e19040d3499a68a31c",
       "IPY_MODEL_4fc089ca629e46179c17939fa94782bf"
      ],
      "layout": "IPY_MODEL_1cba16906e3147ecadbc6706de0c39d6"
     }
    },
    "46f1132276e742fb909466adf9d26fe9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4b9dde8db8da4462b28fd0793ceb5d5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4fc089ca629e46179c17939fa94782bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32d07b4c240d44f5b7b9894bca42540f",
      "placeholder": "​",
      "style": "IPY_MODEL_eea8c8d16bc04a93af2aabf6b526728b",
      "value": " 714M/714M [00:05&lt;00:00, 153MB/s]"
     }
    },
    "52362e3759cb4b3f808c602671700337": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "527e76b798d444fb9c088467f8fa9e4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_611e6c598aa3483bb2c0143f2cd498cd",
      "max": 995526,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d8b4b59278814e38a249ff6e7a1b0885",
      "value": 995526
     }
    },
    "538dd1ab4c82412b83dee2d6f709f994": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "569fcbc6a1c44d52b64226dbe4d5451e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56fd94b10ecc43178e1865f37f5e20e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "56fdffe8b977489b9ec2e5ea8a40edf5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5a150d2dafa1478cb605c03ae1b6f11c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5db7d093c33b4e2a8082774769259371": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6074bfa7ab5145ad91c79fcac9875f3c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "611e6c598aa3483bb2c0143f2cd498cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "644aa53bc9a047d1a4938cf9aa3de6e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6531766795024285ab5dcb1828072349": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "66de85187d564d16953e5d45a48466d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_134d4d993a884a6e8c4fc86dedb75b21",
      "placeholder": "​",
      "style": "IPY_MODEL_b6af3a537d524dfd8c48b06001d860b5",
      "value": "vocab.txt: 100%"
     }
    },
    "6a137696522c4a6ca2c8ad9dc7e9acd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73cfb114ca204454900aa142feedaa47",
      "max": 701,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_945d2960866041a7bc653dfe62a40211",
      "value": 701
     }
    },
    "6c4a5936add74d4cadffe7e6d9dfba73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6fc971d8f2f24a62be8f9b3ff4301ba5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "700c4a3194f241eaa4ae36b9fa476914": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "715c99ee56c244d6b9f79384e293333b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_84fc974f3f8c40199788427160646b56",
      "max": 409251346,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4b9dde8db8da4462b28fd0793ceb5d5a",
      "value": 409251346
     }
    },
    "720a589cb35d45f4aebf20dd2b73b07f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9858cb49cdc247b1abd923428afb691e",
       "IPY_MODEL_8fb4f3b706b14ed9bd565fa9ec9a6f9e",
       "IPY_MODEL_238e7b4c12d644f9aa05c4f4c593d4cf"
      ],
      "layout": "IPY_MODEL_d45bef2c5ce5422b8fd150dfb3378562"
     }
    },
    "733616701add43a0b47e2565c67cc277": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "73cfb114ca204454900aa142feedaa47": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "759bab7844094ada9fe4d454058e3b3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "76b82f63b5cc49ebbbd4e97ff4820a50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be5bf2d5e1a7442dad9e0439d50579f5",
      "placeholder": "​",
      "style": "IPY_MODEL_46f1132276e742fb909466adf9d26fe9",
      "value": " 409M/409M [00:06&lt;00:00, 125MB/s]"
     }
    },
    "7a6208ceae814dc69046c5a7a8f6d9b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6074bfa7ab5145ad91c79fcac9875f3c",
      "placeholder": "​",
      "style": "IPY_MODEL_6c4a5936add74d4cadffe7e6d9dfba73",
      "value": "vocab.txt: 100%"
     }
    },
    "7c3c148f9b90423385d516070de18258": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7fd9db41a1ad42f3b5aff4d361943bb6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82a629771ba64d33bd22296eea4422c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84fc974f3f8c40199788427160646b56": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89cac8a78da644598575401b3bd024d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8d5911ca7c2241d8a2bdb3a5f77a31e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9370f273eb4647c4bdeadfe48dcee187",
      "max": 725,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b02773cc93624856906bd903ae3dff37",
      "value": 725
     }
    },
    "8fb4f3b706b14ed9bd565fa9ec9a6f9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c734c2af04840a3af651a31e0ae33ee",
      "max": 80,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6fc971d8f2f24a62be8f9b3ff4301ba5",
      "value": 80
     }
    },
    "907bc2da70694082b8147f9502c5983f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "918e1783d17e44f79cfd44a9e9e1e009": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "926df48f58ae43e0b55924dc10143d60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e1c08ebdce2346a3a9be94d10fb29fb7",
       "IPY_MODEL_34720f0f64834830b1c090e5b86ca5c6",
       "IPY_MODEL_e45bbf5f1ed0479c91c2a5ffd920af56"
      ],
      "layout": "IPY_MODEL_0563cfc3dc7a4334a53b03abea67bf34"
     }
    },
    "9370f273eb4647c4bdeadfe48dcee187": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "945d2960866041a7bc653dfe62a40211": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "96ea27ef4a594badb71ef41b3d53bec6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9858cb49cdc247b1abd923428afb691e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_644aa53bc9a047d1a4938cf9aa3de6e4",
      "placeholder": "​",
      "style": "IPY_MODEL_759bab7844094ada9fe4d454058e3b3e",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "9a249264df174c9f8392583b817ff4b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9e5336577baf42f99c498a274e7b4d0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c8c65ba734d84a958b11806ef8c45e9c",
      "placeholder": "​",
      "style": "IPY_MODEL_733616701add43a0b47e2565c67cc277",
      "value": " 701/701 [00:00&lt;00:00, 8.56kB/s]"
     }
    },
    "a072699ae51044d8a72d5c82f8182411": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4e03bf1e679463ba560517492456925": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aa571eba262645259e967446753c17bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ad0ea6494ceb48a8ac8a39bca70999d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b02773cc93624856906bd903ae3dff37": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b22c7a401a2544d5b3e003e4bfc89848": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dc692d3bd30846c893969865f28231d5",
       "IPY_MODEL_6a137696522c4a6ca2c8ad9dc7e9acd5",
       "IPY_MODEL_9e5336577baf42f99c498a274e7b4d0c"
      ],
      "layout": "IPY_MODEL_7fd9db41a1ad42f3b5aff4d361943bb6"
     }
    },
    "b4da9eee63a84ad383f189e13a6d0fa9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3348d44475c94cb1b98061bfcb53900e",
      "placeholder": "​",
      "style": "IPY_MODEL_56fd94b10ecc43178e1865f37f5e20e4",
      "value": " 996k/996k [00:00&lt;00:00, 8.26MB/s]"
     }
    },
    "b6af3a537d524dfd8c48b06001d860b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b988ec82ad424ae3835dd35d16a568db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d17c9b9a5592452eb4f6944648a2e8ea",
      "placeholder": "​",
      "style": "IPY_MODEL_56fdffe8b977489b9ec2e5ea8a40edf5",
      "value": " 49.0/49.0 [00:00&lt;00:00, 851B/s]"
     }
    },
    "bb325f7be9334219a976b70c49578c28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bc8062ce07204a17ab32b380b3792c1f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be5bf2d5e1a7442dad9e0439d50579f5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8c65ba734d84a958b11806ef8c45e9c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd2b767543f1435299935d6dadee5034": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc8062ce07204a17ab32b380b3792c1f",
      "placeholder": "​",
      "style": "IPY_MODEL_ed9e0e610cec4c84aeb24b399e6e55a4",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "cfc8e231b76a49b7b7bcb877d5865a34": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d17c9b9a5592452eb4f6944648a2e8ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d45bef2c5ce5422b8fd150dfb3378562": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d46cd83f2d084f96ace507dc7873d143": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d795e4d7c862477485a2fb3587a801bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8b4b59278814e38a249ff6e7a1b0885": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d910e33b773b44f1ac0b2461317e25ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "da264c4adb1b4347a7a06dab0ce3dd57": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc0cec054f6947989c810c05bc469ada": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc692d3bd30846c893969865f28231d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_30c4c0cd48464741b15fd40e0c450e77",
      "placeholder": "​",
      "style": "IPY_MODEL_d46cd83f2d084f96ace507dc7873d143",
      "value": "config.json: 100%"
     }
    },
    "dd0d07a703ed49a98f58ec914582192c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e1c08ebdce2346a3a9be94d10fb29fb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_907bc2da70694082b8147f9502c5983f",
      "placeholder": "​",
      "style": "IPY_MODEL_a4e03bf1e679463ba560517492456925",
      "value": "tokenizer.json: 100%"
     }
    },
    "e45bbf5f1ed0479c91c2a5ffd920af56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_569fcbc6a1c44d52b64226dbe4d5451e",
      "placeholder": "​",
      "style": "IPY_MODEL_ad0ea6494ceb48a8ac8a39bca70999d8",
      "value": " 1.96M/1.96M [00:00&lt;00:00, 16.0MB/s]"
     }
    },
    "e974ba8f861c48aeb8548cab312d758c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0938947be70f49b4a2668b30e45b1aae",
       "IPY_MODEL_2cd96637c2054f7e8489493d5281508c",
       "IPY_MODEL_f802bbfadf5145f3b291cad7a617c4d4"
      ],
      "layout": "IPY_MODEL_d795e4d7c862477485a2fb3587a801bb"
     }
    },
    "ecd1452d40544b9f8e824893d8965f80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cd2b767543f1435299935d6dadee5034",
       "IPY_MODEL_14c4da599454480886928b62d789a0d5",
       "IPY_MODEL_b988ec82ad424ae3835dd35d16a568db"
      ],
      "layout": "IPY_MODEL_0b8c98a0d9b7446396cfbebb7356f676"
     }
    },
    "ed194bf6757a450f96d791fd7e0ecbd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1de1d369d5294e5a85c9916b298fe2f1",
      "placeholder": "​",
      "style": "IPY_MODEL_700c4a3194f241eaa4ae36b9fa476914",
      "value": "model.safetensors: 100%"
     }
    },
    "ed9e0e610cec4c84aeb24b399e6e55a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee853e912fec4f14ad6edacb24cf7f01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a072699ae51044d8a72d5c82f8182411",
      "placeholder": "​",
      "style": "IPY_MODEL_aa571eba262645259e967446753c17bf",
      "value": "config.json: 100%"
     }
    },
    "eea8c8d16bc04a93af2aabf6b526728b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eee8199ead804a67a93cc1c6adcc7690": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7a6208ceae814dc69046c5a7a8f6d9b6",
       "IPY_MODEL_22c2517d14394a4e8f3acd48feec8d56",
       "IPY_MODEL_fc999c62f7f94238becc6229b2169da6"
      ],
      "layout": "IPY_MODEL_dc0cec054f6947989c810c05bc469ada"
     }
    },
    "f3a35087770b400fa5877ce0e6842536": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f802bbfadf5145f3b291cad7a617c4d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52362e3759cb4b3f808c602671700337",
      "placeholder": "​",
      "style": "IPY_MODEL_96ea27ef4a594badb71ef41b3d53bec6",
      "value": " 625/625 [00:00&lt;00:00, 14.8kB/s]"
     }
    },
    "f8101c683be54ab8896726653a59bf9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f9c5eddf3686461280d275049ee72790": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fc999c62f7f94238becc6229b2169da6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14c72a7544d547e19e3b04474ed198c2",
      "placeholder": "​",
      "style": "IPY_MODEL_d910e33b773b44f1ac0b2461317e25ff",
      "value": " 344k/344k [00:00&lt;00:00, 1.39MB/s]"
     }
    },
    "ff694afd3f42475fb6829485061c9a72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_422d1a5b399e4941bbec1937d5dee18a",
      "placeholder": "​",
      "style": "IPY_MODEL_9a249264df174c9f8392583b817ff4b3",
      "value": " 725/725 [00:00&lt;00:00, 23.7kB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
